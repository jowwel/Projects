{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import regexp_tokenize, wordpunct_tokenize,blankline_tokenize\n",
    "from nltk import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import json\n",
    "import re as regex\n",
    "# This will score 0.556+ on the LB, you can further raise this score\n",
    "# by using PCA and SVD as features.\n",
    "\n",
    "# From https://github.com/rhiever/datacleaner\n",
    "from datacleaner import autoclean\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterData_Initialize():\n",
    "    data = []\n",
    "    processed_data = []\n",
    "    wordlist = []\n",
    "\n",
    "    featureList = []\n",
    "    fea_vect=[]\n",
    "    whitelist = [\"n't\",\"not\"]    \n",
    "    \n",
    "    data_model = None\n",
    "    data_labels = None\n",
    "    is_testing = False\n",
    "    \n",
    "    def initialize(self, csv_file, is_testing_set=False, from_cached=None):\n",
    "        if from_cached is not None:\n",
    "            #self.data_model = pd.read_csv(from_cached)\n",
    "            self.data_model = pd.read_json(from_cached)\n",
    "\n",
    "            return\n",
    "\n",
    "        self.is_testing = is_testing_set\n",
    "\n",
    "        if not is_testing_set:\n",
    "            #self.data = pd.read_csv(csv_file, header=0, names=[\"id\", \"emotion\", \"text\"])\n",
    "            self.data = pd.read_json(csv_file)\n",
    "\n",
    "            #self.data = self.data[self.data[\"emotion\"].isin([\"positive\", \"negative\", \"neutral\"])]\n",
    "        \n",
    "\n",
    "        self.processed_data = self.data\n",
    "        self.wordlist = []\n",
    "        self.data_model = None\n",
    "        self.data_labels = None\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def do_process(self):\n",
    "        def stem_and_join(row,stemmer=nltk.PorterStemmer()):\n",
    "            row[\"spans\"] = list(map(lambda str: stemmer.stem(str.lower()), row[\"spans\"]))\n",
    "            return row\n",
    "    \n",
    "        def tokenize_grams(row):\n",
    "                #remove numbers\n",
    "                def remove_numbers(text):\n",
    "                    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "                #20 Function to remove whitespace\n",
    "                def remove_whitespace(text):\n",
    "                    return \" \".join(text.split())\n",
    "\n",
    "                # Function to remove punctuations\n",
    "                def remove_punctuations(text):\n",
    "                    words = nltk.word_tokenize(text)\n",
    "                    punt_removed = [w for w in words if w.lower() not in string.punctuation]\n",
    "                    return \" \".join(punt_removed)\n",
    "#30\n",
    "\n",
    "                # Function to remove stop words\n",
    "                def remove_stopwords(text, lang='english'):\n",
    "                    stop_words = set(stopwords.words('english'))\n",
    "                    word_tokens = word_tokenize(text)\n",
    "                    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "                    filtered_sentence = []\n",
    "                    for w in word_tokens:\n",
    "                        if w not in stop_words:\n",
    "                            filtered_sentence.append(w)\n",
    "                \n",
    "                    ch=\" \".join(filtered_sentence)\n",
    "\n",
    "                    return ch\n",
    "#40\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # Function to extract n-grams from text\n",
    "                def get_ngrams(text, n):\n",
    "\n",
    "                    n_grams = ngrams(nltk.word_tokenize(text), n)\n",
    "                    list_grams=[ ' '.join(grams) for grams in n_grams]\n",
    "                    return list_grams\n",
    "\n",
    "\n",
    "                # Function to apply lemmatization to a list of words\n",
    "                def words_lemmatizer(text, encoding=\"utf8\"):\n",
    "                    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "                    words = nltk.word_tokenize(text)\n",
    "                    lemma_words = []\n",
    "                    wl = WordNetLemmatizer()\n",
    "                    for word in words:\n",
    "                        pos = find_pos(word)\n",
    "                        lemma_words.append(wl.lemmatize(word, pos))\n",
    "                    return \" \".join(lemma_words)\n",
    "\n",
    "                # Function to find part of speech tag for a word\n",
    "                def find_pos(word):\n",
    "                    # Part of Speech constants\n",
    "                    # ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v'\n",
    "   \n",
    "                    pos = nltk.pos_tag(nltk.word_tokenize(word))[0][1]\n",
    "                    # Adjective tags - 'JJ', 'JJR', 'JJS'\n",
    "                    if pos.lower()[0] == 'j':\n",
    "                        return 'a'\n",
    "                    # Adverb tags - 'RB', 'RBR', 'RBS'\n",
    "                    elif pos.lower()[0] == 'r':\n",
    "                        return 'r'\n",
    "                    # Verb tags - 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'\n",
    "                    elif pos.lower()[0] == 'v':\n",
    "                        return 'v'\n",
    "                    # Noun tags - 'NN', 'NNS', 'NNP', 'NNPS'\n",
    "                    else:\n",
    "                        return 'n'\n",
    "    \n",
    "            \n",
    "            \n",
    "                idx=row[\"spans\"]\n",
    "                #convert to string\n",
    "                ch=\"\"\n",
    "                for w in idx :\n",
    "                    ch=\"\".join(w);\n",
    "    \n",
    "                #words_stemmer(ch, type=\"PorterStemmer\", lang=\"english\", encoding=\"utf8\")\n",
    "                #Convert to lower case\n",
    "                txt_num=remove_numbers(ch)\n",
    "    \n",
    "                txt_ws=remove_whitespace(txt_num)\n",
    "    \n",
    "                txt_pun=remove_punctuations(txt_ws)\n",
    "        \n",
    "                txt_final=remove_stopwords(txt_pun)\n",
    "\n",
    "                texte=words_lemmatizer(txt_final)\n",
    "\n",
    "                n_grams=get_ngrams(texte, 1)\n",
    "                row[\"token_spans\"] = n_grams\n",
    "    \n",
    "                return row\n",
    "        self.processed_data = self.processed_data.apply(stem_and_join, axis=1)\n",
    "        self.processed_data = self.processed_data.apply(tokenize_grams, axis=1)\n",
    "        \n",
    "    def build_wordlist(self, min_occurrences=0, max_occurences=500, stopwords=nltk.corpus.stopwords.words(\"english\"),\n",
    "                       whitelist=None):\n",
    "        self.wordlist = []\n",
    "        whitelist = self.whitelist if whitelist is None else whitelist\n",
    "        \n",
    "\n",
    "        words = Counter()\n",
    "\n",
    "        for idx in self.processed_data.index:\n",
    "            words.update(self.processed_data.loc[idx, \"token_spans\"])\n",
    "\n",
    "        \n",
    "                \n",
    "\n",
    "        word_df = pd.DataFrame(data={\"word\": [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\n",
    "                                     \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "\n",
    "        word_df.to_csv(\"wordlist_copie.csv\", index_label=\"idx\")\n",
    "        self.wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]\n",
    "        \n",
    "        \n",
    "    def build_data_model(self):\n",
    "        label_column = []\n",
    "        \n",
    "        label_column = [\"label\"]\n",
    "\n",
    "        columns = label_column + list(\n",
    "            map(lambda w: w + \"_bow\",self.wordlist))\n",
    "        labels = []\n",
    "        rows = []\n",
    "        for idx in self.processed_data.index:\n",
    "            current_row = []\n",
    "\n",
    "            if True:\n",
    "                # add label\n",
    "                current_label = self.processed_data.loc[idx, \"sentiment score\"]\n",
    "                labels.append(current_label)\n",
    "                current_row.append(current_label)\n",
    "\n",
    "            # add bag-of-words\n",
    "            tokens = set(self.processed_data.loc[idx, \"token_spans\"])\n",
    "            for _, word in enumerate(self.wordlist):\n",
    "                current_row.append(1 if word in tokens else 0)\n",
    "\n",
    "            rows.append(current_row)\n",
    "\n",
    "        self.data_model = pd.DataFrame(rows, columns=columns)\n",
    "        self.data_labels = pd.Series(labels)\n",
    "        return self.data_model, self.data_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterData_Initialize_test(TwitterData_Initialize):\n",
    "\n",
    "    \n",
    "    \n",
    "    def do_process(self):\n",
    "        def stem_and_join(row,stemmer=nltk.PorterStemmer()):\n",
    "            row[\"spans\"] = list(map(lambda str: stemmer.stem(str.lower()), row[\"spans\"]))\n",
    "            return row\n",
    "    \n",
    "        def tokenize_grams(row):\n",
    "                #remove numbers\n",
    "                def remove_numbers(text):\n",
    "                    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "                #20 Function to remove whitespace\n",
    "                def remove_whitespace(text):\n",
    "                    return \" \".join(text.split())\n",
    "\n",
    "                # Function to remove punctuations\n",
    "                def remove_punctuations(text):\n",
    "                    words = nltk.word_tokenize(text)\n",
    "                    punt_removed = [w for w in words if w.lower() not in string.punctuation]\n",
    "                    return \" \".join(punt_removed)\n",
    "#30\n",
    "\n",
    "                # Function to remove stop words\n",
    "                def remove_stopwords(text, lang='english'):\n",
    "                    stop_words = set(stopwords.words('english'))\n",
    "                    word_tokens = word_tokenize(text)\n",
    "                    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "                    filtered_sentence = []\n",
    "                    for w in word_tokens:\n",
    "                        if w not in stop_words:\n",
    "                            filtered_sentence.append(w)\n",
    "                \n",
    "                    ch=\" \".join(filtered_sentence)\n",
    "\n",
    "                    return ch\n",
    "#40\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # Function to extract n-grams from text\n",
    "                def get_ngrams(text, n):\n",
    "\n",
    "                    n_grams = ngrams(nltk.word_tokenize(text), n)\n",
    "                    list_grams=[ ' '.join(grams) for grams in n_grams]\n",
    "                    return list_grams\n",
    "\n",
    "\n",
    "                # Function to apply lemmatization to a list of words\n",
    "                def words_lemmatizer(text, encoding=\"utf8\"):\n",
    "                    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "                    words = nltk.word_tokenize(text)\n",
    "                    lemma_words = []\n",
    "                    wl = WordNetLemmatizer()\n",
    "                    for word in words:\n",
    "                        pos = find_pos(word)\n",
    "                        lemma_words.append(wl.lemmatize(word, pos))\n",
    "                    return \" \".join(lemma_words)\n",
    "\n",
    "                # Function to find part of speech tag for a word\n",
    "                def find_pos(word):\n",
    "                    # Part of Speech constants\n",
    "                    # ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v'\n",
    "   \n",
    "                    pos = nltk.pos_tag(nltk.word_tokenize(word))[0][1]\n",
    "                    # Adjective tags - 'JJ', 'JJR', 'JJS'\n",
    "                    if pos.lower()[0] == 'j':\n",
    "                        return 'a'\n",
    "                    # Adverb tags - 'RB', 'RBR', 'RBS'\n",
    "                    elif pos.lower()[0] == 'r':\n",
    "                        return 'r'\n",
    "                    # Verb tags - 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'\n",
    "                    elif pos.lower()[0] == 'v':\n",
    "                        return 'v'\n",
    "                    # Noun tags - 'NN', 'NNS', 'NNP', 'NNPS'\n",
    "                    else:\n",
    "                        return 'n'\n",
    "    \n",
    "            \n",
    "            \n",
    "                idx=row[\"spans\"]\n",
    "                ch=\"\".join(idx)\n",
    "\n",
    "    \n",
    "                #words_stemmer(ch, type=\"PorterStemmer\", lang=\"english\", encoding=\"utf8\")\n",
    "                #Convert to lower case\n",
    "                txt_num=remove_numbers(ch)\n",
    "    \n",
    "                txt_ws=remove_whitespace(txt_num)\n",
    "    \n",
    "                txt_pun=remove_punctuations(txt_ws)\n",
    "        \n",
    "                txt_final=remove_stopwords(txt_pun)\n",
    "\n",
    "                texte=words_lemmatizer(txt_final)\n",
    "\n",
    "                n_grams=get_ngrams(texte, 1)\n",
    "                row[\"token_spans\"] = n_grams\n",
    "    \n",
    "                return row\n",
    "        self.processed_data = self.processed_data.apply(stem_and_join, axis=1)\n",
    "        self.processed_data = self.processed_data.apply(tokenize_grams, axis=1)\n",
    "        \n",
    "    def build_wordlist(self, min_occurrences=0, max_occurences=500, stopwords=nltk.corpus.stopwords.words(\"english\"),\n",
    "                       whitelist=None):\n",
    "        self.wordlist = []\n",
    "        whitelist = self.whitelist if whitelist is None else whitelist\n",
    "        \n",
    "\n",
    "        words = Counter()\n",
    "\n",
    "        for idx in self.processed_data.index:\n",
    "            words.update(self.processed_data.loc[idx, \"token_spans\"])\n",
    "\n",
    "        \n",
    "                \n",
    "\n",
    "        word_df = pd.DataFrame(data={\"word\": [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\n",
    "                                     \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "\n",
    "        word_df.to_csv(\"wordlist_test.csv\", index_label=\"idx\")\n",
    "        self.wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]\n",
    "        \n",
    "        \n",
    "    def build_data_model(self):\n",
    "        \n",
    "\n",
    "        columns = list(\n",
    "            map(lambda w: w + \"_bow\",self.wordlist))\n",
    "        rows = []\n",
    "        for idx in self.processed_data.index:\n",
    "            current_row = []\n",
    "\n",
    "            \n",
    "\n",
    "            # add bag-of-words\n",
    "            tokens = set(self.processed_data.loc[idx, \"token_spans\"])\n",
    "            for _, word in enumerate(self.wordlist):\n",
    "                current_row.append(1 if word in tokens else 0)\n",
    "\n",
    "            rows.append(current_row)\n",
    "\n",
    "        self.data_model = pd.DataFrame(rows, columns=columns)\n",
    "        return self.data_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1700"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TwitterData_Initialize()\n",
    "data.initialize(\"Microblog_Trainingdata.json\")\n",
    "\n",
    "len(data.processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = TwitterData_Initialize_test()\n",
    "data_test.initialize(\"Microblogs_Testdata.json\")\n",
    "\n",
    "data_test.processed_data.head(5)\n",
    "len(data_test.processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.do_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cashtag</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment score</th>\n",
       "      <th>source</th>\n",
       "      <th>spans</th>\n",
       "      <th>token_spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$FB</td>\n",
       "      <td>719659409228451840</td>\n",
       "      <td>0.366</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[watching for bounce tomorrow]</td>\n",
       "      <td>[watch, bounce, tomorrow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$LUV</td>\n",
       "      <td>719904304207962112</td>\n",
       "      <td>0.638</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[record number of passengers served in 2015]</td>\n",
       "      <td>[record, number, passenger, serve]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$NFLX</td>\n",
       "      <td>5329774</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[out $nflx -.35]</td>\n",
       "      <td>[nflx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$DIA</td>\n",
       "      <td>719891468173844480</td>\n",
       "      <td>0.460</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[looking for a strong bounc, lunchtime rally com]</td>\n",
       "      <td>[lunchtime, rally, com]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$PLUG</td>\n",
       "      <td>20091246</td>\n",
       "      <td>0.403</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[very intrigued with the technology and growth...</td>\n",
       "      <td>[intrigue, technology, growth, potenti]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cashtag                  id  sentiment score      source  \\\n",
       "0     $FB  719659409228451840            0.366     twitter   \n",
       "1    $LUV  719904304207962112            0.638     twitter   \n",
       "2   $NFLX             5329774           -0.494  stocktwits   \n",
       "3    $DIA  719891468173844480            0.460     twitter   \n",
       "4   $PLUG            20091246            0.403  stocktwits   \n",
       "\n",
       "                                               spans  \\\n",
       "0                     [watching for bounce tomorrow]   \n",
       "1       [record number of passengers served in 2015]   \n",
       "2                                   [out $nflx -.35]   \n",
       "3  [looking for a strong bounc, lunchtime rally com]   \n",
       "4  [very intrigued with the technology and growth...   \n",
       "\n",
       "                               token_spans  \n",
       "0                [watch, bounce, tomorrow]  \n",
       "1       [record, number, passenger, serve]  \n",
       "2                                   [nflx]  \n",
       "3                  [lunchtime, rally, com]  \n",
       "4  [intrigue, technology, growth, potenti]  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cashtag</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$COST</td>\n",
       "      <td>709723193125175300</td>\n",
       "      <td>twitter</td>\n",
       "      <td>consumers keep cautious stance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$CTRP</td>\n",
       "      <td>719529094652698600</td>\n",
       "      <td>twitter</td>\n",
       "      <td>Close $CTRP @46.16 from 43.55 entry +6%;$;+6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$INTC</td>\n",
       "      <td>39048670</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>Every Reason to Be Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$PANW</td>\n",
       "      <td>37048093</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>$PANW need anoth $1 to all time high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$JRCC</td>\n",
       "      <td>6207860</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>Long setup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cashtag                  id      source  \\\n",
       "0   $COST  709723193125175300     twitter   \n",
       "1   $CTRP  719529094652698600     twitter   \n",
       "2   $INTC            39048670  stocktwits   \n",
       "3   $PANW            37048093  stocktwits   \n",
       "4   $JRCC             6207860  stocktwits   \n",
       "\n",
       "                                           spans  \n",
       "0                 consumers keep cautious stance  \n",
       "1  Close $CTRP @46.16 from 43.55 entry +6%;$;+6%  \n",
       "2                     Every Reason to Be Bullish  \n",
       "3           $PANW need anoth $1 to all time high  \n",
       "4                                     Long setup  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.processed_data = data_test.processed_data.drop(15)\n",
    "data_test.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.do_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.build_wordlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cashtag</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment score</th>\n",
       "      <th>source</th>\n",
       "      <th>spans</th>\n",
       "      <th>token_spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$FB</td>\n",
       "      <td>719659409228451840</td>\n",
       "      <td>0.366</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[watching for bounce tomorrow]</td>\n",
       "      <td>[watch, bounce, tomorrow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$LUV</td>\n",
       "      <td>719904304207962112</td>\n",
       "      <td>0.638</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[record number of passengers served in 2015]</td>\n",
       "      <td>[record, number, passenger, serve]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$NFLX</td>\n",
       "      <td>5329774</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[out $nflx -.35]</td>\n",
       "      <td>[nflx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$DIA</td>\n",
       "      <td>719891468173844480</td>\n",
       "      <td>0.460</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[looking for a strong bounc, lunchtime rally com]</td>\n",
       "      <td>[lunchtime, rally, com]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$PLUG</td>\n",
       "      <td>20091246</td>\n",
       "      <td>0.403</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[very intrigued with the technology and growth...</td>\n",
       "      <td>[intrigue, technology, growth, potenti]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cashtag                  id  sentiment score      source  \\\n",
       "0     $FB  719659409228451840            0.366     twitter   \n",
       "1    $LUV  719904304207962112            0.638     twitter   \n",
       "2   $NFLX             5329774           -0.494  stocktwits   \n",
       "3    $DIA  719891468173844480            0.460     twitter   \n",
       "4   $PLUG            20091246            0.403  stocktwits   \n",
       "\n",
       "                                               spans  \\\n",
       "0                     [watching for bounce tomorrow]   \n",
       "1       [record number of passengers served in 2015]   \n",
       "2                                   [out $nflx -.35]   \n",
       "3  [looking for a strong bounc, lunchtime rally com]   \n",
       "4  [very intrigued with the technology and growth...   \n",
       "\n",
       "                               token_spans  \n",
       "0                [watch, bounce, tomorrow]  \n",
       "1       [record, number, passenger, serve]  \n",
       "2                                   [nflx]  \n",
       "3                  [lunchtime, rally, com]  \n",
       "4  [intrigue, technology, growth, potenti]  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1700"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow, labels = data.build_data_model()\n",
    "bow.head(5)\n",
    "len(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cashtag</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>spans</th>\n",
       "      <th>token_spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$COST</td>\n",
       "      <td>709723193125175300</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[c, o, n, s, u, m, e, r, s,  , k, e, e, p,  , ...</td>\n",
       "      <td>[consumer, keep, cautious, stance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$CTRP</td>\n",
       "      <td>719529094652698600</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[c, l, o, s, e,  , $, c, t, r, p,  , @, 4, 6, ...</td>\n",
       "      <td>[close, ctrp, entry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$INTC</td>\n",
       "      <td>39048670</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[e, v, e, r, y,  , r, e, a, s, o, n,  , t, o, ...</td>\n",
       "      <td>[every, reason, bullish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$PANW</td>\n",
       "      <td>37048093</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[$, p, a, n, w,  , n, e, e, d,  , a, n, o, t, ...</td>\n",
       "      <td>[panw, need, anoth, time, high]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$JRCC</td>\n",
       "      <td>6207860</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[l, o, n, g,  , s, e, t, u, p]</td>\n",
       "      <td>[long, setup]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cashtag                  id      source  \\\n",
       "0   $COST  709723193125175300     twitter   \n",
       "1   $CTRP  719529094652698600     twitter   \n",
       "2   $INTC            39048670  stocktwits   \n",
       "3   $PANW            37048093  stocktwits   \n",
       "4   $JRCC             6207860  stocktwits   \n",
       "\n",
       "                                               spans  \\\n",
       "0  [c, o, n, s, u, m, e, r, s,  , k, e, e, p,  , ...   \n",
       "1  [c, l, o, s, e,  , $, c, t, r, p,  , @, 4, 6, ...   \n",
       "2  [e, v, e, r, y,  , r, e, a, s, o, n,  , t, o, ...   \n",
       "3  [$, p, a, n, w,  , n, e, e, d,  , a, n, o, t, ...   \n",
       "4                     [l, o, n, g,  , s, e, t, u, p]   \n",
       "\n",
       "                          token_spans  \n",
       "0  [consumer, keep, cautious, stance]  \n",
       "1                [close, ctrp, entry]  \n",
       "2            [every, reason, bullish]  \n",
       "3     [panw, need, anoth, time, high]  \n",
       "4                       [long, setup]  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.build_wordlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_test= data_test.build_data_model()\n",
    "bow_test.head(5)\n",
    "len(bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>stock_bow</th>\n",
       "      <th>short_bow</th>\n",
       "      <th>buy_bow</th>\n",
       "      <th>long_bow</th>\n",
       "      <th>look_bow</th>\n",
       "      <th>high_bow</th>\n",
       "      <th>today_bow</th>\n",
       "      <th>sell_bow</th>\n",
       "      <th>new_bow</th>\n",
       "      <th>...</th>\n",
       "      <th>infect_bow</th>\n",
       "      <th>malwar_bow</th>\n",
       "      <th>inc_bow</th>\n",
       "      <th>brings_bow</th>\n",
       "      <th>upscale_bow</th>\n",
       "      <th>concept_bow</th>\n",
       "      <th>ownitdon'ttradeit_bow</th>\n",
       "      <th>skin_bow</th>\n",
       "      <th>call/put_bow</th>\n",
       "      <th>buyer_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.366</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y  stock_bow  short_bow  buy_bow  long_bow  look_bow  high_bow  \\\n",
       "0  0.366          0          0        0         0         0         0   \n",
       "1  0.638          0          0        0         0         0         0   \n",
       "2 -0.494          0          0        0         0         0         0   \n",
       "3  0.460          0          0        0         0         0         0   \n",
       "4  0.403          0          0        0         0         0         0   \n",
       "\n",
       "   today_bow  sell_bow  new_bow    ...      infect_bow  malwar_bow  inc_bow  \\\n",
       "0          0         0        0    ...               0           0        0   \n",
       "1          0         0        0    ...               0           0        0   \n",
       "2          0         0        0    ...               0           0        0   \n",
       "3          0         0        0    ...               0           0        0   \n",
       "4          0         0        0    ...               0           0        0   \n",
       "\n",
       "   brings_bow  upscale_bow  concept_bow  ownitdon'ttradeit_bow  skin_bow  \\\n",
       "0           0            0            0                      0         0   \n",
       "1           0            0            0                      0         0   \n",
       "2           0            0            0                      0         0   \n",
       "3           0            0            0                      0         0   \n",
       "4           0            0            0                      0         0   \n",
       "\n",
       "   call/put_bow  buyer_bow  \n",
       "0             0          0  \n",
       "1             0          0  \n",
       "2             0          0  \n",
       "3             0          0  \n",
       "4             0          0  \n",
       "\n",
       "[5 rows x 1770 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow=bow.rename(columns={\"label\":\"y\"})\n",
    "bow.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_bow</th>\n",
       "      <th>buy_bow</th>\n",
       "      <th>short_bow</th>\n",
       "      <th>high_bow</th>\n",
       "      <th>long_bow</th>\n",
       "      <th>look_bow</th>\n",
       "      <th>call_bow</th>\n",
       "      <th>'s_bow</th>\n",
       "      <th>go_bow</th>\n",
       "      <th>sell_bow</th>\n",
       "      <th>...</th>\n",
       "      <th>many_bow</th>\n",
       "      <th>holder_bow</th>\n",
       "      <th>pennant/symmetrical_bow</th>\n",
       "      <th>progress_bow</th>\n",
       "      <th>sure_bow</th>\n",
       "      <th>thus_bow</th>\n",
       "      <th>believe_bow</th>\n",
       "      <th>flyin_bow</th>\n",
       "      <th>fundementals_bow</th>\n",
       "      <th>poopoo_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_bow  buy_bow  short_bow  high_bow  long_bow  look_bow  call_bow  \\\n",
       "0          0        0          0         0         0         0         0   \n",
       "1          0        0          0         0         0         0         0   \n",
       "2          0        0          0         0         0         0         0   \n",
       "3          0        0          0         1         0         0         0   \n",
       "4          0        0          0         0         1         0         0   \n",
       "\n",
       "   's_bow  go_bow  sell_bow     ...      many_bow  holder_bow  \\\n",
       "0       0       0         0     ...             0           0   \n",
       "1       0       0         0     ...             0           0   \n",
       "2       0       0         0     ...             0           0   \n",
       "3       0       0         0     ...             0           0   \n",
       "4       0       0         0     ...             0           0   \n",
       "\n",
       "   pennant/symmetrical_bow  progress_bow  sure_bow  thus_bow  believe_bow  \\\n",
       "0                        0             0         0         0            0   \n",
       "1                        0             0         0         0            0   \n",
       "2                        0             0         0         0            0   \n",
       "3                        0             0         0         0            0   \n",
       "4                        0             0         0         0            0   \n",
       "\n",
       "   flyin_bow  fundementals_bow  poopoo_bow  \n",
       "0          0                 0           0  \n",
       "1          0                 0           0  \n",
       "2          0                 0           0  \n",
       "3          0                 0           0  \n",
       "4          0                 0           0  \n",
       "\n",
       "[5 rows x 1236 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_test.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the data frames\n",
    "\n",
    "# This is for autocleaner to work properly\n",
    "\n",
    "# Since we have categorical variables we will\n",
    "# need our encoder to label them correctly\n",
    "# so we must use our encoder on the full\n",
    "# dataset to avoid having representation\n",
    "# errors.\n",
    "bow_clean = bow.append(bow_test)\n",
    "bow_clean = autoclean(bow_clean)\n",
    "train, test = bow_clean[0:len(bow)], bow_clean[len(bow):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'auto_bow</th>\n",
       "      <th>'best_bow</th>\n",
       "      <th>'d_bow</th>\n",
       "      <th>'grossly_bow</th>\n",
       "      <th>'highly_bow</th>\n",
       "      <th>'large_bow</th>\n",
       "      <th>'let_bow</th>\n",
       "      <th>'ll_bow</th>\n",
       "      <th>'m_bow</th>\n",
       "      <th>'outperform_bow</th>\n",
       "      <th>...</th>\n",
       "      <th>yoku_bow</th>\n",
       "      <th>zero_bow</th>\n",
       "      <th>zigzag_bow</th>\n",
       "      <th>zmh_bow</th>\n",
       "      <th>znga_bow</th>\n",
       "      <th>zombie_bow</th>\n",
       "      <th>zon_bow</th>\n",
       "      <th>zone_bow</th>\n",
       "      <th>zuck_bow</th>\n",
       "      <th>zuckerberg_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   'auto_bow  'best_bow  'd_bow  'grossly_bow  'highly_bow  'large_bow  \\\n",
       "0        0.0        0.0     0.0           0.0          0.0           0   \n",
       "1        0.0        0.0     0.0           0.0          0.0           0   \n",
       "2        0.0        0.0     0.0           0.0          0.0           0   \n",
       "3        0.0        0.0     0.0           0.0          0.0           0   \n",
       "4        0.0        0.0     0.0           0.0          0.0           0   \n",
       "\n",
       "   'let_bow  'll_bow  'm_bow  'outperform_bow       ...        yoku_bow  \\\n",
       "0       0.0        0       0                0       ...             0.0   \n",
       "1       0.0        0       0                0       ...             0.0   \n",
       "2       0.0        0       0                0       ...             0.0   \n",
       "3       0.0        0       0                0       ...             0.0   \n",
       "4       0.0        0       0                0       ...             0.0   \n",
       "\n",
       "   zero_bow  zigzag_bow  zmh_bow  znga_bow  zombie_bow  zon_bow  zone_bow  \\\n",
       "0       0.0         0.0      0.0       0.0         0.0      0.0       0.0   \n",
       "1       0.0         0.0      0.0       0.0         0.0      0.0       0.0   \n",
       "2       0.0         0.0      0.0       0.0         0.0      0.0       0.0   \n",
       "3       0.0         0.0      0.0       0.0         0.0      0.0       0.0   \n",
       "4       0.0         0.0      0.0       0.0         0.0      0.0       0.0   \n",
       "\n",
       "   zuck_bow  zuckerberg_bow  \n",
       "0       0.0             0.0  \n",
       "1       0.0             0.0  \n",
       "2       0.0             0.0  \n",
       "3       0.0             0.0  \n",
       "4       0.0             0.0  \n",
       "\n",
       "[5 rows x 2240 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'auto_bow</th>\n",
       "      <th>'best_bow</th>\n",
       "      <th>'d_bow</th>\n",
       "      <th>'grossly_bow</th>\n",
       "      <th>'highly_bow</th>\n",
       "      <th>'large_bow</th>\n",
       "      <th>'let_bow</th>\n",
       "      <th>'ll_bow</th>\n",
       "      <th>'m_bow</th>\n",
       "      <th>'outperform_bow</th>\n",
       "      <th>...</th>\n",
       "      <th>yoku_bow</th>\n",
       "      <th>zero_bow</th>\n",
       "      <th>zigzag_bow</th>\n",
       "      <th>zmh_bow</th>\n",
       "      <th>znga_bow</th>\n",
       "      <th>zombie_bow</th>\n",
       "      <th>zon_bow</th>\n",
       "      <th>zone_bow</th>\n",
       "      <th>zuck_bow</th>\n",
       "      <th>zuckerberg_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   'auto_bow  'best_bow  'd_bow  'grossly_bow  'highly_bow  'large_bow  \\\n",
       "0        0.0        0.0     0.0           0.0          0.0           0   \n",
       "1        0.0        0.0     0.0           0.0          0.0           0   \n",
       "2        0.0        0.0     0.0           0.0          0.0           0   \n",
       "3        0.0        0.0     0.0           0.0          0.0           0   \n",
       "4        0.0        0.0     0.0           0.0          0.0           0   \n",
       "\n",
       "   'let_bow  'll_bow  'm_bow  'outperform_bow       ...        yoku_bow  \\\n",
       "0       0.0        0       0                0       ...             0.0   \n",
       "1       0.0        0       0                0       ...             0.0   \n",
       "2       0.0        0       0                0       ...             0.0   \n",
       "3       0.0        0       0                0       ...             0.0   \n",
       "4       0.0        0       0                0       ...             0.0   \n",
       "\n",
       "   zero_bow  zigzag_bow  zmh_bow  znga_bow  zombie_bow  zon_bow  zone_bow  \\\n",
       "0       0.0         0.0      0.0       0.0         0.0      0.0       0.0   \n",
       "1       0.0         0.0      0.0       0.0         0.0      0.0       0.0   \n",
       "2       0.0         0.0      0.0       0.0         0.0      0.0       0.0   \n",
       "3       0.0         0.0      0.0       0.0         0.0      0.0       0.0   \n",
       "4       0.0         0.0      0.0       0.0         0.0      0.0       0.0   \n",
       "\n",
       "   zuck_bow  zuckerberg_bow  \n",
       "0       0.0             0.0  \n",
       "1       0.0             0.0  \n",
       "2       0.0             0.0  \n",
       "3       0.0             0.0  \n",
       "4       0.0             0.0  \n",
       "\n",
       "[5 rows x 2240 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Organize our data for training\n",
    "X = train.drop([\"y\"], axis=1)\n",
    "Y = train[\"y\"]\n",
    "x_test = test.drop([\"y\"], axis=1)\n",
    "X, X_Val, Y, Y_Val = train_test_split(X, Y)\n",
    "print(type(Y_Val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= 1275 Y= 425 X_val= 1275 Y_val= 425\n"
     ]
    }
   ],
   "source": [
    "print(\"X=\",len(X),\"Y=\", len(X_Val),\"X_val=\", len(Y),\"Y_val=\", len(Y_Val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1251   -0.528\n",
       "1018    0.311\n",
       "481     0.415\n",
       "1465    0.579\n",
       "814    -0.329\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,11)],\n",
    "'colsample_bytree':[i/10.0 for i in range(6,11)], 'max_depth': [2,3,4]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=-1, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'min_child_weight': [4, 5], 'gamma': [0.3, 0.4, 0.5], 'subsample': [0.6, 0.7, 0.8, 0.9, 1.0], 'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0], 'max_depth': [2, 3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize XGB and GridSearch\n",
    "xgb = XGBRegressor(nthread=-1) \n",
    "\n",
    "grid = GridSearchCV(xgb, params)\n",
    "grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34274347426351115\n"
     ]
    }
   ],
   "source": [
    "# Print the r2 score\n",
    "print(r2_score(Y_Val, grid.best_estimator_.predict(X_Val))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the file\n",
    "y_test = grid.best_estimator_.predict(x_test)\n",
    "results_df = pd.DataFrame(data={'y':y_test}) \n",
    "#ids = test_df[\"ID\"]\n",
    "ids=bow_test.index\n",
    "joined = pd.DataFrame(ids).join(results_df)\n",
    "joined.to_csv(\"mercedes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [425, 799]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-c84a5ec1280f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_Val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 181\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [425, 799]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(Y_Val, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_io.TextIOWrapper'>\n"
     ]
    }
   ],
   "source": [
    "#load file data into dictionnary \n",
    "with open('Microblog_Trialdata.json') as json_data:\n",
    "    print(type(json_data))\n",
    "    data_dict = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

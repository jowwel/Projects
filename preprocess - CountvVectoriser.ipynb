{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import time\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import regexp_tokenize, wordpunct_tokenize,blankline_tokenize\n",
    "from nltk import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import json\n",
    "import re as regex\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterData_Initialize():\n",
    "    data = []\n",
    "    processed_data = []\n",
    "    wordlist = []\n",
    "\n",
    "    featureList = []\n",
    "    fea_vect=[]\n",
    "    \n",
    "    data_model = None\n",
    "    data_labels = None\n",
    "    is_testing = False\n",
    "    \n",
    "    def initialize(self, csv_file, is_testing_set=False, from_cached=None):\n",
    "        if from_cached is not None:\n",
    "            #self.data_model = pd.read_csv(from_cached)\n",
    "            self.data_model = pd.read_json(from_cached)\n",
    "\n",
    "            return\n",
    "\n",
    "        self.is_testing = is_testing_set\n",
    "\n",
    "        if not is_testing_set:\n",
    "            #self.data = pd.read_csv(csv_file, header=0, names=[\"id\", \"emotion\", \"text\"])\n",
    "            self.data = pd.read_json(csv_file)\n",
    "\n",
    "            #self.data = self.data[self.data[\"emotion\"].isin([\"positive\", \"negative\", \"neutral\"])]\n",
    "        \n",
    "\n",
    "        self.processed_data = self.data\n",
    "        self.wordlist = []\n",
    "        self.data_model = None\n",
    "        self.data_labels = None\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def do_process(self):\n",
    "        start_time = time.time()\n",
    "        def stem_and_join(row,stemmer=nltk.PorterStemmer()):\n",
    "            row[\"spans\"] = list(map(lambda str: stemmer.stem(str.lower()), row[\"spans\"]))\n",
    "            return row\n",
    "    \n",
    "        def tokenize_grams(row):\n",
    "                #remove numbers\n",
    "                def remove_numbers(text):\n",
    "                    return re.sub(r'\\d+', '', text)\n",
    "             \n",
    "                def to_lower(text):\n",
    "                    return text.lower()\n",
    "\n",
    "                #20 Function to remove whitespace\n",
    "                def remove_whitespace(text):\n",
    "                    return \" \".join(text.split())\n",
    "\n",
    "                # Function to remove punctuations\n",
    "                def remove_punctuations(text):\n",
    "                    text=re.sub(r'[?|*|.|!|+|-]',r'',text)\n",
    "                    words = nltk.word_tokenize(text)\n",
    "                    punt_removed = [w for w in words if w.lower() not in string.punctuation]\n",
    "                    return \" \".join(punt_removed)\n",
    "#30\n",
    "\n",
    "                # Function to remove stop words\n",
    "                def remove_stopwords(text, lang='english'):\n",
    "                        \n",
    "\n",
    "                    stop_words = set(stopwords.words('english'))\n",
    "                    word_tokens = word_tokenize(text)\n",
    "                    #filtered_sentence = [w for w in word_tokens if ((not w in stop_words) or (w in whitelist))]\n",
    "                    filtered_sentence = []\n",
    "                    for w in word_tokens:\n",
    "                        if (w not in stop_words):\n",
    "                            filtered_sentence.append(w)\n",
    "                \n",
    "                    ch=\" \".join(filtered_sentence)\n",
    "\n",
    "                    return ch\n",
    "#40\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # Function to extract n-grams from text\n",
    "                def get_ngrams(text, n):\n",
    "\n",
    "                    n_grams = ngrams(nltk.word_tokenize(text), n)\n",
    "                    list_grams=[ ' '.join(grams) for grams in n_grams]\n",
    "                    return list_grams\n",
    "\n",
    "\n",
    "                # Function to apply lemmatization to a list of words\n",
    "                def words_lemmatizer(text, encoding=\"utf8\"):\n",
    "                    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "                    words = nltk.word_tokenize(text)\n",
    "                    lemma_words = []\n",
    "                    wl = WordNetLemmatizer()\n",
    "                    for word in words:\n",
    "                        pos = find_pos(word)\n",
    "                        lemma_words.append(wl.lemmatize(word, pos))\n",
    "                    return \" \".join(lemma_words)\n",
    "\n",
    "                # Function to find part of speech tag for a word\n",
    "                def find_pos(word):\n",
    "                    # Part of Speech constants\n",
    "                    # ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v'\n",
    "   \n",
    "                    pos = nltk.pos_tag(nltk.word_tokenize(word))[0][1]\n",
    "                    # Adjective tags - 'JJ', 'JJR', 'JJS'\n",
    "                    if pos.lower()[0] == 'j':\n",
    "                        return 'a'\n",
    "                    # Adverb tags - 'RB', 'RBR', 'RBS'\n",
    "                    elif pos.lower()[0] == 'r':\n",
    "                        return 'r'\n",
    "                    # Verb tags - 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'\n",
    "                    elif pos.lower()[0] == 'v':\n",
    "                        return 'v'\n",
    "                    # Noun tags - 'NN', 'NNS', 'NNP', 'NNPS'\n",
    "                    else:\n",
    "                        return 'n'\n",
    "    \n",
    "            \n",
    "                #convert to string\n",
    "                idx=row[\"spans\"]\n",
    "                #ch=\"\".join(x for x in idx if x)\n",
    "                ch=' '.join(idx)\n",
    "               \n",
    "    \n",
    "                \n",
    "                \n",
    "                #words_stemmer(ch, type=\"PorterStemmer\", lang=\"english\", encoding=\"utf8\")\n",
    "                #Convert to lower case\n",
    "                txt_num=remove_numbers(ch)\n",
    "\n",
    "                txt_low=to_lower(txt_num)\n",
    "                \n",
    "                txt_ws=remove_whitespace(txt_low)\n",
    "    \n",
    "\n",
    "                txt_pun=remove_punctuations(txt_ws)\n",
    "\n",
    "                #txt_final=remove_stopwords(txt_pun)\n",
    "\n",
    "                texte=words_lemmatizer(txt_pun)\n",
    "\n",
    "                n_grams=get_ngrams(texte, 1)\n",
    "\n",
    "                row[\"token_spans\"] = n_grams\n",
    "    \n",
    "                return row\n",
    "        #self.processed_data = self.processed_data.apply(stem_and_join, axis=1)\n",
    "        self.processed_data = self.processed_data.apply(tokenize_grams, axis=1)\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    \n",
    "\n",
    "    def build_wordlist(self, min_occurrences=0, max_occurences=500, stopwords=nltk.corpus.stopwords.words(\"english\"),\n",
    "                       ):\n",
    "        def get_tweets(data):\n",
    "            start_time = time.time()\n",
    "\n",
    "            tweets=list(data.processed_data.token_spans)\n",
    "    \n",
    "            list_tweet=[]\n",
    "            for i,chaine in enumerate(tweets):\n",
    "                ch=\" \".join(chaine)\n",
    "                list_tweet.append(ch)\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "            return list_tweet\n",
    "    \n",
    "        def get_top_n_words(corpus, n=None):\n",
    "   \n",
    "            vec = CountVectorizer().fit(corpus)\n",
    "            bag_of_words = vec.transform(corpus)\n",
    "            sum_words = bag_of_words.sum(axis=0) \n",
    "            words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "            words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "            return words_freq[:n]\n",
    "        #whitelist=[\"n't\",\"not\",\"below\"]\n",
    "        whitelist=[\"to\",\"on\",\"for\",\"up\",\"below\",\"short\",\"long\"]\n",
    "        self.wordlist = []\n",
    "        \"\"\"\n",
    "        corpus=get_tweets(self)\n",
    "        common_words = get_top_n_words(corpus)\n",
    "        word_df = pd.DataFrame(data={\"word\": [k for k, v in common_words],\n",
    "                                     \"occurrences\": [v for k, v in common_words]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "        \n",
    "        \n",
    "        word_df.to_csv(\"wordlist_count.csv\", index_label=\"idx\")\n",
    "        self.wordlist = [k for k, v in common_words]\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        words = Counter()\n",
    "      \n",
    "        for idx in self.processed_data.index:\n",
    "            words.update(self.processed_data.loc[idx, \"token_spans\"])\n",
    "\n",
    "        for idx, stop_word in enumerate(stopwords):\n",
    "            if stop_word not in whitelist:\n",
    "                del words[stop_word]\n",
    "        \n",
    "\n",
    "        \n",
    "                \n",
    "        print(words.most_common())\n",
    "        word_df = pd.DataFrame(data={\"word\": [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\n",
    "                                     \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "\n",
    "        word_df.to_csv(\"wordlist_copie.csv\", index_label=\"idx\")\n",
    "        self.wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]\n",
    "        \n",
    "        \n",
    "    def build_data_model(self):\n",
    "        label_column = []\n",
    "        Id_column=[\"ID\"]\n",
    "        label_column = [\"label\"]\n",
    "\n",
    "        columns = Id_column + label_column + list(\n",
    "            map(lambda w: w ,self.wordlist))\n",
    "        labels = []\n",
    "        rows = []\n",
    "        for idx in self.processed_data.index:\n",
    "            current_row = []\n",
    "\n",
    "            if True:\n",
    "                # add label\n",
    "                current_label = self.processed_data.loc[idx, \"sentiment score\"]\n",
    "                current_id = self.processed_data.loc[idx, \"id\"]\n",
    "                \n",
    "                labels.append(current_id)\n",
    "                labels.append(current_label)\n",
    "                \n",
    "                current_row.append(current_id)\n",
    "                current_row.append(current_label)\n",
    "\n",
    "            # add bag-of-words\n",
    "            tokens = set(self.processed_data.loc[idx, \"token_spans\"])\n",
    "            for _, word in enumerate(self.wordlist):\n",
    "                current_row.append(1 if word in tokens else 0)\n",
    "\n",
    "            rows.append(current_row)\n",
    "\n",
    "        self.data_model = pd.DataFrame(rows, columns=columns)\n",
    "        self.data_labels = pd.Series(labels)\n",
    "        return self.data_model, self.data_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterData_Initialize_test(TwitterData_Initialize):\n",
    "\n",
    "    \n",
    "    \n",
    "    def do_process(self):\n",
    "        def stem_and_join(row,stemmer=nltk.PorterStemmer()):\n",
    "            \n",
    "            row[\"spans\"] = list(map(lambda str: stemmer.stem(str.lower()), row[\"spans\"].split()))\n",
    "            return row\n",
    "    \n",
    "        def tokenize_grams(row):\n",
    "                #remove numbers\n",
    "                def remove_numbers(text):\n",
    "                    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "                def to_lower(text):\n",
    "                    return text.lower()\n",
    "                \n",
    "                #20 Function to remove whitespace\n",
    "                def remove_whitespace(text):\n",
    "                    return \" \".join(text.split())\n",
    "\n",
    "                # Function to remove punctuations\n",
    "                def remove_punctuations(text):\n",
    "                    text=re.sub(r'[?|*|.|!|+|-]',r'',text)\n",
    "\n",
    "                    words = nltk.word_tokenize(text)\n",
    "                    punt_removed = [w for w in words if w.lower() not in string.punctuation]\n",
    "                    return \" \".join(punt_removed)\n",
    "#30\n",
    "\n",
    "                # Function to remove stop words\n",
    "                def remove_stopwords(text, lang='english'):\n",
    "\n",
    "                    stop_words = set(stopwords.words('english'))\n",
    "                    word_tokens = word_tokenize(text)\n",
    "                    #filtered_sentence = [w for w in word_tokens if ((not w in stop_words) or (w in whitelist))]\n",
    "                    filtered_sentence = []\n",
    "                    for w in word_tokens:\n",
    "                        if (w not in stop_words):\n",
    "                            filtered_sentence.append(w)\n",
    "                \n",
    "                    ch=\" \".join(filtered_sentence)\n",
    "\n",
    "                    return ch\n",
    "#40\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # Function to extract n-grams from text\n",
    "                def get_ngrams(text, n):\n",
    "\n",
    "                    n_grams = ngrams(nltk.word_tokenize(text), n)\n",
    "                    list_grams=[ ' '.join(grams) for grams in n_grams]\n",
    "                    return list_grams\n",
    "\n",
    "\n",
    "                # Function to apply lemmatization to a list of words\n",
    "                def words_lemmatizer(text, encoding=\"utf8\"):\n",
    "                    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "                    words = nltk.word_tokenize(text)\n",
    "                    lemma_words = []\n",
    "                    wl = WordNetLemmatizer()\n",
    "                    for word in words:\n",
    "                        pos = find_pos(word)\n",
    "                        lemma_words.append(wl.lemmatize(word, pos))\n",
    "                    return \" \".join(lemma_words)\n",
    "\n",
    "                # Function to find part of speech tag for a word\n",
    "                def find_pos(word):\n",
    "                    # Part of Speech constants\n",
    "                    # ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v'\n",
    "   \n",
    "                    pos = nltk.pos_tag(nltk.word_tokenize(word))[0][1]\n",
    "                    # Adjective tags - 'JJ', 'JJR', 'JJS'\n",
    "                    if pos.lower()[0] == 'j':\n",
    "                        return 'a'\n",
    "                    # Adverb tags - 'RB', 'RBR', 'RBS'\n",
    "                    elif pos.lower()[0] == 'r':\n",
    "                        return 'r'\n",
    "                    # Verb tags - 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'\n",
    "                    elif pos.lower()[0] == 'v':\n",
    "                        return 'v'\n",
    "                    # Noun tags - 'NN', 'NNS', 'NNP', 'NNPS'\n",
    "                    else:\n",
    "                        return 'n'\n",
    "    \n",
    "            \n",
    "            \n",
    "                idx=row[\"spans\"]\n",
    "                ch=' '.join(idx)\n",
    "\n",
    "\n",
    "    \n",
    "                #words_stemmer(ch, type=\"PorterStemmer\", lang=\"english\", encoding=\"utf8\")\n",
    "                #Convert to lower case\n",
    "                txt_num=remove_numbers(ch)\n",
    "                \n",
    "                \n",
    "                txt_low=to_lower(txt_num)\n",
    "                \n",
    "                txt_ws=remove_whitespace(txt_low)\n",
    "                    \n",
    "    \n",
    "                txt_pun=remove_punctuations(txt_ws)\n",
    "        \n",
    "                #txt_final=remove_stopwords(txt_pun)\n",
    "\n",
    "                texte=words_lemmatizer(txt_pun)\n",
    "\n",
    "                n_grams=get_ngrams(texte, 1)\n",
    "                #print(\"list ngrams--------------\\n\",n_grams)\n",
    "\n",
    "                row[\"token_spans\"] = n_grams\n",
    "    \n",
    "                return row\n",
    "        #self.processed_data = self.processed_data.apply(stem_and_join, axis=1)\n",
    "        self.processed_data = self.processed_data.apply(tokenize_grams, axis=1)\n",
    "        \n",
    "    def build_wordlist(self, min_occurrences=0, max_occurences=500, stopwords=nltk.corpus.stopwords.words(\"english\"),\n",
    "                      ):\n",
    "        def get_tweets(data):\n",
    "            start_time = time.time()\n",
    "\n",
    "            tweets=list(data.processed_data.token_spans)\n",
    "    \n",
    "            list_tweet=[]\n",
    "            for i,chaine in enumerate(tweets):\n",
    "                ch=\" \".join(chaine)\n",
    "                list_tweet.append(ch)\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "            return list_tweet\n",
    "    \n",
    "        def get_top_n_words(corpus, n=None):\n",
    "   \n",
    "            vec = CountVectorizer().fit(corpus)\n",
    "            bag_of_words = vec.transform(corpus)\n",
    "            sum_words = bag_of_words.sum(axis=0) \n",
    "            words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "            words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "            return words_freq[:n]\n",
    "\n",
    "        whitelist=[\"to\",\"on\",\"for\",\"up\",\"below\",\"short\",\"long\"]\n",
    "        self.wordlist = []\n",
    "        \"\"\"\n",
    "        corpus=get_tweets(self)\n",
    "        common_words = get_top_n_words(corpus)\n",
    "        word_df = pd.DataFrame(data={\"word\": [k for k, v in common_words],\n",
    "                                     \"occurrences\": [v for k, v in common_words]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "        \n",
    "        \n",
    "        word_df.to_csv(\"wordlist_count_test.csv\", index_label=\"idx\")\n",
    "        self.wordlist = [k for k, v in common_words]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        words = Counter()\n",
    "      \n",
    "        for idx in self.processed_data.index:\n",
    "            words.update(self.processed_data.loc[idx, \"token_spans\"])\n",
    "\n",
    "        for idx, stop_word in enumerate(stopwords):\n",
    "            if stop_word not in whitelist:\n",
    "                del words[stop_word]\n",
    "        \n",
    "\n",
    "        \n",
    "                \n",
    "        print(words.most_common())\n",
    "\n",
    "        word_df = pd.DataFrame(data={\"word\": [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\n",
    "                                     \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "\n",
    "        word_df.to_csv(\"wordlist_test.csv\", index_label=\"idx\")\n",
    "        self.wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]\n",
    "        \n",
    "        \n",
    "    def build_data_model(self):\n",
    "        \n",
    "        label_id = [\"ID\"]\n",
    "\n",
    "        columns = label_id + list(\n",
    "            map(lambda w: w ,self.wordlist))\n",
    "        labels = []\n",
    "        rows = []\n",
    "        for idx in self.processed_data.index:\n",
    "            current_row = []\n",
    "            if True:\n",
    "                # add label\n",
    "                current_id = self.processed_data.loc[idx, \"id\"]\n",
    "                \n",
    "                labels.append(current_id)\n",
    "                \n",
    "                current_row.append(current_id)\n",
    "\n",
    "            \n",
    "\n",
    "            # add bag-of-words\n",
    "            tokens = set(self.processed_data.loc[idx, \"token_spans\"])\n",
    "            for _, word in enumerate(self.wordlist):\n",
    "                current_row.append(1 if word in tokens else 0)\n",
    "\n",
    "            rows.append(current_row)\n",
    "\n",
    "        self.data_model = pd.DataFrame(rows, columns=columns)\n",
    "        return self.data_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cashtag</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment score</th>\n",
       "      <th>source</th>\n",
       "      <th>spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$FB</td>\n",
       "      <td>719659409228451840</td>\n",
       "      <td>0.366</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[watching for bounce tomorrow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$LUV</td>\n",
       "      <td>719904304207962112</td>\n",
       "      <td>0.638</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[record number of passengers served in 2015]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$NFLX</td>\n",
       "      <td>5329774</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[out $NFLX -.35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$DIA</td>\n",
       "      <td>719891468173844480</td>\n",
       "      <td>0.460</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Looking for a strong bounce, Lunchtime rally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$PLUG</td>\n",
       "      <td>20091246</td>\n",
       "      <td>0.403</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Very intrigued with the technology and growth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>$GMCR</td>\n",
       "      <td>5819749</td>\n",
       "      <td>0.000</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[short worked, puts up]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>$IBM</td>\n",
       "      <td>709741154393133056</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[overbought]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>$JOSB</td>\n",
       "      <td>17892972</td>\n",
       "      <td>-0.546</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[absolute garbage still up, stores TOTALLY EMP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>$CSTM</td>\n",
       "      <td>709834259687710720</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Biggest Market Losers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>$PYPL</td>\n",
       "      <td>708481442079068160</td>\n",
       "      <td>0.408</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Love this company long time.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>$GOOGL</td>\n",
       "      <td>31971935</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[$GOOG $GOOGL would suck]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>$ENDP</td>\n",
       "      <td>710187873492983808</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[who won't pay anymore, REAL risk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>$XLI</td>\n",
       "      <td>13915103</td>\n",
       "      <td>0.025</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[No edge offered]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>$PCLN</td>\n",
       "      <td>10448993</td>\n",
       "      <td>0.486</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[runs into the 50sma on the acquisition news]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>$AA</td>\n",
       "      <td>24886266</td>\n",
       "      <td>0.308</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[t can't go down]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>$AAPL</td>\n",
       "      <td>12793642</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[now seems like its helping the downtrend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>$AAPL</td>\n",
       "      <td>9408369</td>\n",
       "      <td>0.461</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[mastered their supply chain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>$GOLD</td>\n",
       "      <td>719909604654624768</td>\n",
       "      <td>0.408</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Most bullish stocks on Twitter during this dip]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>$AMD</td>\n",
       "      <td>9674584</td>\n",
       "      <td>-0.699</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[big dumping, would not touch it for a while]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>$SPY</td>\n",
       "      <td>10041008</td>\n",
       "      <td>0.495</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[trade continuing very nicely from yesterday, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cashtag                  id  sentiment score      source  \\\n",
       "0      $FB  719659409228451840            0.366     twitter   \n",
       "1     $LUV  719904304207962112            0.638     twitter   \n",
       "2    $NFLX             5329774           -0.494  stocktwits   \n",
       "3     $DIA  719891468173844480            0.460     twitter   \n",
       "4    $PLUG            20091246            0.403  stocktwits   \n",
       "5    $GMCR             5819749            0.000  stocktwits   \n",
       "6     $IBM  709741154393133056           -0.296     twitter   \n",
       "7    $JOSB            17892972           -0.546  stocktwits   \n",
       "8    $CSTM  709834259687710720           -0.438     twitter   \n",
       "9    $PYPL  708481442079068160            0.408     twitter   \n",
       "10  $GOOGL            31971935           -0.398  stocktwits   \n",
       "11   $ENDP  710187873492983808           -0.349     twitter   \n",
       "12    $XLI            13915103            0.025  stocktwits   \n",
       "13   $PCLN            10448993            0.486  stocktwits   \n",
       "14     $AA            24886266            0.308  stocktwits   \n",
       "15   $AAPL            12793642           -0.372  stocktwits   \n",
       "16   $AAPL             9408369            0.461  stocktwits   \n",
       "17   $GOLD  719909604654624768            0.408     twitter   \n",
       "18    $AMD             9674584           -0.699  stocktwits   \n",
       "19    $SPY            10041008            0.495  stocktwits   \n",
       "\n",
       "                                                spans  \n",
       "0                      [watching for bounce tomorrow]  \n",
       "1        [record number of passengers served in 2015]  \n",
       "2                                    [out $NFLX -.35]  \n",
       "3   [Looking for a strong bounce, Lunchtime rally ...  \n",
       "4   [Very intrigued with the technology and growth...  \n",
       "5                             [short worked, puts up]  \n",
       "6                                        [overbought]  \n",
       "7   [absolute garbage still up, stores TOTALLY EMP...  \n",
       "8                             [Biggest Market Losers]  \n",
       "9                      [Love this company long time.]  \n",
       "10                          [$GOOG $GOOGL would suck]  \n",
       "11                 [who won't pay anymore, REAL risk]  \n",
       "12                                  [No edge offered]  \n",
       "13      [runs into the 50sma on the acquisition news]  \n",
       "14                                  [t can't go down]  \n",
       "15         [now seems like its helping the downtrend]  \n",
       "16                      [mastered their supply chain]  \n",
       "17   [Most bullish stocks on Twitter during this dip]  \n",
       "18      [big dumping, would not touch it for a while]  \n",
       "19  [trade continuing very nicely from yesterday, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TwitterData_Initialize()\n",
    "data.initialize(\"Microblog_Trainingdata.json\")\n",
    "\n",
    "data.processed_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 318.39482259750366 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cashtag</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment score</th>\n",
       "      <th>source</th>\n",
       "      <th>spans</th>\n",
       "      <th>token_spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$FB</td>\n",
       "      <td>719659409228451840</td>\n",
       "      <td>0.366</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[watching for bounce tomorrow]</td>\n",
       "      <td>[watch, for, bounce, tomorrow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$LUV</td>\n",
       "      <td>719904304207962112</td>\n",
       "      <td>0.638</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[record number of passengers served in 2015]</td>\n",
       "      <td>[record, number, of, passenger, serve, in]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$NFLX</td>\n",
       "      <td>5329774</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[out $NFLX -.35]</td>\n",
       "      <td>[out, nflx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$DIA</td>\n",
       "      <td>719891468173844480</td>\n",
       "      <td>0.460</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Looking for a strong bounce, Lunchtime rally ...</td>\n",
       "      <td>[look, for, a, strong, bounce, lunchtime, rall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$PLUG</td>\n",
       "      <td>20091246</td>\n",
       "      <td>0.403</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Very intrigued with the technology and growth...</td>\n",
       "      <td>[very, intrigue, with, the, technology, and, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>$GMCR</td>\n",
       "      <td>5819749</td>\n",
       "      <td>0.000</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[short worked, puts up]</td>\n",
       "      <td>[short, work, put, up]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>$IBM</td>\n",
       "      <td>709741154393133056</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[overbought]</td>\n",
       "      <td>[overbought]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>$JOSB</td>\n",
       "      <td>17892972</td>\n",
       "      <td>-0.546</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[absolute garbage still up, stores TOTALLY EMP...</td>\n",
       "      <td>[absolute, garbage, still, up, store, totally,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>$CSTM</td>\n",
       "      <td>709834259687710720</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Biggest Market Losers]</td>\n",
       "      <td>[big, market, loser]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>$PYPL</td>\n",
       "      <td>708481442079068160</td>\n",
       "      <td>0.408</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Love this company long time.]</td>\n",
       "      <td>[love, this, company, long, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>$GOOGL</td>\n",
       "      <td>31971935</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[$GOOG $GOOGL would suck]</td>\n",
       "      <td>[goog, googl, would, suck]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>$ENDP</td>\n",
       "      <td>710187873492983808</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[who won't pay anymore, REAL risk]</td>\n",
       "      <td>[who, wo, n't, pay, anymore, real, risk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>$XLI</td>\n",
       "      <td>13915103</td>\n",
       "      <td>0.025</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[No edge offered]</td>\n",
       "      <td>[no, edge, offer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>$PCLN</td>\n",
       "      <td>10448993</td>\n",
       "      <td>0.486</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[runs into the 50sma on the acquisition news]</td>\n",
       "      <td>[run, into, the, sma, on, the, acquisition, news]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>$AA</td>\n",
       "      <td>24886266</td>\n",
       "      <td>0.308</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[t can't go down]</td>\n",
       "      <td>[t, ca, n't, go, down]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>$AAPL</td>\n",
       "      <td>12793642</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[now seems like its helping the downtrend]</td>\n",
       "      <td>[now, seem, like, it, help, the, downtrend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>$AAPL</td>\n",
       "      <td>9408369</td>\n",
       "      <td>0.461</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[mastered their supply chain]</td>\n",
       "      <td>[master, their, supply, chain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>$GOLD</td>\n",
       "      <td>719909604654624768</td>\n",
       "      <td>0.408</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Most bullish stocks on Twitter during this dip]</td>\n",
       "      <td>[most, bullish, stock, on, twitter, during, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>$AMD</td>\n",
       "      <td>9674584</td>\n",
       "      <td>-0.699</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[big dumping, would not touch it for a while]</td>\n",
       "      <td>[big, dump, would, not, touch, it, for, a, while]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>$SPY</td>\n",
       "      <td>10041008</td>\n",
       "      <td>0.495</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[trade continuing very nicely from yesterday, ...</td>\n",
       "      <td>[trade, continue, very, nicely, from, yesterda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>$IDRA</td>\n",
       "      <td>20249627</td>\n",
       "      <td>0.306</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[in from 3.61]</td>\n",
       "      <td>[in, from]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>$ASMB</td>\n",
       "      <td>39047349</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Stochastic Overbought]</td>\n",
       "      <td>[stochastic, overbought]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>$RHT</td>\n",
       "      <td>711907079296933888</td>\n",
       "      <td>0.336</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Unusual call buying]</td>\n",
       "      <td>[unusual, call, buying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>$CHK</td>\n",
       "      <td>5364581</td>\n",
       "      <td>0.279</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[reserves are in decline]</td>\n",
       "      <td>[reserve, be, in, decline]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>$CELG</td>\n",
       "      <td>25816362</td>\n",
       "      <td>0.591</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[all on a longer-term, technical swing long ba...</td>\n",
       "      <td>[all, on, a, longerterm, technical, swing, lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>$CBPO</td>\n",
       "      <td>708960045799759872</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Insiders Are Selling]</td>\n",
       "      <td>[insider, be, sell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>$TSLA</td>\n",
       "      <td>719521470175522816</td>\n",
       "      <td>-0.514</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[What goes up...]</td>\n",
       "      <td>[what, go, up]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>$TSLA</td>\n",
       "      <td>719572690453934080</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[if $249.84 breaks we see $245 then $240]</td>\n",
       "      <td>[if, break, we, see, then]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>$BBRY</td>\n",
       "      <td>33458939</td>\n",
       "      <td>0.361</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[let's see a big bounce]</td>\n",
       "      <td>[let, 's, see, a, big, bounce]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>$FB</td>\n",
       "      <td>719547428924481536</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[I don't think it will move $FB in the short t...</td>\n",
       "      <td>[i, do, n't, think, it, will, move, fb, in, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>$HDGE</td>\n",
       "      <td>39047349</td>\n",
       "      <td>-0.385</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Stochastic Overbought]</td>\n",
       "      <td>[stochastic, overbought]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>$XBI</td>\n",
       "      <td>6783339</td>\n",
       "      <td>0.281</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Good to load up Be confident]</td>\n",
       "      <td>[good, to, load, up, be, confident]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>$RIG</td>\n",
       "      <td>5679790</td>\n",
       "      <td>-0.720</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Worst performers today,  $RIG -13%]</td>\n",
       "      <td>[bad, performer, today, rig]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>$HPCQ</td>\n",
       "      <td>708960045799759872</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Insiders Are Selling]</td>\n",
       "      <td>[insider, be, sell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>$FB</td>\n",
       "      <td>719849703106551808</td>\n",
       "      <td>0.365</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Pie In The Sky]</td>\n",
       "      <td>[pie, in, the, sky]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>$IWM</td>\n",
       "      <td>22957112</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Small caps threatening descending triangle br...</td>\n",
       "      <td>[small, cap, threaten, descend, triangle, brea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>$AMZN</td>\n",
       "      <td>719894972636512256</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Amazon has been selling surveillance cameras ...</td>\n",
       "      <td>[amazon, have, be, sell, surveillance, camera,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>$HTZ</td>\n",
       "      <td>719507659741872128</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[$HTZ, lower]</td>\n",
       "      <td>[htz, low]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>$SPY</td>\n",
       "      <td>5612699</td>\n",
       "      <td>0.412</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Don't hang your bull hat yet, Next week we wi...</td>\n",
       "      <td>[do, n't, hang, your, bull, hat, yet, next, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>$GOOGL</td>\n",
       "      <td>719560961879728128</td>\n",
       "      <td>0.465</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Alphabet Inc was just upgraded to buy]</td>\n",
       "      <td>[alphabet, inc, be, just, upgraded, to, buy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>$MU</td>\n",
       "      <td>719585607215808512</td>\n",
       "      <td>0.362</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Today I bought more]</td>\n",
       "      <td>[today, i, bought, more]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>$SBUX</td>\n",
       "      <td>709056556466200576</td>\n",
       "      <td>0.220</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[brings upscale concept]</td>\n",
       "      <td>[brings, upscale, concept]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>$AAPL</td>\n",
       "      <td>710143603524427776</td>\n",
       "      <td>0.365</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[looking for a sharp move up in equities]</td>\n",
       "      <td>[look, for, a, sharp, move, up, in, equity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>$AMRN</td>\n",
       "      <td>11845293</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[I'm betting over 52%]</td>\n",
       "      <td>[i, 'm, bet, over]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>$DUST</td>\n",
       "      <td>17553855</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[careful can reverse fast]</td>\n",
       "      <td>[careful, can, reverse, fast]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>$AAPL</td>\n",
       "      <td>719886818800463872</td>\n",
       "      <td>0.435</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[#OwnItDon'tTradeIt]</td>\n",
       "      <td>[ownitdon'ttradeit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>$PSXP</td>\n",
       "      <td>719732320404709376</td>\n",
       "      <td>0.414</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[TOP 5 STOCK PICKS]</td>\n",
       "      <td>[top, stock, pick]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>$OPK</td>\n",
       "      <td>5792305</td>\n",
       "      <td>0.471</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Major skin in the game...positive.]</td>\n",
       "      <td>[major, skin, in, the, gamepositive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>$TVIX</td>\n",
       "      <td>30158448</td>\n",
       "      <td>-0.589</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[100.0% increased bearish conversations]</td>\n",
       "      <td>[increase, bearish, conversation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>$AAPL</td>\n",
       "      <td>719489192078610432</td>\n",
       "      <td>-0.513</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Another Sell Rating, Sell Rating]</td>\n",
       "      <td>[another, sell, rating, sell, rating]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>$FOLD</td>\n",
       "      <td>11118210</td>\n",
       "      <td>-0.581</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[sold today]</td>\n",
       "      <td>[sell, today]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>$FB</td>\n",
       "      <td>719536774821867520</td>\n",
       "      <td>0.087</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Buy Call!]</td>\n",
       "      <td>[buy, call]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>$TSLA</td>\n",
       "      <td>719535349379284992</td>\n",
       "      <td>0.230</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Long, buying point]</td>\n",
       "      <td>[long, buying, point]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>$ETN</td>\n",
       "      <td>15658194</td>\n",
       "      <td>0.813</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[UPGRADE today by MS to overweight, Excellent ...</td>\n",
       "      <td>[upgrade, today, by, m, to, overweight, excell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>$OMER</td>\n",
       "      <td>22409313</td>\n",
       "      <td>0.380</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Buy the dip']</td>\n",
       "      <td>[buy, the, dip]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>$RIMM</td>\n",
       "      <td>7442585</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[So both call/put buyers are crushed]</td>\n",
       "      <td>[so, both, call/put, buyer, be, crush]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>$XOM</td>\n",
       "      <td>5430926</td>\n",
       "      <td>0.295</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Buy stop above 80]</td>\n",
       "      <td>[buy, stop, above]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>$HOT</td>\n",
       "      <td>719547552874512384</td>\n",
       "      <td>0.405</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Airplane And Hospitality Industries Set Their...</td>\n",
       "      <td>[airplane, and, hospitality, industry, set, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>$BBRY</td>\n",
       "      <td>18346099</td>\n",
       "      <td>0.296</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[nice bounce]</td>\n",
       "      <td>[nice, bounce]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>$AXP</td>\n",
       "      <td>709741154393133056</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[overbought]</td>\n",
       "      <td>[overbought]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cashtag                  id  sentiment score      source  \\\n",
       "0        $FB  719659409228451840            0.366     twitter   \n",
       "1       $LUV  719904304207962112            0.638     twitter   \n",
       "2      $NFLX             5329774           -0.494  stocktwits   \n",
       "3       $DIA  719891468173844480            0.460     twitter   \n",
       "4      $PLUG            20091246            0.403  stocktwits   \n",
       "5      $GMCR             5819749            0.000  stocktwits   \n",
       "6       $IBM  709741154393133056           -0.296     twitter   \n",
       "7      $JOSB            17892972           -0.546  stocktwits   \n",
       "8      $CSTM  709834259687710720           -0.438     twitter   \n",
       "9      $PYPL  708481442079068160            0.408     twitter   \n",
       "10    $GOOGL            31971935           -0.398  stocktwits   \n",
       "11     $ENDP  710187873492983808           -0.349     twitter   \n",
       "12      $XLI            13915103            0.025  stocktwits   \n",
       "13     $PCLN            10448993            0.486  stocktwits   \n",
       "14       $AA            24886266            0.308  stocktwits   \n",
       "15     $AAPL            12793642           -0.372  stocktwits   \n",
       "16     $AAPL             9408369            0.461  stocktwits   \n",
       "17     $GOLD  719909604654624768            0.408     twitter   \n",
       "18      $AMD             9674584           -0.699  stocktwits   \n",
       "19      $SPY            10041008            0.495  stocktwits   \n",
       "20     $IDRA            20249627            0.306  stocktwits   \n",
       "21     $ASMB            39047349           -0.385  stocktwits   \n",
       "22      $RHT  711907079296933888            0.336     twitter   \n",
       "23      $CHK             5364581            0.279  stocktwits   \n",
       "24     $CELG            25816362            0.591  stocktwits   \n",
       "25     $CBPO  708960045799759872           -0.351     twitter   \n",
       "26     $TSLA  719521470175522816           -0.514     twitter   \n",
       "27     $TSLA  719572690453934080           -0.519     twitter   \n",
       "28     $BBRY            33458939            0.361  stocktwits   \n",
       "29       $FB  719547428924481536           -0.042     twitter   \n",
       "...      ...                 ...              ...         ...   \n",
       "1670   $HDGE            39047349           -0.385  stocktwits   \n",
       "1671    $XBI             6783339            0.281  stocktwits   \n",
       "1672    $RIG             5679790           -0.720  stocktwits   \n",
       "1673   $HPCQ  708960045799759872           -0.351     twitter   \n",
       "1674     $FB  719849703106551808            0.365     twitter   \n",
       "1675    $IWM            22957112           -0.382  stocktwits   \n",
       "1676   $AMZN  719894972636512256           -0.186     twitter   \n",
       "1677    $HTZ  719507659741872128           -0.409     twitter   \n",
       "1678    $SPY             5612699            0.412  stocktwits   \n",
       "1679  $GOOGL  719560961879728128            0.465     twitter   \n",
       "1680     $MU  719585607215808512            0.362     twitter   \n",
       "1681   $SBUX  709056556466200576            0.220     twitter   \n",
       "1682   $AAPL  710143603524427776            0.365     twitter   \n",
       "1683   $AMRN            11845293           -0.248  stocktwits   \n",
       "1684   $DUST            17553855           -0.152  stocktwits   \n",
       "1685   $AAPL  719886818800463872            0.435     twitter   \n",
       "1686   $PSXP  719732320404709376            0.414     twitter   \n",
       "1687    $OPK             5792305            0.471  stocktwits   \n",
       "1688   $TVIX            30158448           -0.589  stocktwits   \n",
       "1689   $AAPL  719489192078610432           -0.513     twitter   \n",
       "1690   $FOLD            11118210           -0.581  stocktwits   \n",
       "1691     $FB  719536774821867520            0.087     twitter   \n",
       "1692   $TSLA  719535349379284992            0.230     twitter   \n",
       "1693    $ETN            15658194            0.813  stocktwits   \n",
       "1694   $OMER            22409313            0.380  stocktwits   \n",
       "1695   $RIMM             7442585           -0.126  stocktwits   \n",
       "1696    $XOM             5430926            0.295  stocktwits   \n",
       "1697    $HOT  719547552874512384            0.405     twitter   \n",
       "1698   $BBRY            18346099            0.296  stocktwits   \n",
       "1699    $AXP  709741154393133056           -0.296     twitter   \n",
       "\n",
       "                                                  spans  \\\n",
       "0                        [watching for bounce tomorrow]   \n",
       "1          [record number of passengers served in 2015]   \n",
       "2                                      [out $NFLX -.35]   \n",
       "3     [Looking for a strong bounce, Lunchtime rally ...   \n",
       "4     [Very intrigued with the technology and growth...   \n",
       "5                               [short worked, puts up]   \n",
       "6                                          [overbought]   \n",
       "7     [absolute garbage still up, stores TOTALLY EMP...   \n",
       "8                               [Biggest Market Losers]   \n",
       "9                        [Love this company long time.]   \n",
       "10                            [$GOOG $GOOGL would suck]   \n",
       "11                   [who won't pay anymore, REAL risk]   \n",
       "12                                    [No edge offered]   \n",
       "13        [runs into the 50sma on the acquisition news]   \n",
       "14                                    [t can't go down]   \n",
       "15           [now seems like its helping the downtrend]   \n",
       "16                        [mastered their supply chain]   \n",
       "17     [Most bullish stocks on Twitter during this dip]   \n",
       "18        [big dumping, would not touch it for a while]   \n",
       "19    [trade continuing very nicely from yesterday, ...   \n",
       "20                                       [in from 3.61]   \n",
       "21                              [Stochastic Overbought]   \n",
       "22                                [Unusual call buying]   \n",
       "23                            [reserves are in decline]   \n",
       "24    [all on a longer-term, technical swing long ba...   \n",
       "25                               [Insiders Are Selling]   \n",
       "26                                    [What goes up...]   \n",
       "27            [if $249.84 breaks we see $245 then $240]   \n",
       "28                             [let's see a big bounce]   \n",
       "29    [I don't think it will move $FB in the short t...   \n",
       "...                                                 ...   \n",
       "1670                            [Stochastic Overbought]   \n",
       "1671                     [Good to load up Be confident]   \n",
       "1672               [Worst performers today,  $RIG -13%]   \n",
       "1673                             [Insiders Are Selling]   \n",
       "1674                                   [Pie In The Sky]   \n",
       "1675  [Small caps threatening descending triangle br...   \n",
       "1676  [Amazon has been selling surveillance cameras ...   \n",
       "1677                                      [$HTZ, lower]   \n",
       "1678  [Don't hang your bull hat yet, Next week we wi...   \n",
       "1679            [Alphabet Inc was just upgraded to buy]   \n",
       "1680                              [Today I bought more]   \n",
       "1681                           [brings upscale concept]   \n",
       "1682          [looking for a sharp move up in equities]   \n",
       "1683                             [I'm betting over 52%]   \n",
       "1684                         [careful can reverse fast]   \n",
       "1685                               [#OwnItDon'tTradeIt]   \n",
       "1686                                [TOP 5 STOCK PICKS]   \n",
       "1687               [Major skin in the game...positive.]   \n",
       "1688           [100.0% increased bearish conversations]   \n",
       "1689                 [Another Sell Rating, Sell Rating]   \n",
       "1690                                       [sold today]   \n",
       "1691                                        [Buy Call!]   \n",
       "1692                               [Long, buying point]   \n",
       "1693  [UPGRADE today by MS to overweight, Excellent ...   \n",
       "1694                                     [Buy the dip']   \n",
       "1695              [So both call/put buyers are crushed]   \n",
       "1696                                [Buy stop above 80]   \n",
       "1697  [Airplane And Hospitality Industries Set Their...   \n",
       "1698                                      [nice bounce]   \n",
       "1699                                       [overbought]   \n",
       "\n",
       "                                            token_spans  \n",
       "0                        [watch, for, bounce, tomorrow]  \n",
       "1            [record, number, of, passenger, serve, in]  \n",
       "2                                           [out, nflx]  \n",
       "3     [look, for, a, strong, bounce, lunchtime, rall...  \n",
       "4     [very, intrigue, with, the, technology, and, g...  \n",
       "5                                [short, work, put, up]  \n",
       "6                                          [overbought]  \n",
       "7     [absolute, garbage, still, up, store, totally,...  \n",
       "8                                  [big, market, loser]  \n",
       "9                     [love, this, company, long, time]  \n",
       "10                           [goog, googl, would, suck]  \n",
       "11             [who, wo, n't, pay, anymore, real, risk]  \n",
       "12                                    [no, edge, offer]  \n",
       "13    [run, into, the, sma, on, the, acquisition, news]  \n",
       "14                               [t, ca, n't, go, down]  \n",
       "15          [now, seem, like, it, help, the, downtrend]  \n",
       "16                       [master, their, supply, chain]  \n",
       "17    [most, bullish, stock, on, twitter, during, th...  \n",
       "18    [big, dump, would, not, touch, it, for, a, while]  \n",
       "19    [trade, continue, very, nicely, from, yesterda...  \n",
       "20                                           [in, from]  \n",
       "21                             [stochastic, overbought]  \n",
       "22                              [unusual, call, buying]  \n",
       "23                           [reserve, be, in, decline]  \n",
       "24    [all, on, a, longerterm, technical, swing, lon...  \n",
       "25                                  [insider, be, sell]  \n",
       "26                                       [what, go, up]  \n",
       "27                           [if, break, we, see, then]  \n",
       "28                       [let, 's, see, a, big, bounce]  \n",
       "29    [i, do, n't, think, it, will, move, fb, in, th...  \n",
       "...                                                 ...  \n",
       "1670                           [stochastic, overbought]  \n",
       "1671                [good, to, load, up, be, confident]  \n",
       "1672                       [bad, performer, today, rig]  \n",
       "1673                                [insider, be, sell]  \n",
       "1674                                [pie, in, the, sky]  \n",
       "1675  [small, cap, threaten, descend, triangle, brea...  \n",
       "1676  [amazon, have, be, sell, surveillance, camera,...  \n",
       "1677                                         [htz, low]  \n",
       "1678  [do, n't, hang, your, bull, hat, yet, next, we...  \n",
       "1679       [alphabet, inc, be, just, upgraded, to, buy]  \n",
       "1680                           [today, i, bought, more]  \n",
       "1681                         [brings, upscale, concept]  \n",
       "1682        [look, for, a, sharp, move, up, in, equity]  \n",
       "1683                                 [i, 'm, bet, over]  \n",
       "1684                      [careful, can, reverse, fast]  \n",
       "1685                                [ownitdon'ttradeit]  \n",
       "1686                                 [top, stock, pick]  \n",
       "1687               [major, skin, in, the, gamepositive]  \n",
       "1688                  [increase, bearish, conversation]  \n",
       "1689              [another, sell, rating, sell, rating]  \n",
       "1690                                      [sell, today]  \n",
       "1691                                        [buy, call]  \n",
       "1692                              [long, buying, point]  \n",
       "1693  [upgrade, today, by, m, to, overweight, excell...  \n",
       "1694                                    [buy, the, dip]  \n",
       "1695             [so, both, call/put, buyer, be, crush]  \n",
       "1696                                 [buy, stop, above]  \n",
       "1697  [airplane, and, hospitality, industry, set, th...  \n",
       "1698                                     [nice, bounce]  \n",
       "1699                                       [overbought]  \n",
       "\n",
       "[1700 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.do_process()\n",
    "data.processed_data.head()\n",
    "data.processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_tweets(data):\n",
    "    start_time = time.time()\n",
    "\n",
    "    tweets=list(data.processed_data.token_spans)\n",
    "    \n",
    "    list_tweet=[]\n",
    "    for i,chaine in enumerate(tweets):\n",
    "        ch=\" \".join(chaine)\n",
    "        list_tweet.append(ch)\n",
    "    print(type(list_tweet))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    return list_tweet\n",
    "\n",
    "def get_count_vector(corpus):\n",
    "    vect = CountVectorizer()#appel à l'objet counvectorizer\n",
    "    vect.fit(corpus)#construction du vecteur de mots\n",
    "    #print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "    #print(\"Vocabulary content:\\n {}\".format(vect.vocabulary_))\n",
    "    vect.get_stop_words()\n",
    "    X = vect.transform(corpus)\n",
    "    #print(\"bag_of_words: {}\".format(repr(X)))\n",
    "    #print(\"Dense representation of bag_of_words:\\n{}\".format(\n",
    "    #X.toarray()))\n",
    "    return X\n",
    "   \n",
    "    \n",
    "#sparse_matrix = sparse.csr_matrix(bag_of_words)\n",
    "#print(\"\\nSciPy sparse CSR matrix:\\n{}\".format(sparse_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.366\n",
       "1       0.638\n",
       "2      -0.494\n",
       "3       0.460\n",
       "4       0.403\n",
       "5       0.000\n",
       "6      -0.296\n",
       "7      -0.546\n",
       "8      -0.438\n",
       "9       0.408\n",
       "10     -0.398\n",
       "11     -0.349\n",
       "12      0.025\n",
       "13      0.486\n",
       "14      0.308\n",
       "15     -0.372\n",
       "16      0.461\n",
       "17      0.408\n",
       "18     -0.699\n",
       "19      0.495\n",
       "20      0.306\n",
       "21     -0.385\n",
       "22      0.336\n",
       "23      0.279\n",
       "24      0.591\n",
       "25     -0.351\n",
       "26     -0.514\n",
       "27     -0.519\n",
       "28      0.361\n",
       "29     -0.042\n",
       "        ...  \n",
       "1670   -0.385\n",
       "1671    0.281\n",
       "1672   -0.720\n",
       "1673   -0.351\n",
       "1674    0.365\n",
       "1675   -0.382\n",
       "1676   -0.186\n",
       "1677   -0.409\n",
       "1678    0.412\n",
       "1679    0.465\n",
       "1680    0.362\n",
       "1681    0.220\n",
       "1682    0.365\n",
       "1683   -0.248\n",
       "1684   -0.152\n",
       "1685    0.435\n",
       "1686    0.414\n",
       "1687    0.471\n",
       "1688   -0.589\n",
       "1689   -0.513\n",
       "1690   -0.581\n",
       "1691    0.087\n",
       "1692    0.230\n",
       "1693    0.813\n",
       "1694    0.380\n",
       "1695   -0.126\n",
       "1696    0.295\n",
       "1697    0.405\n",
       "1698    0.296\n",
       "1699   -0.296\n",
       "Name: sentiment score, Length: 1700, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['sentiment score']  + [col for col in data.processed_data if col != 'sentiment score']\n",
    "data.processed_data=data.processed_data[cols]\n",
    "data.processed_data.iloc[:,0:]\n",
    "data.processed_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "--- 0.0015037059783935547 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\"\"\"train_data, test_data, y_train, y_test = train_test_split(data.processed_data.iloc[:,1:], data.processed_data.iloc[:,0],\n",
    "                                                   train_size=0.7)\n",
    "corpus=get_tweets(train_data)\n",
    "len(corpus)\"\"\"\n",
    "corpus=get_tweets(data)\n",
    "with open(\"tweets.txt\",\"w\") as fichier:\n",
    "    fichier.writelines(\"\\n\".join(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "be 292\n",
      "the 249\n",
      "to 235\n",
      "in 151\n",
      "on 133\n",
      "for 128\n",
      "stock 127\n",
      "of 110\n",
      "up 109\n",
      "short 96\n",
      "look 83\n",
      "and 83\n",
      "buy 77\n",
      "it 76\n",
      "long 74\n",
      "this 73\n",
      "today 68\n",
      "sell 66\n",
      "high 66\n",
      "call 60\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    \"\"\"\n",
    "    List the top n words in a vocabulary according to occurrence in a text corpus.\n",
    "    \n",
    "    get_top_n_words([\"I love Python\", \"Python is a language programming\", \"Hello world\", \"I love the world\"]) -> \n",
    "    [('python', 2),\n",
    "     ('world', 2),\n",
    "     ('love', 2),\n",
    "     ('hello', 1),\n",
    "     ('is', 1),\n",
    "     ('programming', 1),\n",
    "     ('the', 1),\n",
    "     ('language', 1)]\n",
    "    \"\"\"\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    print(vec.stop_words_)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "\n",
    "\n",
    "common_words = get_top_n_words(corpus, 20)\n",
    "for word, freq in common_words:\n",
    "    print(word, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "--- 0.0015292167663574219 seconds ---\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "corpus=get_tweets(data)\n",
    "lst=get_top_n_words(corpus)\n",
    "with open(\"top_words.csv\", \"w\",newline='') as fichier:\n",
    "    c = csv.writer(fichier,delimiter=\",\")\n",
    "\n",
    "    for l in lst:\n",
    "        c.writerow(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = TwitterData_Initialize_test()\n",
    "data_test.initialize(\"Microblog_Trialdata.json\")\n",
    "\n",
    "data_test.processed_data.head()\n",
    "data_test.do_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train=get_count_vector(corpus)\n",
    "X_train.toarray()\n",
    "y_train=data.processed_data[\"sentiment score\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=0.7, gamma=0.3, learning_rate=0.1,\n",
      "       max_delta_step=0, max_depth=4, min_child_weight=4, missing=None,\n",
      "       n_estimators=100, n_jobs=1, nthread=None, objective='reg:linear',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=0.8)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import model_selection, preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "params={'colsample_bytree': 1.0, 'gamma': 0.3, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.8}\n",
    "#Fitting XGB regressor \n",
    "model = xgb.XGBRegressor(max_depth=4, min_child_weight= 4,gamma=0.3,subsample=0.8,colsample_bytree=0.7)\n",
    "model.fit(X_train,y_train)\n",
    "#bst = xgb.train(param, dtrain,)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "--- 0.0010027885437011719 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['put on a little f short',\n",
       " 'short some',\n",
       " 'buying opportunity',\n",
       " 'scale up on long position',\n",
       " 'it time to sell bank',\n",
       " 'enter long',\n",
       " 'picked some up',\n",
       " 'time to accumulate for a long position far more upside than downside',\n",
       " 'look for a strong bounce lunchtime rally come',\n",
       " 'very intrigue with the technology and growth potential',\n",
       " 'short work put up',\n",
       " 'big market loser',\n",
       " 'goog googl would suck',\n",
       " 'buying sbux on dip',\n",
       " 'be a short below and be overbought',\n",
       " \"do n't put on a down little f short\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus=get_tweets(data_test)\n",
    "test_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "short 5\n",
      "on 4\n",
      "put 3\n",
      "up 3\n",
      "long 3\n",
      "little 2\n",
      "some 2\n",
      "buying 2\n",
      "position 2\n",
      "time 2\n",
      "to 2\n",
      "for 2\n",
      "and 2\n",
      "be 2\n",
      "opportunity 1\n",
      "scale 1\n",
      "it 1\n",
      "sell 1\n",
      "bank 1\n",
      "enter 1\n"
     ]
    }
   ],
   "source": [
    "common_words = get_top_n_words(test_corpus, 20)\n",
    "for word, freq in common_words:\n",
    "    print(word, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=get_count_vector(test_corpus)\n",
    "y_test=data.processed_data[\"sentiment score\"].values\n",
    "X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499', 'f500', 'f501', 'f502', 'f503', 'f504', 'f505', 'f506', 'f507', 'f508', 'f509', 'f510', 'f511', 'f512', 'f513', 'f514', 'f515', 'f516', 'f517', 'f518', 'f519', 'f520', 'f521', 'f522', 'f523', 'f524', 'f525', 'f526', 'f527', 'f528', 'f529', 'f530', 'f531', 'f532', 'f533', 'f534', 'f535', 'f536', 'f537', 'f538', 'f539', 'f540', 'f541', 'f542', 'f543', 'f544', 'f545', 'f546', 'f547', 'f548', 'f549', 'f550', 'f551', 'f552', 'f553', 'f554', 'f555', 'f556', 'f557', 'f558', 'f559', 'f560', 'f561', 'f562', 'f563', 'f564', 'f565', 'f566', 'f567', 'f568', 'f569', 'f570', 'f571', 'f572', 'f573', 'f574', 'f575', 'f576', 'f577', 'f578', 'f579', 'f580', 'f581', 'f582', 'f583', 'f584', 'f585', 'f586', 'f587', 'f588', 'f589', 'f590', 'f591', 'f592', 'f593', 'f594', 'f595', 'f596', 'f597', 'f598', 'f599', 'f600', 'f601', 'f602', 'f603', 'f604', 'f605', 'f606', 'f607', 'f608', 'f609', 'f610', 'f611', 'f612', 'f613', 'f614', 'f615', 'f616', 'f617', 'f618', 'f619', 'f620', 'f621', 'f622', 'f623', 'f624', 'f625', 'f626', 'f627', 'f628', 'f629', 'f630', 'f631', 'f632', 'f633', 'f634', 'f635', 'f636', 'f637', 'f638', 'f639', 'f640', 'f641', 'f642', 'f643', 'f644', 'f645', 'f646', 'f647', 'f648', 'f649', 'f650', 'f651', 'f652', 'f653', 'f654', 'f655', 'f656', 'f657', 'f658', 'f659', 'f660', 'f661', 'f662', 'f663', 'f664', 'f665', 'f666', 'f667', 'f668', 'f669', 'f670', 'f671', 'f672', 'f673', 'f674', 'f675', 'f676', 'f677', 'f678', 'f679', 'f680', 'f681', 'f682', 'f683', 'f684', 'f685', 'f686', 'f687', 'f688', 'f689', 'f690', 'f691', 'f692', 'f693', 'f694', 'f695', 'f696', 'f697', 'f698', 'f699', 'f700', 'f701', 'f702', 'f703', 'f704', 'f705', 'f706', 'f707', 'f708', 'f709', 'f710', 'f711', 'f712', 'f713', 'f714', 'f715', 'f716', 'f717', 'f718', 'f719', 'f720', 'f721', 'f722', 'f723', 'f724', 'f725', 'f726', 'f727', 'f728', 'f729', 'f730', 'f731', 'f732', 'f733', 'f734', 'f735', 'f736', 'f737', 'f738', 'f739', 'f740', 'f741', 'f742', 'f743', 'f744', 'f745', 'f746', 'f747', 'f748', 'f749', 'f750', 'f751', 'f752', 'f753', 'f754', 'f755', 'f756', 'f757', 'f758', 'f759', 'f760', 'f761', 'f762', 'f763', 'f764', 'f765', 'f766', 'f767', 'f768', 'f769', 'f770', 'f771', 'f772', 'f773', 'f774', 'f775', 'f776', 'f777', 'f778', 'f779', 'f780', 'f781', 'f782', 'f783', 'f784', 'f785', 'f786', 'f787', 'f788', 'f789', 'f790', 'f791', 'f792', 'f793', 'f794', 'f795', 'f796', 'f797', 'f798', 'f799', 'f800', 'f801', 'f802', 'f803', 'f804', 'f805', 'f806', 'f807', 'f808', 'f809', 'f810', 'f811', 'f812', 'f813', 'f814', 'f815', 'f816', 'f817', 'f818', 'f819', 'f820', 'f821', 'f822', 'f823', 'f824', 'f825', 'f826', 'f827', 'f828', 'f829', 'f830', 'f831', 'f832', 'f833', 'f834', 'f835', 'f836', 'f837', 'f838', 'f839', 'f840', 'f841', 'f842', 'f843', 'f844', 'f845', 'f846', 'f847', 'f848', 'f849', 'f850', 'f851', 'f852', 'f853', 'f854', 'f855', 'f856', 'f857', 'f858', 'f859', 'f860', 'f861', 'f862', 'f863', 'f864', 'f865', 'f866', 'f867', 'f868', 'f869', 'f870', 'f871', 'f872', 'f873', 'f874', 'f875', 'f876', 'f877', 'f878', 'f879', 'f880', 'f881', 'f882', 'f883', 'f884', 'f885', 'f886', 'f887', 'f888', 'f889', 'f890', 'f891', 'f892', 'f893', 'f894', 'f895', 'f896', 'f897', 'f898', 'f899', 'f900', 'f901', 'f902', 'f903', 'f904', 'f905', 'f906', 'f907', 'f908', 'f909', 'f910', 'f911', 'f912', 'f913', 'f914', 'f915', 'f916', 'f917', 'f918', 'f919', 'f920', 'f921', 'f922', 'f923', 'f924', 'f925', 'f926', 'f927', 'f928', 'f929', 'f930', 'f931', 'f932', 'f933', 'f934', 'f935', 'f936', 'f937', 'f938', 'f939', 'f940', 'f941', 'f942', 'f943', 'f944', 'f945', 'f946', 'f947', 'f948', 'f949', 'f950', 'f951', 'f952', 'f953', 'f954', 'f955', 'f956', 'f957', 'f958', 'f959', 'f960', 'f961', 'f962', 'f963', 'f964', 'f965', 'f966', 'f967', 'f968', 'f969', 'f970', 'f971', 'f972', 'f973', 'f974', 'f975', 'f976', 'f977', 'f978', 'f979', 'f980', 'f981', 'f982', 'f983', 'f984', 'f985', 'f986', 'f987', 'f988', 'f989', 'f990', 'f991', 'f992', 'f993', 'f994', 'f995', 'f996', 'f997', 'f998', 'f999', 'f1000', 'f1001', 'f1002', 'f1003', 'f1004', 'f1005', 'f1006', 'f1007', 'f1008', 'f1009', 'f1010', 'f1011', 'f1012', 'f1013', 'f1014', 'f1015', 'f1016', 'f1017', 'f1018', 'f1019', 'f1020', 'f1021', 'f1022', 'f1023', 'f1024', 'f1025', 'f1026', 'f1027', 'f1028', 'f1029', 'f1030', 'f1031', 'f1032', 'f1033', 'f1034', 'f1035', 'f1036', 'f1037', 'f1038', 'f1039', 'f1040', 'f1041', 'f1042', 'f1043', 'f1044', 'f1045', 'f1046', 'f1047', 'f1048', 'f1049', 'f1050', 'f1051', 'f1052', 'f1053', 'f1054', 'f1055', 'f1056', 'f1057', 'f1058', 'f1059', 'f1060', 'f1061', 'f1062', 'f1063', 'f1064', 'f1065', 'f1066', 'f1067', 'f1068', 'f1069', 'f1070', 'f1071', 'f1072', 'f1073', 'f1074', 'f1075', 'f1076', 'f1077', 'f1078', 'f1079', 'f1080', 'f1081', 'f1082', 'f1083', 'f1084', 'f1085', 'f1086', 'f1087', 'f1088', 'f1089', 'f1090', 'f1091', 'f1092', 'f1093', 'f1094', 'f1095', 'f1096', 'f1097', 'f1098', 'f1099', 'f1100', 'f1101', 'f1102', 'f1103', 'f1104', 'f1105', 'f1106', 'f1107', 'f1108', 'f1109', 'f1110', 'f1111', 'f1112', 'f1113', 'f1114', 'f1115', 'f1116', 'f1117', 'f1118', 'f1119', 'f1120', 'f1121', 'f1122', 'f1123', 'f1124', 'f1125', 'f1126', 'f1127', 'f1128', 'f1129', 'f1130', 'f1131', 'f1132', 'f1133', 'f1134', 'f1135', 'f1136', 'f1137', 'f1138', 'f1139', 'f1140', 'f1141', 'f1142', 'f1143', 'f1144', 'f1145', 'f1146', 'f1147', 'f1148', 'f1149', 'f1150', 'f1151', 'f1152', 'f1153', 'f1154', 'f1155', 'f1156', 'f1157', 'f1158', 'f1159', 'f1160', 'f1161', 'f1162', 'f1163', 'f1164', 'f1165', 'f1166', 'f1167', 'f1168', 'f1169', 'f1170', 'f1171', 'f1172', 'f1173', 'f1174', 'f1175', 'f1176', 'f1177', 'f1178', 'f1179', 'f1180', 'f1181', 'f1182', 'f1183', 'f1184', 'f1185', 'f1186', 'f1187', 'f1188', 'f1189', 'f1190', 'f1191', 'f1192', 'f1193', 'f1194', 'f1195', 'f1196', 'f1197', 'f1198', 'f1199', 'f1200', 'f1201', 'f1202', 'f1203', 'f1204', 'f1205', 'f1206', 'f1207', 'f1208', 'f1209', 'f1210', 'f1211', 'f1212', 'f1213', 'f1214', 'f1215', 'f1216', 'f1217', 'f1218', 'f1219', 'f1220', 'f1221', 'f1222', 'f1223', 'f1224', 'f1225', 'f1226', 'f1227', 'f1228', 'f1229', 'f1230', 'f1231', 'f1232', 'f1233', 'f1234', 'f1235', 'f1236', 'f1237', 'f1238', 'f1239', 'f1240', 'f1241', 'f1242', 'f1243', 'f1244', 'f1245', 'f1246', 'f1247', 'f1248', 'f1249', 'f1250', 'f1251', 'f1252', 'f1253', 'f1254', 'f1255', 'f1256', 'f1257', 'f1258', 'f1259', 'f1260', 'f1261', 'f1262', 'f1263', 'f1264', 'f1265', 'f1266', 'f1267', 'f1268', 'f1269', 'f1270', 'f1271', 'f1272', 'f1273', 'f1274', 'f1275', 'f1276', 'f1277', 'f1278', 'f1279', 'f1280', 'f1281', 'f1282', 'f1283', 'f1284', 'f1285', 'f1286', 'f1287', 'f1288', 'f1289', 'f1290', 'f1291', 'f1292', 'f1293', 'f1294', 'f1295', 'f1296', 'f1297', 'f1298', 'f1299', 'f1300', 'f1301', 'f1302', 'f1303', 'f1304', 'f1305', 'f1306', 'f1307', 'f1308', 'f1309', 'f1310', 'f1311', 'f1312', 'f1313', 'f1314', 'f1315', 'f1316', 'f1317', 'f1318', 'f1319', 'f1320', 'f1321', 'f1322', 'f1323', 'f1324', 'f1325', 'f1326', 'f1327', 'f1328', 'f1329', 'f1330', 'f1331', 'f1332', 'f1333', 'f1334', 'f1335', 'f1336', 'f1337', 'f1338', 'f1339', 'f1340', 'f1341', 'f1342', 'f1343', 'f1344', 'f1345', 'f1346', 'f1347', 'f1348', 'f1349', 'f1350', 'f1351', 'f1352', 'f1353', 'f1354', 'f1355', 'f1356', 'f1357', 'f1358', 'f1359', 'f1360', 'f1361', 'f1362', 'f1363', 'f1364', 'f1365', 'f1366', 'f1367', 'f1368', 'f1369', 'f1370', 'f1371', 'f1372', 'f1373', 'f1374', 'f1375', 'f1376', 'f1377', 'f1378', 'f1379', 'f1380', 'f1381', 'f1382', 'f1383', 'f1384', 'f1385', 'f1386', 'f1387', 'f1388', 'f1389', 'f1390', 'f1391', 'f1392', 'f1393', 'f1394', 'f1395', 'f1396', 'f1397', 'f1398', 'f1399', 'f1400', 'f1401', 'f1402', 'f1403', 'f1404', 'f1405', 'f1406', 'f1407', 'f1408', 'f1409', 'f1410', 'f1411', 'f1412', 'f1413', 'f1414', 'f1415', 'f1416', 'f1417', 'f1418', 'f1419', 'f1420', 'f1421', 'f1422', 'f1423', 'f1424', 'f1425', 'f1426', 'f1427', 'f1428', 'f1429', 'f1430', 'f1431', 'f1432', 'f1433', 'f1434', 'f1435', 'f1436', 'f1437', 'f1438', 'f1439', 'f1440', 'f1441', 'f1442', 'f1443', 'f1444', 'f1445', 'f1446', 'f1447', 'f1448', 'f1449', 'f1450', 'f1451', 'f1452', 'f1453', 'f1454', 'f1455', 'f1456', 'f1457', 'f1458', 'f1459', 'f1460', 'f1461', 'f1462', 'f1463', 'f1464', 'f1465', 'f1466', 'f1467', 'f1468', 'f1469', 'f1470', 'f1471', 'f1472', 'f1473', 'f1474', 'f1475', 'f1476', 'f1477', 'f1478', 'f1479', 'f1480', 'f1481', 'f1482', 'f1483', 'f1484', 'f1485', 'f1486', 'f1487', 'f1488', 'f1489', 'f1490', 'f1491', 'f1492', 'f1493', 'f1494', 'f1495', 'f1496', 'f1497', 'f1498', 'f1499', 'f1500', 'f1501', 'f1502', 'f1503', 'f1504', 'f1505', 'f1506', 'f1507', 'f1508', 'f1509', 'f1510', 'f1511', 'f1512', 'f1513', 'f1514', 'f1515', 'f1516', 'f1517', 'f1518', 'f1519', 'f1520', 'f1521', 'f1522', 'f1523', 'f1524', 'f1525', 'f1526', 'f1527', 'f1528', 'f1529', 'f1530', 'f1531', 'f1532', 'f1533', 'f1534', 'f1535', 'f1536', 'f1537', 'f1538', 'f1539', 'f1540', 'f1541', 'f1542', 'f1543', 'f1544', 'f1545', 'f1546', 'f1547', 'f1548', 'f1549', 'f1550', 'f1551', 'f1552', 'f1553', 'f1554', 'f1555', 'f1556', 'f1557', 'f1558', 'f1559', 'f1560', 'f1561', 'f1562', 'f1563', 'f1564', 'f1565', 'f1566', 'f1567', 'f1568', 'f1569', 'f1570', 'f1571', 'f1572', 'f1573', 'f1574', 'f1575', 'f1576', 'f1577', 'f1578', 'f1579', 'f1580', 'f1581', 'f1582', 'f1583', 'f1584', 'f1585', 'f1586', 'f1587', 'f1588', 'f1589', 'f1590', 'f1591', 'f1592', 'f1593', 'f1594', 'f1595', 'f1596', 'f1597', 'f1598', 'f1599', 'f1600', 'f1601', 'f1602', 'f1603', 'f1604', 'f1605', 'f1606', 'f1607', 'f1608', 'f1609', 'f1610', 'f1611', 'f1612', 'f1613', 'f1614', 'f1615', 'f1616', 'f1617', 'f1618', 'f1619', 'f1620', 'f1621', 'f1622', 'f1623', 'f1624', 'f1625', 'f1626', 'f1627', 'f1628', 'f1629', 'f1630', 'f1631', 'f1632', 'f1633', 'f1634', 'f1635', 'f1636', 'f1637', 'f1638', 'f1639', 'f1640', 'f1641', 'f1642', 'f1643', 'f1644', 'f1645', 'f1646', 'f1647', 'f1648', 'f1649', 'f1650', 'f1651', 'f1652', 'f1653', 'f1654', 'f1655', 'f1656', 'f1657', 'f1658', 'f1659', 'f1660', 'f1661', 'f1662', 'f1663', 'f1664', 'f1665', 'f1666', 'f1667', 'f1668', 'f1669', 'f1670', 'f1671', 'f1672', 'f1673', 'f1674', 'f1675', 'f1676', 'f1677', 'f1678', 'f1679', 'f1680', 'f1681', 'f1682', 'f1683', 'f1684', 'f1685', 'f1686', 'f1687', 'f1688', 'f1689', 'f1690', 'f1691', 'f1692', 'f1693', 'f1694', 'f1695', 'f1696', 'f1697', 'f1698', 'f1699', 'f1700', 'f1701', 'f1702', 'f1703', 'f1704', 'f1705', 'f1706', 'f1707', 'f1708', 'f1709', 'f1710', 'f1711', 'f1712', 'f1713', 'f1714', 'f1715', 'f1716', 'f1717', 'f1718', 'f1719', 'f1720', 'f1721', 'f1722', 'f1723', 'f1724', 'f1725', 'f1726', 'f1727', 'f1728', 'f1729', 'f1730', 'f1731', 'f1732', 'f1733', 'f1734', 'f1735', 'f1736', 'f1737', 'f1738', 'f1739', 'f1740', 'f1741', 'f1742', 'f1743', 'f1744', 'f1745', 'f1746', 'f1747', 'f1748', 'f1749', 'f1750', 'f1751', 'f1752', 'f1753', 'f1754', 'f1755', 'f1756', 'f1757', 'f1758', 'f1759', 'f1760', 'f1761', 'f1762', 'f1763', 'f1764', 'f1765', 'f1766', 'f1767', 'f1768', 'f1769', 'f1770', 'f1771', 'f1772', 'f1773', 'f1774', 'f1775', 'f1776', 'f1777', 'f1778', 'f1779', 'f1780', 'f1781', 'f1782', 'f1783', 'f1784', 'f1785', 'f1786', 'f1787', 'f1788', 'f1789', 'f1790', 'f1791', 'f1792', 'f1793', 'f1794', 'f1795', 'f1796', 'f1797', 'f1798', 'f1799', 'f1800', 'f1801', 'f1802', 'f1803', 'f1804', 'f1805', 'f1806', 'f1807', 'f1808', 'f1809', 'f1810', 'f1811', 'f1812', 'f1813', 'f1814', 'f1815', 'f1816', 'f1817', 'f1818', 'f1819', 'f1820', 'f1821', 'f1822', 'f1823', 'f1824', 'f1825', 'f1826', 'f1827', 'f1828', 'f1829', 'f1830', 'f1831', 'f1832', 'f1833', 'f1834', 'f1835', 'f1836', 'f1837', 'f1838', 'f1839', 'f1840', 'f1841', 'f1842', 'f1843', 'f1844', 'f1845', 'f1846', 'f1847', 'f1848', 'f1849', 'f1850', 'f1851', 'f1852', 'f1853', 'f1854', 'f1855', 'f1856', 'f1857', 'f1858', 'f1859', 'f1860', 'f1861', 'f1862', 'f1863', 'f1864', 'f1865', 'f1866', 'f1867', 'f1868', 'f1869', 'f1870', 'f1871', 'f1872', 'f1873', 'f1874', 'f1875', 'f1876', 'f1877', 'f1878', 'f1879', 'f1880', 'f1881', 'f1882', 'f1883', 'f1884', 'f1885', 'f1886', 'f1887', 'f1888', 'f1889', 'f1890', 'f1891', 'f1892', 'f1893', 'f1894', 'f1895', 'f1896', 'f1897', 'f1898', 'f1899', 'f1900', 'f1901', 'f1902', 'f1903', 'f1904', 'f1905', 'f1906', 'f1907', 'f1908', 'f1909', 'f1910', 'f1911', 'f1912', 'f1913', 'f1914', 'f1915', 'f1916', 'f1917', 'f1918', 'f1919', 'f1920', 'f1921', 'f1922', 'f1923', 'f1924'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53']\nexpected f1321, f1134, f1429, f1924, f1791, f1340, f148, f1496, f1423, f162, f891, f948, f847, f1234, f1259, f639, f1456, f909, f521, f217, f1274, f1693, f600, f1643, f165, f782, f296, f1230, f994, f1379, f569, f329, f1503, f1325, f1414, f1381, f1411, f1010, f1880, f1527, f1176, f645, f1512, f748, f112, f638, f1563, f1685, f1231, f435, f196, f966, f1789, f91, f271, f317, f1221, f754, f1408, f1756, f1829, f853, f570, f469, f691, f1584, f1876, f949, f1696, f1462, f1445, f1824, f355, f1454, f1654, f1243, f1076, f833, f749, f654, f1917, f1384, f331, f881, f494, f387, f1612, f1647, f88, f752, f1281, f1479, f467, f362, f1473, f172, f265, f902, f1506, f1078, f890, f1718, f1189, f734, f1297, f1427, f802, f1902, f211, f386, f1872, f308, f1750, f1241, f404, f1426, f1528, f1443, f147, f1579, f764, f1383, f1211, f1372, f1349, f1715, f1490, f839, f486, f473, f707, f1921, f405, f1649, f1097, f1110, f1535, f1075, f1335, f164, f354, f973, f1341, f1444, f301, f1850, f1296, f1406, f1757, f1113, f1504, f1289, f358, f140, f1015, f1899, f240, f1458, f573, f611, f1673, f1227, f1575, f100, f904, f1792, f1544, f113, f1807, f1595, f73, f755, f394, f829, f595, f1597, f500, f998, f62, f1755, f670, f1328, f678, f1364, f862, f348, f1747, f629, f633, f888, f898, f632, f835, f1763, f1625, f1105, f1489, f391, f1276, f101, f1223, f1120, f729, f170, f1324, f451, f631, f1923, f820, f77, f294, f260, f340, f914, f1780, f1278, f1323, f173, f374, f545, f1250, f426, f880, f1080, f577, f1699, f1773, f550, f1658, f1376, f139, f241, f1596, f1439, f1368, f843, f1815, f1374, f388, f254, f83, f922, f1079, f663, f262, f1635, f177, f585, f1416, f300, f925, f983, f1401, f195, f491, f110, f341, f130, f498, f1362, f171, f1631, f141, f1096, f349, f131, f151, f593, f216, f773, f1375, f1793, f1816, f1183, f1246, f1122, f1160, f92, f1068, f1494, f246, f1877, f906, f269, f982, f1531, f1864, f259, f1071, f844, f978, f1571, f1705, f185, f529, f566, f86, f567, f588, f1865, f367, f1510, f234, f963, f1738, f1237, f1357, f382, f336, f1778, f827, f1485, f1180, f1209, f433, f714, f704, f249, f1882, f143, f581, f1488, f1735, f1839, f412, f1001, f1210, f1607, f1866, f1004, f415, f1135, f1396, f1100, f1452, f1794, f1430, f428, f1014, f1774, f1831, f999, f1697, f1382, f939, f971, f916, f1620, f957, f1903, f95, f525, f178, f128, f397, f443, f1889, f1533, f186, f1378, f572, f1190, f204, f499, f1459, f989, f59, f760, f1616, f1642, f800, f87, f1795, f607, f1029, f61, f873, f1175, f926, f1043, f680, f324, f896, f85, f1875, f55, f1254, f1619, f1140, f1901, f1562, f1059, f1214, f1320, f936, f821, f1630, f1469, f497, f739, f205, f1205, f883, f368, f1194, f213, f928, f993, f1336, f184, f122, f1476, f617, f1040, f1057, f379, f1731, f1150, f915, f310, f137, f1390, f1719, f810, f1139, f482, f1002, f236, f1207, f1759, f560, f788, f1777, f850, f1501, f1475, f235, f1639, f1005, f1857, f1208, f156, f1727, f1819, f1911, f1177, f306, f1301, f743, f449, f781, f264, f855, f1867, f1790, f1787, f708, f202, f277, f1851, f132, f1609, f1322, f1251, f429, f818, f825, f1821, f393, f123, f565, f345, f136, f1567, f159, f1600, f543, f373, f892, f1822, f227, f1646, f1804, f327, f1569, f1687, f1094, f1525, f1118, f168, f959, f1313, f886, f1351, f392, f1884, f514, f1085, f380, f647, f414, f1252, f669, f70, f268, f1082, f1011, f1367, f1702, f1392, f1446, f64, f602, f244, f290, f1353, f919, f852, f157, f57, f487, f1131, f472, f520, f1282, f1783, f1332, f390, f477, f1652, f605, f1644, f1257, f1598, f672, f1292, f1560, f231, f1007, f1391, f779, f339, f790, f1587, f461, f1225, f857, f1700, f1152, f279, f378, f549, f1591, f870, f1386, f783, f1370, f1518, f200, f1840, f884, f695, f209, f1409, f1692, f1087, f1463, f453, f1151, f1863, f702, f699, f623, f997, f1812, f666, f1215, f1309, f207, f501, f452, f1509, f1377, f1892, f958, f1064, f1887, f813, f526, f991, f82, f161, f267, f1447, f517, f1402, f1659, f622, f1258, f1146, f1657, f1552, f1073, f1077, f1665, f627, f442, f1602, f1590, f1615, f582, f1045, f1363, f203, f667, f90, f1287, f576, f650, f197, f1808, f399, f1166, f1235, f1457, f1610, f134, f1310, f1786, f1862, f601, f519, f923, f552, f1834, f138, f1505, f688, f536, f1148, f1754, f955, f942, f439, f1311, f561, f1922, f934, f1706, f1881, f239, f1062, f1299, f454, f280, f1188, f1604, f1730, f1856, f1095, f275, f1173, f1772, f1052, f1912, f107, f1720, f1187, f293, f215, f1172, f1515, f1016, f1508, f815, f1047, f1797, f297, f559, f1124, f175, f1713, f208, f895, f427, f791, f831, f557, f1593, f1848, f969, f361, f1860, f214, f126, f988, f1785, f696, f1548, f1074, f868, f1449, f1044, f1198, f889, f539, f718, f1585, f1907, f1686, f270, f142, f553, f751, f1219, f796, f660, f343, f940, f1879, f1883, f1736, f967, f753, f121, f946, f127, f425, f1008, f1154, f72, f366, f726, f1671, f869, f224, f795, f662, f1174, f1464, f322, f981, f1389, f785, f767, f1186, f1767, f1112, f1828, f1415, f1539, f193, f485, f465, f1648, f710, f1272, f1760, f1216, f1039, f837, f665, f798, f799, f1107, f530, f1830, f1285, f312, f1893, f1532, f1119, f823, f1849, f376, f929, f921, f1694, f505, f879, f67, f568, f1380, f1908, f1801, f1852, f410, f152, f1885, f845, f1667, f1603, f643, f321, f1636, f1915, f1333, f93, f1129, f1070, f1395, f824, f1847, f656, f1136, f586, f1069, f1169, f1776, f863, f1453, f518, f603, f1589, f1083, f1197, f1050, f1660, f1450, f762, f977, f1319, f1573, f1133, f116, f1405, f698, f849, f1181, f344, f905, f816, f1418, f284, f1111, f1523, f445, f759, f325, f1141, f534, f675, f1574, f1817, f625, f830, f575, f1387, f1632, f1675, f538, f333, f1125, f420, f508, f1128, f792, f346, f1222, f1300, f1279, f1145, f864, f154, f1618, f229, f218, f867, f1868, f1428, f1538, f228, f1012, f664, f169, f1130, f1486, f1358, f634, f1611, f747, f1058, f996, f894, f1895, f1690, f1674, f1664, f1261, f860, f1799, f1536, f774, f932, f1437, f1583, f556, f1572, f580, f396, f1343, f222, f416, f502, f564, f848, f621, f338, f1670, f1870, f302, f1116, f908, f1624, f684, f353, f794, f766, f1142, f819, f1467, f166, f1264, f1455, f1286, f1782, f933, f1637, f1586, f1919, f247, f1499, f728, f1669, f1744, f1465, f1034, f716, f1483, f1497, f865, f1153, f1092, f257, f1549, f1689, f1400, f828, f1542, f1441, f927, f1334, f1565, f233, f1835, f78, f417, f701, f1346, f1491, f1581, f1861, f732, f1373, f626, f765, f793, f1098, f274, f1904, f723, f431, f899, f1920, f155, f987, f1784, f1627, f176, f851, f1721, f589, f1265, f641, f1283, f334, f424, f1103, f111, f163, f182, f1106, f446, f1714, f630, f102, f544, f741, f266, f771, f369, f711, f1298, f801, f1617, f980, f1268, f941, f1745, f283, f990, f1366, f1114, f1035, f299, f278, f1613, f846, f1751, f192, f952, f179, f776, f1555, f1691, f1640, f118, f1517, f887, f1304, f1240, f1213, f1739, f1338, f912, f401, f1424, f187, f524, f481, f104, f432, f1493, f253, f1472, f1683, f1060, f423, f1480, f436, f1650, f1460, f703, f206, f648, f974, f1638, f79, f1171, f733, f1337, f1568, f673, f1203, f574, f363, f1417, f289, f804, f189, f1582, f1681, f421, f1315, f383, f58, f1051, f1540, f384, f856, f583, f649, f592, f692, f872, f1091, f920, f935, f858, f531, f1155, f968, f1633, f1570, f746, f768, f992, f1339, f1796, f686, f1028, f438, f1266, f1749, f757, f1054, f221, f303, f149, f377, f1229, f1206, f554, f979, f1024, f1916, f444, f406, f1534, f1121, f1056, f307, f295, f1818, f281, f1554, f311, f558, f459, f579, f1629, f1018, f402, f685, f1762, f389, f761, f964, f1308, f591, f907, f65, f1236, f1477, f408, f1844, f1023, f1752, f1147, f1020, f1695, f1312, f507, f1663, f1906, f727, f893, f599, f1156, f1825, f1053, f1273, f1270, f304, f1284, f901, f1269, f854, f1788, f943, f1093, f398, f683, f1419, f1682, f1743, f1046, f1803, f316, f780, f145, f1436, f1137, f1360, f1327, f1537, f1679, f1399, f1561, f1448, f697, f174, f995, f838, f1487, f1495, f1032, f1081, f1161, f1742, f199, f784, f1117, f1814, f1084, f181, f1578, f590, f232, f1407, f1524, f492, f219, f950, f1249, f1306, f1271, f522, f455, f286, f1677, f1470, f1645, f273, f495, f882, f194, f1342, f547, f1019, f1628, f437, f251, f677, f1030, f1329, f413, f1193, f466, f986, f606, f1042, f1432, f1891, f1859, f717, f117, f903, f951, f1003, f385, f532, f1295, f1307, f528, f1886, f742, f261, f463, f220, f705, f1293, f332, f1195, f1126, f1592, f1543, f1653, f1516, f1144, f109, f98, f1247, f460, f537, f1878, f1500, f1746, f1072, f1874, f1041, f786, f1165, f1498, f610, f1900, f1843, f66, f447, f69, f900, f1688, f1369, f618, f183, f1022, f108, f523, f1709, f861, f1403, f458, f272, f1471, f1708, f1725, f1918, f1841, f841, f245, f191, f859, f1680, f1354, f1138, f651, f681, f330, f1260, f1179, f1733, f1000, f99, f474, f1232, f1666, f1317, f1086, f1275, f944, f1255, f1132, f84, f158, f1371, f1846, f1164, f1546, f652, f1614, f1897, f60, f1556, f1806, f226, f1710, f1393, f448, f725, f826, f1017, f1511, f1805, f1910, f509, f712, f775, f1502, f120, f571, f411, f133, f756, f811, f1200, f1212, f1256, f970, f319, f787, f679, f1557, f318, f619, f1769, f1201, f400, f1810, f1355, f911, f1672, f1433, f806, f1425, f809, f419, f1031, f1356, f1242, f1027, f1063, f878, f1826, f359, f671, f114, f146, f1601, f440, f1199, f840, f1758, f1833, f1290, f1599, f328, f1398, f1217, f464, f74, f1580, f668, f1191, f94, f1202, f212, f1741, f1033, f613, f1768, f984, f1606, f636, f1732, f1009, f1823, f370, f255, f1365, f918, f945, f1238, f1149, f1224, f832, f313, f1434, f1890, f1634, f540, f740, f594, f124, f738, f1239, f1101, f640, f960, f1314, f628, f97, f615, f653, f1065, f871, f931, f1013, f1869, f1541, f364, f1853, f1798, f506, f938, f291, f1845, f1676, f1204, f1421, f457, f772, f450, f512, f471, f258, f527, f542, f1623, f511, f1734, f1588, f335, f1779, f1244, f515, f736, f1192, f1551, f1684, f842, f1302, f1896, f1253, f285, f256, f1775, f476, f533, f1553, f1608, f1753, f225, f693, f135, f616, f352, f1090, f694, f350, f360, f803, f778, f1726, f745, f63, f953, f797, f713, f720, f1422, f96, f1764, f1461, f1520, f1656, f298, f1712, f1717, f814, f1507, f735, f750, f758, f658, f1316, f287, f1550, f1157, f597, f1178, f409, f975, f1740, f690, f563, f924, f1184, f1350, f769, f1530, f876, f737, f1800, f105, f548, f1802, f80, f1115, f1661, f874, f1559, f789, f1109, f709, f1641, f972, f777, f238, f1451, f1728, f730, f1345, f1233, f961, f1326, f1055, f342, f1678, f305, f1724, f1067, f1182, f320, f1104, f237, f356, f81, f808, f866, f1021, f763, f68, f635, f1163, f1413, f326, f609, f1218, f1420, f434, f657, f1127, f1348, f496, f153, f1577, f1545, f422, f1088, f56, f1478, f624, f1668, f490, f119, f1159, f1827, f468, f250, f1036, f483, f608, f1288, f1385, f1913, f724, f1526, f1168, f129, f1442, f930, f661, f1547, f76, f1513, f210, f288, f1842, f1352, f1914, f976, f188, f913, f1737, f1594, f190, f1294, f198, f503, f1621, f493, f1855, f1522, f1099, f430, f1492, f1280, f1871, f1162, f1888, f1894, f836, f659, f770, f89, f484, f1006, f407, f917, f1359, f947, f1410, f314, f1170, f1331, f1811, f103, f910, f614, f897, f395, f1521, f1748, f1781, f516, f612, f1558, f1388, f817, f372, f689, f1474, f584, f682, f1220, f700, f1909, f655, f1466, f1228, f1482, f562, f877, f1704, f719, f674, f1048, f1701, f578, f357, f637, f1226, f1397, f822, f403, f1347, f1481, f1529, f1651, f676, f1158, f722, f1248, f1440, f475, f1698, f1412, f1766, f1722, f347, f125, f1361, f555, f242, f1662, f201, f721, f144, f150, f115, f489, f1519, f1605, f292, f488, f598, f1854, f744, f587, f1049, f504, f1108, f1770, f1711, f1394, f1809, f418, f1102, f1303, f1196, f180, f1566, f546, f1484, f282, f1873, f1038, f510, f1723, f1123, f1037, f309, f1066, f1330, f706, f1262, f1514, f535, f642, f551, f1167, f1622, f644, f441, f1404, f1277, f1061, f807, f54, f106, f351, f1832, f1729, f1898, f1305, f75, f1143, f167, f252, f263, f541, f604, f1576, f956, f1838, f596, f1716, f230, f646, f1026, f1761, f375, f805, f1813, f812, f1905, f456, f1858, f620, f513, f276, f937, f71, f1267, f985, f470, f1431, f1837, f1263, f1468, f1438, f462, f1820, f965, f1318, f834, f1564, f875, f337, f365, f1025, f323, f371, f1707, f480, f962, f1185, f478, f1703, f1291, f1836, f1771, f1765, f731, f1435, f954, f1245, f715, f1655, f1626, f687, f885, f248, f381, f160, f1344, f315, f243, f223, f479, f1089 in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-479b4c32ae0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#old_pred=list(data_test.processed_data[\"sentiment score\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mold_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#final_df = pd.DataFrame(tweet_row, columns=labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfinal_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost-0.7-py3.6.egg\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[0;32m    310\u001b[0m         return self.get_booster().predict(test_dmatrix,\n\u001b[0;32m    311\u001b[0m                                           \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                                           ntree_limit=ntree_limit)\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost-0.7-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             \u001b[0moption_mask\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[1;36m0x10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost-0.7-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[1;32m-> 1308\u001b[1;33m                                             data.feature_names))\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499', 'f500', 'f501', 'f502', 'f503', 'f504', 'f505', 'f506', 'f507', 'f508', 'f509', 'f510', 'f511', 'f512', 'f513', 'f514', 'f515', 'f516', 'f517', 'f518', 'f519', 'f520', 'f521', 'f522', 'f523', 'f524', 'f525', 'f526', 'f527', 'f528', 'f529', 'f530', 'f531', 'f532', 'f533', 'f534', 'f535', 'f536', 'f537', 'f538', 'f539', 'f540', 'f541', 'f542', 'f543', 'f544', 'f545', 'f546', 'f547', 'f548', 'f549', 'f550', 'f551', 'f552', 'f553', 'f554', 'f555', 'f556', 'f557', 'f558', 'f559', 'f560', 'f561', 'f562', 'f563', 'f564', 'f565', 'f566', 'f567', 'f568', 'f569', 'f570', 'f571', 'f572', 'f573', 'f574', 'f575', 'f576', 'f577', 'f578', 'f579', 'f580', 'f581', 'f582', 'f583', 'f584', 'f585', 'f586', 'f587', 'f588', 'f589', 'f590', 'f591', 'f592', 'f593', 'f594', 'f595', 'f596', 'f597', 'f598', 'f599', 'f600', 'f601', 'f602', 'f603', 'f604', 'f605', 'f606', 'f607', 'f608', 'f609', 'f610', 'f611', 'f612', 'f613', 'f614', 'f615', 'f616', 'f617', 'f618', 'f619', 'f620', 'f621', 'f622', 'f623', 'f624', 'f625', 'f626', 'f627', 'f628', 'f629', 'f630', 'f631', 'f632', 'f633', 'f634', 'f635', 'f636', 'f637', 'f638', 'f639', 'f640', 'f641', 'f642', 'f643', 'f644', 'f645', 'f646', 'f647', 'f648', 'f649', 'f650', 'f651', 'f652', 'f653', 'f654', 'f655', 'f656', 'f657', 'f658', 'f659', 'f660', 'f661', 'f662', 'f663', 'f664', 'f665', 'f666', 'f667', 'f668', 'f669', 'f670', 'f671', 'f672', 'f673', 'f674', 'f675', 'f676', 'f677', 'f678', 'f679', 'f680', 'f681', 'f682', 'f683', 'f684', 'f685', 'f686', 'f687', 'f688', 'f689', 'f690', 'f691', 'f692', 'f693', 'f694', 'f695', 'f696', 'f697', 'f698', 'f699', 'f700', 'f701', 'f702', 'f703', 'f704', 'f705', 'f706', 'f707', 'f708', 'f709', 'f710', 'f711', 'f712', 'f713', 'f714', 'f715', 'f716', 'f717', 'f718', 'f719', 'f720', 'f721', 'f722', 'f723', 'f724', 'f725', 'f726', 'f727', 'f728', 'f729', 'f730', 'f731', 'f732', 'f733', 'f734', 'f735', 'f736', 'f737', 'f738', 'f739', 'f740', 'f741', 'f742', 'f743', 'f744', 'f745', 'f746', 'f747', 'f748', 'f749', 'f750', 'f751', 'f752', 'f753', 'f754', 'f755', 'f756', 'f757', 'f758', 'f759', 'f760', 'f761', 'f762', 'f763', 'f764', 'f765', 'f766', 'f767', 'f768', 'f769', 'f770', 'f771', 'f772', 'f773', 'f774', 'f775', 'f776', 'f777', 'f778', 'f779', 'f780', 'f781', 'f782', 'f783', 'f784', 'f785', 'f786', 'f787', 'f788', 'f789', 'f790', 'f791', 'f792', 'f793', 'f794', 'f795', 'f796', 'f797', 'f798', 'f799', 'f800', 'f801', 'f802', 'f803', 'f804', 'f805', 'f806', 'f807', 'f808', 'f809', 'f810', 'f811', 'f812', 'f813', 'f814', 'f815', 'f816', 'f817', 'f818', 'f819', 'f820', 'f821', 'f822', 'f823', 'f824', 'f825', 'f826', 'f827', 'f828', 'f829', 'f830', 'f831', 'f832', 'f833', 'f834', 'f835', 'f836', 'f837', 'f838', 'f839', 'f840', 'f841', 'f842', 'f843', 'f844', 'f845', 'f846', 'f847', 'f848', 'f849', 'f850', 'f851', 'f852', 'f853', 'f854', 'f855', 'f856', 'f857', 'f858', 'f859', 'f860', 'f861', 'f862', 'f863', 'f864', 'f865', 'f866', 'f867', 'f868', 'f869', 'f870', 'f871', 'f872', 'f873', 'f874', 'f875', 'f876', 'f877', 'f878', 'f879', 'f880', 'f881', 'f882', 'f883', 'f884', 'f885', 'f886', 'f887', 'f888', 'f889', 'f890', 'f891', 'f892', 'f893', 'f894', 'f895', 'f896', 'f897', 'f898', 'f899', 'f900', 'f901', 'f902', 'f903', 'f904', 'f905', 'f906', 'f907', 'f908', 'f909', 'f910', 'f911', 'f912', 'f913', 'f914', 'f915', 'f916', 'f917', 'f918', 'f919', 'f920', 'f921', 'f922', 'f923', 'f924', 'f925', 'f926', 'f927', 'f928', 'f929', 'f930', 'f931', 'f932', 'f933', 'f934', 'f935', 'f936', 'f937', 'f938', 'f939', 'f940', 'f941', 'f942', 'f943', 'f944', 'f945', 'f946', 'f947', 'f948', 'f949', 'f950', 'f951', 'f952', 'f953', 'f954', 'f955', 'f956', 'f957', 'f958', 'f959', 'f960', 'f961', 'f962', 'f963', 'f964', 'f965', 'f966', 'f967', 'f968', 'f969', 'f970', 'f971', 'f972', 'f973', 'f974', 'f975', 'f976', 'f977', 'f978', 'f979', 'f980', 'f981', 'f982', 'f983', 'f984', 'f985', 'f986', 'f987', 'f988', 'f989', 'f990', 'f991', 'f992', 'f993', 'f994', 'f995', 'f996', 'f997', 'f998', 'f999', 'f1000', 'f1001', 'f1002', 'f1003', 'f1004', 'f1005', 'f1006', 'f1007', 'f1008', 'f1009', 'f1010', 'f1011', 'f1012', 'f1013', 'f1014', 'f1015', 'f1016', 'f1017', 'f1018', 'f1019', 'f1020', 'f1021', 'f1022', 'f1023', 'f1024', 'f1025', 'f1026', 'f1027', 'f1028', 'f1029', 'f1030', 'f1031', 'f1032', 'f1033', 'f1034', 'f1035', 'f1036', 'f1037', 'f1038', 'f1039', 'f1040', 'f1041', 'f1042', 'f1043', 'f1044', 'f1045', 'f1046', 'f1047', 'f1048', 'f1049', 'f1050', 'f1051', 'f1052', 'f1053', 'f1054', 'f1055', 'f1056', 'f1057', 'f1058', 'f1059', 'f1060', 'f1061', 'f1062', 'f1063', 'f1064', 'f1065', 'f1066', 'f1067', 'f1068', 'f1069', 'f1070', 'f1071', 'f1072', 'f1073', 'f1074', 'f1075', 'f1076', 'f1077', 'f1078', 'f1079', 'f1080', 'f1081', 'f1082', 'f1083', 'f1084', 'f1085', 'f1086', 'f1087', 'f1088', 'f1089', 'f1090', 'f1091', 'f1092', 'f1093', 'f1094', 'f1095', 'f1096', 'f1097', 'f1098', 'f1099', 'f1100', 'f1101', 'f1102', 'f1103', 'f1104', 'f1105', 'f1106', 'f1107', 'f1108', 'f1109', 'f1110', 'f1111', 'f1112', 'f1113', 'f1114', 'f1115', 'f1116', 'f1117', 'f1118', 'f1119', 'f1120', 'f1121', 'f1122', 'f1123', 'f1124', 'f1125', 'f1126', 'f1127', 'f1128', 'f1129', 'f1130', 'f1131', 'f1132', 'f1133', 'f1134', 'f1135', 'f1136', 'f1137', 'f1138', 'f1139', 'f1140', 'f1141', 'f1142', 'f1143', 'f1144', 'f1145', 'f1146', 'f1147', 'f1148', 'f1149', 'f1150', 'f1151', 'f1152', 'f1153', 'f1154', 'f1155', 'f1156', 'f1157', 'f1158', 'f1159', 'f1160', 'f1161', 'f1162', 'f1163', 'f1164', 'f1165', 'f1166', 'f1167', 'f1168', 'f1169', 'f1170', 'f1171', 'f1172', 'f1173', 'f1174', 'f1175', 'f1176', 'f1177', 'f1178', 'f1179', 'f1180', 'f1181', 'f1182', 'f1183', 'f1184', 'f1185', 'f1186', 'f1187', 'f1188', 'f1189', 'f1190', 'f1191', 'f1192', 'f1193', 'f1194', 'f1195', 'f1196', 'f1197', 'f1198', 'f1199', 'f1200', 'f1201', 'f1202', 'f1203', 'f1204', 'f1205', 'f1206', 'f1207', 'f1208', 'f1209', 'f1210', 'f1211', 'f1212', 'f1213', 'f1214', 'f1215', 'f1216', 'f1217', 'f1218', 'f1219', 'f1220', 'f1221', 'f1222', 'f1223', 'f1224', 'f1225', 'f1226', 'f1227', 'f1228', 'f1229', 'f1230', 'f1231', 'f1232', 'f1233', 'f1234', 'f1235', 'f1236', 'f1237', 'f1238', 'f1239', 'f1240', 'f1241', 'f1242', 'f1243', 'f1244', 'f1245', 'f1246', 'f1247', 'f1248', 'f1249', 'f1250', 'f1251', 'f1252', 'f1253', 'f1254', 'f1255', 'f1256', 'f1257', 'f1258', 'f1259', 'f1260', 'f1261', 'f1262', 'f1263', 'f1264', 'f1265', 'f1266', 'f1267', 'f1268', 'f1269', 'f1270', 'f1271', 'f1272', 'f1273', 'f1274', 'f1275', 'f1276', 'f1277', 'f1278', 'f1279', 'f1280', 'f1281', 'f1282', 'f1283', 'f1284', 'f1285', 'f1286', 'f1287', 'f1288', 'f1289', 'f1290', 'f1291', 'f1292', 'f1293', 'f1294', 'f1295', 'f1296', 'f1297', 'f1298', 'f1299', 'f1300', 'f1301', 'f1302', 'f1303', 'f1304', 'f1305', 'f1306', 'f1307', 'f1308', 'f1309', 'f1310', 'f1311', 'f1312', 'f1313', 'f1314', 'f1315', 'f1316', 'f1317', 'f1318', 'f1319', 'f1320', 'f1321', 'f1322', 'f1323', 'f1324', 'f1325', 'f1326', 'f1327', 'f1328', 'f1329', 'f1330', 'f1331', 'f1332', 'f1333', 'f1334', 'f1335', 'f1336', 'f1337', 'f1338', 'f1339', 'f1340', 'f1341', 'f1342', 'f1343', 'f1344', 'f1345', 'f1346', 'f1347', 'f1348', 'f1349', 'f1350', 'f1351', 'f1352', 'f1353', 'f1354', 'f1355', 'f1356', 'f1357', 'f1358', 'f1359', 'f1360', 'f1361', 'f1362', 'f1363', 'f1364', 'f1365', 'f1366', 'f1367', 'f1368', 'f1369', 'f1370', 'f1371', 'f1372', 'f1373', 'f1374', 'f1375', 'f1376', 'f1377', 'f1378', 'f1379', 'f1380', 'f1381', 'f1382', 'f1383', 'f1384', 'f1385', 'f1386', 'f1387', 'f1388', 'f1389', 'f1390', 'f1391', 'f1392', 'f1393', 'f1394', 'f1395', 'f1396', 'f1397', 'f1398', 'f1399', 'f1400', 'f1401', 'f1402', 'f1403', 'f1404', 'f1405', 'f1406', 'f1407', 'f1408', 'f1409', 'f1410', 'f1411', 'f1412', 'f1413', 'f1414', 'f1415', 'f1416', 'f1417', 'f1418', 'f1419', 'f1420', 'f1421', 'f1422', 'f1423', 'f1424', 'f1425', 'f1426', 'f1427', 'f1428', 'f1429', 'f1430', 'f1431', 'f1432', 'f1433', 'f1434', 'f1435', 'f1436', 'f1437', 'f1438', 'f1439', 'f1440', 'f1441', 'f1442', 'f1443', 'f1444', 'f1445', 'f1446', 'f1447', 'f1448', 'f1449', 'f1450', 'f1451', 'f1452', 'f1453', 'f1454', 'f1455', 'f1456', 'f1457', 'f1458', 'f1459', 'f1460', 'f1461', 'f1462', 'f1463', 'f1464', 'f1465', 'f1466', 'f1467', 'f1468', 'f1469', 'f1470', 'f1471', 'f1472', 'f1473', 'f1474', 'f1475', 'f1476', 'f1477', 'f1478', 'f1479', 'f1480', 'f1481', 'f1482', 'f1483', 'f1484', 'f1485', 'f1486', 'f1487', 'f1488', 'f1489', 'f1490', 'f1491', 'f1492', 'f1493', 'f1494', 'f1495', 'f1496', 'f1497', 'f1498', 'f1499', 'f1500', 'f1501', 'f1502', 'f1503', 'f1504', 'f1505', 'f1506', 'f1507', 'f1508', 'f1509', 'f1510', 'f1511', 'f1512', 'f1513', 'f1514', 'f1515', 'f1516', 'f1517', 'f1518', 'f1519', 'f1520', 'f1521', 'f1522', 'f1523', 'f1524', 'f1525', 'f1526', 'f1527', 'f1528', 'f1529', 'f1530', 'f1531', 'f1532', 'f1533', 'f1534', 'f1535', 'f1536', 'f1537', 'f1538', 'f1539', 'f1540', 'f1541', 'f1542', 'f1543', 'f1544', 'f1545', 'f1546', 'f1547', 'f1548', 'f1549', 'f1550', 'f1551', 'f1552', 'f1553', 'f1554', 'f1555', 'f1556', 'f1557', 'f1558', 'f1559', 'f1560', 'f1561', 'f1562', 'f1563', 'f1564', 'f1565', 'f1566', 'f1567', 'f1568', 'f1569', 'f1570', 'f1571', 'f1572', 'f1573', 'f1574', 'f1575', 'f1576', 'f1577', 'f1578', 'f1579', 'f1580', 'f1581', 'f1582', 'f1583', 'f1584', 'f1585', 'f1586', 'f1587', 'f1588', 'f1589', 'f1590', 'f1591', 'f1592', 'f1593', 'f1594', 'f1595', 'f1596', 'f1597', 'f1598', 'f1599', 'f1600', 'f1601', 'f1602', 'f1603', 'f1604', 'f1605', 'f1606', 'f1607', 'f1608', 'f1609', 'f1610', 'f1611', 'f1612', 'f1613', 'f1614', 'f1615', 'f1616', 'f1617', 'f1618', 'f1619', 'f1620', 'f1621', 'f1622', 'f1623', 'f1624', 'f1625', 'f1626', 'f1627', 'f1628', 'f1629', 'f1630', 'f1631', 'f1632', 'f1633', 'f1634', 'f1635', 'f1636', 'f1637', 'f1638', 'f1639', 'f1640', 'f1641', 'f1642', 'f1643', 'f1644', 'f1645', 'f1646', 'f1647', 'f1648', 'f1649', 'f1650', 'f1651', 'f1652', 'f1653', 'f1654', 'f1655', 'f1656', 'f1657', 'f1658', 'f1659', 'f1660', 'f1661', 'f1662', 'f1663', 'f1664', 'f1665', 'f1666', 'f1667', 'f1668', 'f1669', 'f1670', 'f1671', 'f1672', 'f1673', 'f1674', 'f1675', 'f1676', 'f1677', 'f1678', 'f1679', 'f1680', 'f1681', 'f1682', 'f1683', 'f1684', 'f1685', 'f1686', 'f1687', 'f1688', 'f1689', 'f1690', 'f1691', 'f1692', 'f1693', 'f1694', 'f1695', 'f1696', 'f1697', 'f1698', 'f1699', 'f1700', 'f1701', 'f1702', 'f1703', 'f1704', 'f1705', 'f1706', 'f1707', 'f1708', 'f1709', 'f1710', 'f1711', 'f1712', 'f1713', 'f1714', 'f1715', 'f1716', 'f1717', 'f1718', 'f1719', 'f1720', 'f1721', 'f1722', 'f1723', 'f1724', 'f1725', 'f1726', 'f1727', 'f1728', 'f1729', 'f1730', 'f1731', 'f1732', 'f1733', 'f1734', 'f1735', 'f1736', 'f1737', 'f1738', 'f1739', 'f1740', 'f1741', 'f1742', 'f1743', 'f1744', 'f1745', 'f1746', 'f1747', 'f1748', 'f1749', 'f1750', 'f1751', 'f1752', 'f1753', 'f1754', 'f1755', 'f1756', 'f1757', 'f1758', 'f1759', 'f1760', 'f1761', 'f1762', 'f1763', 'f1764', 'f1765', 'f1766', 'f1767', 'f1768', 'f1769', 'f1770', 'f1771', 'f1772', 'f1773', 'f1774', 'f1775', 'f1776', 'f1777', 'f1778', 'f1779', 'f1780', 'f1781', 'f1782', 'f1783', 'f1784', 'f1785', 'f1786', 'f1787', 'f1788', 'f1789', 'f1790', 'f1791', 'f1792', 'f1793', 'f1794', 'f1795', 'f1796', 'f1797', 'f1798', 'f1799', 'f1800', 'f1801', 'f1802', 'f1803', 'f1804', 'f1805', 'f1806', 'f1807', 'f1808', 'f1809', 'f1810', 'f1811', 'f1812', 'f1813', 'f1814', 'f1815', 'f1816', 'f1817', 'f1818', 'f1819', 'f1820', 'f1821', 'f1822', 'f1823', 'f1824', 'f1825', 'f1826', 'f1827', 'f1828', 'f1829', 'f1830', 'f1831', 'f1832', 'f1833', 'f1834', 'f1835', 'f1836', 'f1837', 'f1838', 'f1839', 'f1840', 'f1841', 'f1842', 'f1843', 'f1844', 'f1845', 'f1846', 'f1847', 'f1848', 'f1849', 'f1850', 'f1851', 'f1852', 'f1853', 'f1854', 'f1855', 'f1856', 'f1857', 'f1858', 'f1859', 'f1860', 'f1861', 'f1862', 'f1863', 'f1864', 'f1865', 'f1866', 'f1867', 'f1868', 'f1869', 'f1870', 'f1871', 'f1872', 'f1873', 'f1874', 'f1875', 'f1876', 'f1877', 'f1878', 'f1879', 'f1880', 'f1881', 'f1882', 'f1883', 'f1884', 'f1885', 'f1886', 'f1887', 'f1888', 'f1889', 'f1890', 'f1891', 'f1892', 'f1893', 'f1894', 'f1895', 'f1896', 'f1897', 'f1898', 'f1899', 'f1900', 'f1901', 'f1902', 'f1903', 'f1904', 'f1905', 'f1906', 'f1907', 'f1908', 'f1909', 'f1910', 'f1911', 'f1912', 'f1913', 'f1914', 'f1915', 'f1916', 'f1917', 'f1918', 'f1919', 'f1920', 'f1921', 'f1922', 'f1923', 'f1924'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53']\nexpected f1321, f1134, f1429, f1924, f1791, f1340, f148, f1496, f1423, f162, f891, f948, f847, f1234, f1259, f639, f1456, f909, f521, f217, f1274, f1693, f600, f1643, f165, f782, f296, f1230, f994, f1379, f569, f329, f1503, f1325, f1414, f1381, f1411, f1010, f1880, f1527, f1176, f645, f1512, f748, f112, f638, f1563, f1685, f1231, f435, f196, f966, f1789, f91, f271, f317, f1221, f754, f1408, f1756, f1829, f853, f570, f469, f691, f1584, f1876, f949, f1696, f1462, f1445, f1824, f355, f1454, f1654, f1243, f1076, f833, f749, f654, f1917, f1384, f331, f881, f494, f387, f1612, f1647, f88, f752, f1281, f1479, f467, f362, f1473, f172, f265, f902, f1506, f1078, f890, f1718, f1189, f734, f1297, f1427, f802, f1902, f211, f386, f1872, f308, f1750, f1241, f404, f1426, f1528, f1443, f147, f1579, f764, f1383, f1211, f1372, f1349, f1715, f1490, f839, f486, f473, f707, f1921, f405, f1649, f1097, f1110, f1535, f1075, f1335, f164, f354, f973, f1341, f1444, f301, f1850, f1296, f1406, f1757, f1113, f1504, f1289, f358, f140, f1015, f1899, f240, f1458, f573, f611, f1673, f1227, f1575, f100, f904, f1792, f1544, f113, f1807, f1595, f73, f755, f394, f829, f595, f1597, f500, f998, f62, f1755, f670, f1328, f678, f1364, f862, f348, f1747, f629, f633, f888, f898, f632, f835, f1763, f1625, f1105, f1489, f391, f1276, f101, f1223, f1120, f729, f170, f1324, f451, f631, f1923, f820, f77, f294, f260, f340, f914, f1780, f1278, f1323, f173, f374, f545, f1250, f426, f880, f1080, f577, f1699, f1773, f550, f1658, f1376, f139, f241, f1596, f1439, f1368, f843, f1815, f1374, f388, f254, f83, f922, f1079, f663, f262, f1635, f177, f585, f1416, f300, f925, f983, f1401, f195, f491, f110, f341, f130, f498, f1362, f171, f1631, f141, f1096, f349, f131, f151, f593, f216, f773, f1375, f1793, f1816, f1183, f1246, f1122, f1160, f92, f1068, f1494, f246, f1877, f906, f269, f982, f1531, f1864, f259, f1071, f844, f978, f1571, f1705, f185, f529, f566, f86, f567, f588, f1865, f367, f1510, f234, f963, f1738, f1237, f1357, f382, f336, f1778, f827, f1485, f1180, f1209, f433, f714, f704, f249, f1882, f143, f581, f1488, f1735, f1839, f412, f1001, f1210, f1607, f1866, f1004, f415, f1135, f1396, f1100, f1452, f1794, f1430, f428, f1014, f1774, f1831, f999, f1697, f1382, f939, f971, f916, f1620, f957, f1903, f95, f525, f178, f128, f397, f443, f1889, f1533, f186, f1378, f572, f1190, f204, f499, f1459, f989, f59, f760, f1616, f1642, f800, f87, f1795, f607, f1029, f61, f873, f1175, f926, f1043, f680, f324, f896, f85, f1875, f55, f1254, f1619, f1140, f1901, f1562, f1059, f1214, f1320, f936, f821, f1630, f1469, f497, f739, f205, f1205, f883, f368, f1194, f213, f928, f993, f1336, f184, f122, f1476, f617, f1040, f1057, f379, f1731, f1150, f915, f310, f137, f1390, f1719, f810, f1139, f482, f1002, f236, f1207, f1759, f560, f788, f1777, f850, f1501, f1475, f235, f1639, f1005, f1857, f1208, f156, f1727, f1819, f1911, f1177, f306, f1301, f743, f449, f781, f264, f855, f1867, f1790, f1787, f708, f202, f277, f1851, f132, f1609, f1322, f1251, f429, f818, f825, f1821, f393, f123, f565, f345, f136, f1567, f159, f1600, f543, f373, f892, f1822, f227, f1646, f1804, f327, f1569, f1687, f1094, f1525, f1118, f168, f959, f1313, f886, f1351, f392, f1884, f514, f1085, f380, f647, f414, f1252, f669, f70, f268, f1082, f1011, f1367, f1702, f1392, f1446, f64, f602, f244, f290, f1353, f919, f852, f157, f57, f487, f1131, f472, f520, f1282, f1783, f1332, f390, f477, f1652, f605, f1644, f1257, f1598, f672, f1292, f1560, f231, f1007, f1391, f779, f339, f790, f1587, f461, f1225, f857, f1700, f1152, f279, f378, f549, f1591, f870, f1386, f783, f1370, f1518, f200, f1840, f884, f695, f209, f1409, f1692, f1087, f1463, f453, f1151, f1863, f702, f699, f623, f997, f1812, f666, f1215, f1309, f207, f501, f452, f1509, f1377, f1892, f958, f1064, f1887, f813, f526, f991, f82, f161, f267, f1447, f517, f1402, f1659, f622, f1258, f1146, f1657, f1552, f1073, f1077, f1665, f627, f442, f1602, f1590, f1615, f582, f1045, f1363, f203, f667, f90, f1287, f576, f650, f197, f1808, f399, f1166, f1235, f1457, f1610, f134, f1310, f1786, f1862, f601, f519, f923, f552, f1834, f138, f1505, f688, f536, f1148, f1754, f955, f942, f439, f1311, f561, f1922, f934, f1706, f1881, f239, f1062, f1299, f454, f280, f1188, f1604, f1730, f1856, f1095, f275, f1173, f1772, f1052, f1912, f107, f1720, f1187, f293, f215, f1172, f1515, f1016, f1508, f815, f1047, f1797, f297, f559, f1124, f175, f1713, f208, f895, f427, f791, f831, f557, f1593, f1848, f969, f361, f1860, f214, f126, f988, f1785, f696, f1548, f1074, f868, f1449, f1044, f1198, f889, f539, f718, f1585, f1907, f1686, f270, f142, f553, f751, f1219, f796, f660, f343, f940, f1879, f1883, f1736, f967, f753, f121, f946, f127, f425, f1008, f1154, f72, f366, f726, f1671, f869, f224, f795, f662, f1174, f1464, f322, f981, f1389, f785, f767, f1186, f1767, f1112, f1828, f1415, f1539, f193, f485, f465, f1648, f710, f1272, f1760, f1216, f1039, f837, f665, f798, f799, f1107, f530, f1830, f1285, f312, f1893, f1532, f1119, f823, f1849, f376, f929, f921, f1694, f505, f879, f67, f568, f1380, f1908, f1801, f1852, f410, f152, f1885, f845, f1667, f1603, f643, f321, f1636, f1915, f1333, f93, f1129, f1070, f1395, f824, f1847, f656, f1136, f586, f1069, f1169, f1776, f863, f1453, f518, f603, f1589, f1083, f1197, f1050, f1660, f1450, f762, f977, f1319, f1573, f1133, f116, f1405, f698, f849, f1181, f344, f905, f816, f1418, f284, f1111, f1523, f445, f759, f325, f1141, f534, f675, f1574, f1817, f625, f830, f575, f1387, f1632, f1675, f538, f333, f1125, f420, f508, f1128, f792, f346, f1222, f1300, f1279, f1145, f864, f154, f1618, f229, f218, f867, f1868, f1428, f1538, f228, f1012, f664, f169, f1130, f1486, f1358, f634, f1611, f747, f1058, f996, f894, f1895, f1690, f1674, f1664, f1261, f860, f1799, f1536, f774, f932, f1437, f1583, f556, f1572, f580, f396, f1343, f222, f416, f502, f564, f848, f621, f338, f1670, f1870, f302, f1116, f908, f1624, f684, f353, f794, f766, f1142, f819, f1467, f166, f1264, f1455, f1286, f1782, f933, f1637, f1586, f1919, f247, f1499, f728, f1669, f1744, f1465, f1034, f716, f1483, f1497, f865, f1153, f1092, f257, f1549, f1689, f1400, f828, f1542, f1441, f927, f1334, f1565, f233, f1835, f78, f417, f701, f1346, f1491, f1581, f1861, f732, f1373, f626, f765, f793, f1098, f274, f1904, f723, f431, f899, f1920, f155, f987, f1784, f1627, f176, f851, f1721, f589, f1265, f641, f1283, f334, f424, f1103, f111, f163, f182, f1106, f446, f1714, f630, f102, f544, f741, f266, f771, f369, f711, f1298, f801, f1617, f980, f1268, f941, f1745, f283, f990, f1366, f1114, f1035, f299, f278, f1613, f846, f1751, f192, f952, f179, f776, f1555, f1691, f1640, f118, f1517, f887, f1304, f1240, f1213, f1739, f1338, f912, f401, f1424, f187, f524, f481, f104, f432, f1493, f253, f1472, f1683, f1060, f423, f1480, f436, f1650, f1460, f703, f206, f648, f974, f1638, f79, f1171, f733, f1337, f1568, f673, f1203, f574, f363, f1417, f289, f804, f189, f1582, f1681, f421, f1315, f383, f58, f1051, f1540, f384, f856, f583, f649, f592, f692, f872, f1091, f920, f935, f858, f531, f1155, f968, f1633, f1570, f746, f768, f992, f1339, f1796, f686, f1028, f438, f1266, f1749, f757, f1054, f221, f303, f149, f377, f1229, f1206, f554, f979, f1024, f1916, f444, f406, f1534, f1121, f1056, f307, f295, f1818, f281, f1554, f311, f558, f459, f579, f1629, f1018, f402, f685, f1762, f389, f761, f964, f1308, f591, f907, f65, f1236, f1477, f408, f1844, f1023, f1752, f1147, f1020, f1695, f1312, f507, f1663, f1906, f727, f893, f599, f1156, f1825, f1053, f1273, f1270, f304, f1284, f901, f1269, f854, f1788, f943, f1093, f398, f683, f1419, f1682, f1743, f1046, f1803, f316, f780, f145, f1436, f1137, f1360, f1327, f1537, f1679, f1399, f1561, f1448, f697, f174, f995, f838, f1487, f1495, f1032, f1081, f1161, f1742, f199, f784, f1117, f1814, f1084, f181, f1578, f590, f232, f1407, f1524, f492, f219, f950, f1249, f1306, f1271, f522, f455, f286, f1677, f1470, f1645, f273, f495, f882, f194, f1342, f547, f1019, f1628, f437, f251, f677, f1030, f1329, f413, f1193, f466, f986, f606, f1042, f1432, f1891, f1859, f717, f117, f903, f951, f1003, f385, f532, f1295, f1307, f528, f1886, f742, f261, f463, f220, f705, f1293, f332, f1195, f1126, f1592, f1543, f1653, f1516, f1144, f109, f98, f1247, f460, f537, f1878, f1500, f1746, f1072, f1874, f1041, f786, f1165, f1498, f610, f1900, f1843, f66, f447, f69, f900, f1688, f1369, f618, f183, f1022, f108, f523, f1709, f861, f1403, f458, f272, f1471, f1708, f1725, f1918, f1841, f841, f245, f191, f859, f1680, f1354, f1138, f651, f681, f330, f1260, f1179, f1733, f1000, f99, f474, f1232, f1666, f1317, f1086, f1275, f944, f1255, f1132, f84, f158, f1371, f1846, f1164, f1546, f652, f1614, f1897, f60, f1556, f1806, f226, f1710, f1393, f448, f725, f826, f1017, f1511, f1805, f1910, f509, f712, f775, f1502, f120, f571, f411, f133, f756, f811, f1200, f1212, f1256, f970, f319, f787, f679, f1557, f318, f619, f1769, f1201, f400, f1810, f1355, f911, f1672, f1433, f806, f1425, f809, f419, f1031, f1356, f1242, f1027, f1063, f878, f1826, f359, f671, f114, f146, f1601, f440, f1199, f840, f1758, f1833, f1290, f1599, f328, f1398, f1217, f464, f74, f1580, f668, f1191, f94, f1202, f212, f1741, f1033, f613, f1768, f984, f1606, f636, f1732, f1009, f1823, f370, f255, f1365, f918, f945, f1238, f1149, f1224, f832, f313, f1434, f1890, f1634, f540, f740, f594, f124, f738, f1239, f1101, f640, f960, f1314, f628, f97, f615, f653, f1065, f871, f931, f1013, f1869, f1541, f364, f1853, f1798, f506, f938, f291, f1845, f1676, f1204, f1421, f457, f772, f450, f512, f471, f258, f527, f542, f1623, f511, f1734, f1588, f335, f1779, f1244, f515, f736, f1192, f1551, f1684, f842, f1302, f1896, f1253, f285, f256, f1775, f476, f533, f1553, f1608, f1753, f225, f693, f135, f616, f352, f1090, f694, f350, f360, f803, f778, f1726, f745, f63, f953, f797, f713, f720, f1422, f96, f1764, f1461, f1520, f1656, f298, f1712, f1717, f814, f1507, f735, f750, f758, f658, f1316, f287, f1550, f1157, f597, f1178, f409, f975, f1740, f690, f563, f924, f1184, f1350, f769, f1530, f876, f737, f1800, f105, f548, f1802, f80, f1115, f1661, f874, f1559, f789, f1109, f709, f1641, f972, f777, f238, f1451, f1728, f730, f1345, f1233, f961, f1326, f1055, f342, f1678, f305, f1724, f1067, f1182, f320, f1104, f237, f356, f81, f808, f866, f1021, f763, f68, f635, f1163, f1413, f326, f609, f1218, f1420, f434, f657, f1127, f1348, f496, f153, f1577, f1545, f422, f1088, f56, f1478, f624, f1668, f490, f119, f1159, f1827, f468, f250, f1036, f483, f608, f1288, f1385, f1913, f724, f1526, f1168, f129, f1442, f930, f661, f1547, f76, f1513, f210, f288, f1842, f1352, f1914, f976, f188, f913, f1737, f1594, f190, f1294, f198, f503, f1621, f493, f1855, f1522, f1099, f430, f1492, f1280, f1871, f1162, f1888, f1894, f836, f659, f770, f89, f484, f1006, f407, f917, f1359, f947, f1410, f314, f1170, f1331, f1811, f103, f910, f614, f897, f395, f1521, f1748, f1781, f516, f612, f1558, f1388, f817, f372, f689, f1474, f584, f682, f1220, f700, f1909, f655, f1466, f1228, f1482, f562, f877, f1704, f719, f674, f1048, f1701, f578, f357, f637, f1226, f1397, f822, f403, f1347, f1481, f1529, f1651, f676, f1158, f722, f1248, f1440, f475, f1698, f1412, f1766, f1722, f347, f125, f1361, f555, f242, f1662, f201, f721, f144, f150, f115, f489, f1519, f1605, f292, f488, f598, f1854, f744, f587, f1049, f504, f1108, f1770, f1711, f1394, f1809, f418, f1102, f1303, f1196, f180, f1566, f546, f1484, f282, f1873, f1038, f510, f1723, f1123, f1037, f309, f1066, f1330, f706, f1262, f1514, f535, f642, f551, f1167, f1622, f644, f441, f1404, f1277, f1061, f807, f54, f106, f351, f1832, f1729, f1898, f1305, f75, f1143, f167, f252, f263, f541, f604, f1576, f956, f1838, f596, f1716, f230, f646, f1026, f1761, f375, f805, f1813, f812, f1905, f456, f1858, f620, f513, f276, f937, f71, f1267, f985, f470, f1431, f1837, f1263, f1468, f1438, f462, f1820, f965, f1318, f834, f1564, f875, f337, f365, f1025, f323, f371, f1707, f480, f962, f1185, f478, f1703, f1291, f1836, f1771, f1765, f731, f1435, f954, f1245, f715, f1655, f1626, f687, f885, f248, f381, f160, f1344, f315, f243, f223, f479, f1089 in input data"
     ]
    }
   ],
   "source": [
    "#Predict \n",
    "#output=grid.best_estimator_.predict(X_test)\n",
    "tweet_row=list(data_test.processed_data[\"spans\"])\n",
    "#old_pred=list(data_test.processed_data[\"sentiment score\"])\n",
    "old_pred=list(y_test)\n",
    "output = model.predict(X_test)\n",
    "#final_df = pd.DataFrame(tweet_row, columns=labels)\n",
    "final_df = pd.DataFrame()\n",
    "final_df[\"tweet\"] = tweet_row\n",
    "\n",
    "final_df[\"old_pred\"] = old_pred\n",
    "\n",
    "final_df[\"Prediction\"] = output\n",
    "final_df.to_csv(\"Output_1.csv\",sep=\",\")\n",
    "final_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-2a6cd5549bdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mean squared error:\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"R2 score:\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "#test model accuracy\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "print(\"mean squared error:\" ,mean_squared_error(output, y_test))\n",
    "print(\"R2 score:\" ,r2_score(output,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

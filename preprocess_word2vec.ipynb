{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import time\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import regexp_tokenize, wordpunct_tokenize,blankline_tokenize\n",
    "from nltk import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import json\n",
    "import re as regex\n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection, preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterData_Initialize():\n",
    "    data = []\n",
    "    processed_data = []\n",
    "    wordlist = []\n",
    "\n",
    "    featureList = []\n",
    "    fea_vect=[]\n",
    "    \n",
    "    data_model = None\n",
    "    data_labels = None\n",
    "    is_testing = False\n",
    "    \n",
    "    def initialize(self, csv_file, is_testing_set=False, from_cached=None):\n",
    "        if from_cached is not None:\n",
    "            #self.data_model = pd.read_csv(from_cached)\n",
    "            self.data_model = pd.read_json(from_cached)\n",
    "\n",
    "            return\n",
    "\n",
    "        self.is_testing = is_testing_set\n",
    "\n",
    "        if not is_testing_set:\n",
    "            #self.data = pd.read_csv(csv_file, header=0, names=[\"id\", \"emotion\", \"text\"])\n",
    "            self.data = pd.read_json(csv_file)\n",
    "\n",
    "            #self.data = self.data[self.data[\"emotion\"].isin([\"positive\", \"negative\", \"neutral\"])]\n",
    "        \n",
    "\n",
    "        self.processed_data = self.data\n",
    "        self.wordlist = []\n",
    "        self.data_model = None\n",
    "        self.data_labels = None\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def do_process(self):\n",
    "        start_time = time.time()\n",
    "        def stem_and_join(row,stemmer=nltk.PorterStemmer()):\n",
    "            row[\"spans\"] = list(map(lambda str: stemmer.stem(str.lower()), row[\"spans\"]))\n",
    "            return row\n",
    "    \n",
    "        def tokenize_grams(row):\n",
    "                #remove numbers\n",
    "                def remove_numbers(text):\n",
    "                    return re.sub(r'\\d+', '', text)\n",
    "             \n",
    "                def to_lower(text):\n",
    "                    return text.lower()\n",
    "\n",
    "                #20 Function to remove whitespace\n",
    "                def remove_whitespace(text):\n",
    "                    return \" \".join(text.split())\n",
    "\n",
    "                # Function to remove punctuations\n",
    "                def remove_punctuations(text):\n",
    "                    text=re.sub(r'[?|*|.|!|+|-]',r'',text)\n",
    "                    words = nltk.word_tokenize(text)\n",
    "                    punt_removed = [w for w in words if w.lower() not in string.punctuation]\n",
    "                    return \" \".join(punt_removed)\n",
    "#30\n",
    "\n",
    "                # Function to remove stop words\n",
    "                def remove_stopwords(text, lang='english'):\n",
    "                        \n",
    "\n",
    "                    whitelist=[\"to\",\"on\",\"n't\",\"not\",\"don't\",\"for\",\"up\",\"below\",\"short\",\"long\"]\n",
    "\n",
    "                    stop_words = set(stopwords.words('english'))\n",
    "                    word_tokens = word_tokenize(text)\n",
    "                    #filtered_sentence = [w for w in word_tokens if ((not w in stop_words) or (w in whitelist))]\n",
    "                    filtered_sentence = []\n",
    "                    for w in word_tokens:\n",
    "                        if ((w not in stop_words) or (w in whitelist)) :\n",
    "                            filtered_sentence.append(w)\n",
    "                \n",
    "                    ch=\" \".join(filtered_sentence)\n",
    "\n",
    "                    return ch\n",
    "#40\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # Function to extract n-grams from text\n",
    "                def get_ngrams(text, n):\n",
    "\n",
    "                    n_grams = ngrams(nltk.word_tokenize(text), n)\n",
    "                    list_grams=[ ' '.join(grams) for grams in n_grams]\n",
    "                    return list_grams\n",
    "\n",
    "\n",
    "                # Function to apply lemmatization to a list of words\n",
    "                def words_lemmatizer(text, encoding=\"utf8\"):\n",
    "                    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "                    words = nltk.word_tokenize(text)\n",
    "                    lemma_words = []\n",
    "                    wl = WordNetLemmatizer()\n",
    "                    for word in words:\n",
    "                        pos = find_pos(word)\n",
    "                        lemma_words.append(wl.lemmatize(word, pos))\n",
    "                    return \" \".join(lemma_words)\n",
    "\n",
    "                # Function to find part of speech tag for a word\n",
    "                def find_pos(word):\n",
    "                    # Part of Speech constants\n",
    "                    # ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v'\n",
    "   \n",
    "                    pos = nltk.pos_tag(nltk.word_tokenize(word))[0][1]\n",
    "                    # Adjective tags - 'JJ', 'JJR', 'JJS'\n",
    "                    if pos.lower()[0] == 'j':\n",
    "                        return 'a'\n",
    "                    # Adverb tags - 'RB', 'RBR', 'RBS'\n",
    "                    elif pos.lower()[0] == 'r':\n",
    "                        return 'r'\n",
    "                    # Verb tags - 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'\n",
    "                    elif pos.lower()[0] == 'v':\n",
    "                        return 'v'\n",
    "                    # Noun tags - 'NN', 'NNS', 'NNP', 'NNPS'\n",
    "                    else:\n",
    "                        return 'n'\n",
    "    \n",
    "            \n",
    "                #convert to string\n",
    "                idx=row[\"spans\"]\n",
    "                #ch=\"\".join(x for x in idx if x)\n",
    "                ch=' '.join(idx)\n",
    "               \n",
    "    \n",
    "                \n",
    "                \n",
    "                #words_stemmer(ch, type=\"PorterStemmer\", lang=\"english\", encoding=\"utf8\")\n",
    "                #Convert to lower case\n",
    "                txt_num=remove_numbers(ch)\n",
    "\n",
    "                txt_low=to_lower(txt_num)\n",
    "                \n",
    "                txt_ws=remove_whitespace(txt_low)\n",
    "    \n",
    "\n",
    "                txt_pun=remove_punctuations(txt_ws)\n",
    "\n",
    "                txt_final=remove_stopwords(txt_pun)\n",
    "\n",
    "                #texte=words_lemmatizer(txt_final)\n",
    "\n",
    "                n_grams=get_ngrams(txt_final, 1)\n",
    "\n",
    "                row[\"token_spans\"] = n_grams\n",
    "    \n",
    "                return row\n",
    "        #self.processed_data = self.processed_data.apply(stem_and_join, axis=1)\n",
    "        self.processed_data = self.processed_data.apply(tokenize_grams, axis=1)\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    \n",
    "\n",
    "    def build_wordlist(self, min_occurrences=0, max_occurences=500, stopwords=nltk.corpus.stopwords.words(\"english\"),\n",
    "                       ):\n",
    "        def get_tweets(data):\n",
    "            start_time = time.time()\n",
    "\n",
    "            tweets=list(data.processed_data.token_spans)\n",
    "    \n",
    "            list_tweet=[]\n",
    "            for i,chaine in enumerate(tweets):\n",
    "                ch=\" \".join(chaine)\n",
    "                list_tweet.append(ch)\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "            return list_tweet\n",
    "    \n",
    "        def get_top_n_words(corpus, n=None):\n",
    "   \n",
    "            vec = CountVectorizer().fit(corpus)\n",
    "            bag_of_words = vec.transform(corpus)\n",
    "            sum_words = bag_of_words.sum(axis=0) \n",
    "            words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "            words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "            return words_freq[:n]\n",
    "        whitelist=[]\n",
    "        stopwords=[]\n",
    "        self.wordlist = []\n",
    "        \"\"\"\n",
    "        corpus=get_tweets(self)\n",
    "        common_words = get_top_n_words(corpus)\n",
    "        word_df = pd.DataFrame(data={\"word\": [k for k, v in common_words],\n",
    "                                     \"occurrences\": [v for k, v in common_words]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "        \n",
    "        \n",
    "        word_df.to_csv(\"wordlist_count.csv\", index_label=\"idx\")\n",
    "        self.wordlist = [k for k, v in common_words]\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        words = Counter()\n",
    "      \n",
    "        for idx in self.processed_data.index:\n",
    "            words.update(self.processed_data.loc[idx, \"token_spans\"])\n",
    "\n",
    "        for idx, stop_word in enumerate(stopwords):\n",
    "            if stop_word not in whitelist:\n",
    "                del words[stop_word]\n",
    "        \n",
    "\n",
    "        \n",
    "                \n",
    "        print(words.most_common())\n",
    "        word_df = pd.DataFrame(data={\"word\": [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\n",
    "                                     \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "\n",
    "        word_df.to_csv(\"wordlist_copie.csv\", index_label=\"idx\")\n",
    "        self.wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]\n",
    "        \n",
    "        \n",
    "    def build_data_model(self):\n",
    "        label_column = []\n",
    "        Id_column=[\"ID\"]\n",
    "        label_column = [\"label\"]\n",
    "\n",
    "        columns = Id_column + label_column + list(\n",
    "            map(lambda w: w ,self.wordlist))\n",
    "        labels = []\n",
    "        rows = []\n",
    "        for idx in self.processed_data.index:\n",
    "            current_row = []\n",
    "\n",
    "            if True:\n",
    "                # add label\n",
    "                current_label = self.processed_data.loc[idx, \"sentiment score\"]\n",
    "                current_id = self.processed_data.loc[idx, \"id\"]\n",
    "                \n",
    "                labels.append(current_id)\n",
    "                labels.append(current_label)\n",
    "                \n",
    "                current_row.append(current_id)\n",
    "                current_row.append(current_label)\n",
    "\n",
    "            # add bag-of-words\n",
    "            tokens = set(self.processed_data.loc[idx, \"token_spans\"])\n",
    "            for _, word in enumerate(self.wordlist):\n",
    "                current_row.append(1 if word in tokens else 0)\n",
    "\n",
    "            rows.append(current_row)\n",
    "\n",
    "        self.data_model = pd.DataFrame(rows, columns=columns)\n",
    "        self.data_labels = pd.Series(labels)\n",
    "        return self.data_model, self.data_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterData_Initialize_test(TwitterData_Initialize):\n",
    "\n",
    "    \n",
    "    \n",
    "    def do_process(self):\n",
    "        def stem_and_join(row,stemmer=nltk.PorterStemmer()):\n",
    "            \n",
    "            row[\"spans\"] = list(map(lambda str: stemmer.stem(str.lower()), row[\"spans\"].split()))\n",
    "            return row\n",
    "    \n",
    "        def tokenize_grams(row):\n",
    "                #remove numbers\n",
    "                def remove_numbers(text):\n",
    "                    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "                def to_lower(text):\n",
    "                    return text.lower()\n",
    "                \n",
    "                #20 Function to remove whitespace\n",
    "                def remove_whitespace(text):\n",
    "                    return \" \".join(text.split())\n",
    "\n",
    "                # Function to remove punctuations\n",
    "                def remove_punctuations(text):\n",
    "                    text=re.sub(r'[?|*|.|!|+|-]',r'',text)\n",
    "\n",
    "                    words = nltk.word_tokenize(text)\n",
    "                    punt_removed = [w for w in words if w.lower() not in string.punctuation]\n",
    "                    return \" \".join(punt_removed)\n",
    "#30\n",
    "\n",
    "                # Function to remove stop words\n",
    "                def remove_stopwords(text, lang='english'):\n",
    "\n",
    "                    whitelist=[\"to\",\"on\",\"n't\",\"not\",\"don't\",\"for\",\"up\",\"below\",\"short\",\"long\"]\n",
    "\n",
    "                    stop_words = set(stopwords.words('english'))\n",
    "                    word_tokens = word_tokenize(text)\n",
    "                    #filtered_sentence = [w for w in word_tokens if ((not w in stop_words) or (w in whitelist))]\n",
    "                    filtered_sentence = []\n",
    "                    for w in word_tokens:\n",
    "                        if ((w not in stop_words) or (w in whitelist)) :\n",
    "                            filtered_sentence.append(w)\n",
    "                \n",
    "                    ch=\" \".join(filtered_sentence)\n",
    "\n",
    "                    return ch\n",
    "#40\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # Function to extract n-grams from text\n",
    "                def get_ngrams(text, n):\n",
    "\n",
    "                    n_grams = ngrams(nltk.word_tokenize(text), n)\n",
    "                    list_grams=[ ' '.join(grams) for grams in n_grams]\n",
    "                    return list_grams\n",
    "\n",
    "\n",
    "                # Function to apply lemmatization to a list of words\n",
    "                def words_lemmatizer(text, encoding=\"utf8\"):\n",
    "                    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "                    words = nltk.word_tokenize(text)\n",
    "                    lemma_words = []\n",
    "                    wl = WordNetLemmatizer()\n",
    "                    for word in words:\n",
    "                        pos = find_pos(word)\n",
    "                        lemma_words.append(wl.lemmatize(word, pos))\n",
    "                    return \" \".join(lemma_words)\n",
    "\n",
    "                # Function to find part of speech tag for a word\n",
    "                def find_pos(word):\n",
    "                    # Part of Speech constants\n",
    "                    # ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v'\n",
    "   \n",
    "                    pos = nltk.pos_tag(nltk.word_tokenize(word))[0][1]\n",
    "                    # Adjective tags - 'JJ', 'JJR', 'JJS'\n",
    "                    if pos.lower()[0] == 'j':\n",
    "                        return 'a'\n",
    "                    # Adverb tags - 'RB', 'RBR', 'RBS'\n",
    "                    elif pos.lower()[0] == 'r':\n",
    "                        return 'r'\n",
    "                    # Verb tags - 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'\n",
    "                    elif pos.lower()[0] == 'v':\n",
    "                        return 'v'\n",
    "                    # Noun tags - 'NN', 'NNS', 'NNP', 'NNPS'\n",
    "                    else:\n",
    "                        return 'n'\n",
    "    \n",
    "            \n",
    "            \n",
    "                idx=row[\"spans\"]\n",
    "                ch=' '.join(idx)\n",
    "\n",
    "\n",
    "    \n",
    "                #words_stemmer(ch, type=\"PorterStemmer\", lang=\"english\", encoding=\"utf8\")\n",
    "                #Convert to lower case\n",
    "                txt_num=remove_numbers(ch)\n",
    "                \n",
    "                \n",
    "                txt_low=to_lower(txt_num)\n",
    "                \n",
    "                txt_ws=remove_whitespace(txt_low)\n",
    "                    \n",
    "    \n",
    "                txt_pun=remove_punctuations(txt_ws)\n",
    "        \n",
    "                txt_final=remove_stopwords(txt_pun)\n",
    "\n",
    "                #texte=words_lemmatizer(txt_final)\n",
    "\n",
    "                n_grams=get_ngrams(txt_final, 1)\n",
    "                #print(\"list ngrams--------------\\n\",n_grams)\n",
    "\n",
    "                row[\"token_spans\"] = n_grams\n",
    "    \n",
    "                return row\n",
    "        #self.processed_data = self.processed_data.apply(stem_and_join, axis=1)\n",
    "        self.processed_data = self.processed_data.apply(tokenize_grams, axis=1)\n",
    "        \n",
    "    def build_wordlist(self, min_occurrences=0, max_occurences=500, stopwords=nltk.corpus.stopwords.words(\"english\"),\n",
    "                      ):\n",
    "        def get_tweets(data):\n",
    "            start_time = time.time()\n",
    "\n",
    "            tweets=list(data.processed_data.token_spans)\n",
    "    \n",
    "            list_tweet=[]\n",
    "            for i,chaine in enumerate(tweets):\n",
    "                ch=\" \".join(chaine)\n",
    "                list_tweet.append(ch)\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "            return list_tweet\n",
    "    \n",
    "        def get_top_n_words(corpus, n=None):\n",
    "   \n",
    "            vec = CountVectorizer().fit(corpus)\n",
    "            bag_of_words = vec.transform(corpus)\n",
    "            sum_words = bag_of_words.sum(axis=0) \n",
    "            words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "            words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "            return words_freq[:n]\n",
    "\n",
    "        whitelist=[]\n",
    "        stopwords=[]\n",
    "        self.wordlist = []\n",
    "        \"\"\"\n",
    "        corpus=get_tweets(self)\n",
    "        common_words = get_top_n_words(corpus)\n",
    "        word_df = pd.DataFrame(data={\"word\": [k for k, v in common_words],\n",
    "                                     \"occurrences\": [v for k, v in common_words]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "        \n",
    "        \n",
    "        word_df.to_csv(\"wordlist_count_test.csv\", index_label=\"idx\")\n",
    "        self.wordlist = [k for k, v in common_words]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        words = Counter()\n",
    "      \n",
    "        for idx in self.processed_data.index:\n",
    "            words.update(self.processed_data.loc[idx, \"token_spans\"])\n",
    "\n",
    "        for idx, stop_word in enumerate(stopwords):\n",
    "            if stop_word not in whitelist:\n",
    "                del words[stop_word]\n",
    "        \n",
    "\n",
    "        \n",
    "                \n",
    "        print(words.most_common())\n",
    "\n",
    "        word_df = pd.DataFrame(data={\"word\": [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\n",
    "                                     \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "\n",
    "        word_df.to_csv(\"wordlist_test.csv\", index_label=\"idx\")\n",
    "        self.wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]\n",
    "        \n",
    "        \n",
    "    def build_data_model(self):\n",
    "        \n",
    "        label_id = [\"ID\"]\n",
    "\n",
    "        columns = label_id + list(\n",
    "            map(lambda w: w ,self.wordlist))\n",
    "        labels = []\n",
    "        rows = []\n",
    "        for idx in self.processed_data.index:\n",
    "            current_row = []\n",
    "            if True:\n",
    "                # add label\n",
    "                current_id = self.processed_data.loc[idx, \"id\"]\n",
    "                \n",
    "                labels.append(current_id)\n",
    "                \n",
    "                current_row.append(current_id)\n",
    "\n",
    "            \n",
    "\n",
    "            # add bag-of-words\n",
    "            tokens = set(self.processed_data.loc[idx, \"token_spans\"])\n",
    "            for _, word in enumerate(self.wordlist):\n",
    "                current_row.append(1 if word in tokens else 0)\n",
    "\n",
    "            rows.append(current_row)\n",
    "\n",
    "        self.data_model = pd.DataFrame(rows, columns=columns)\n",
    "        return self.data_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cashtag</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment score</th>\n",
       "      <th>source</th>\n",
       "      <th>spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$FB</td>\n",
       "      <td>719659409228451840</td>\n",
       "      <td>0.366</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[watching for bounce tomorrow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$LUV</td>\n",
       "      <td>719904304207962112</td>\n",
       "      <td>0.638</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[record number of passengers served in 2015]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$NFLX</td>\n",
       "      <td>5329774</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[out $NFLX -.35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$DIA</td>\n",
       "      <td>719891468173844480</td>\n",
       "      <td>0.460</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Looking for a strong bounce, Lunchtime rally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$PLUG</td>\n",
       "      <td>20091246</td>\n",
       "      <td>0.403</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Very intrigued with the technology and growth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>$GMCR</td>\n",
       "      <td>5819749</td>\n",
       "      <td>0.000</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[short worked, puts up]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>$IBM</td>\n",
       "      <td>709741154393133056</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[overbought]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>$JOSB</td>\n",
       "      <td>17892972</td>\n",
       "      <td>-0.546</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[absolute garbage still up, stores TOTALLY EMP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>$CSTM</td>\n",
       "      <td>709834259687710720</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Biggest Market Losers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>$PYPL</td>\n",
       "      <td>708481442079068160</td>\n",
       "      <td>0.408</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Love this company long time.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>$GOOGL</td>\n",
       "      <td>31971935</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[$GOOG $GOOGL would suck]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>$ENDP</td>\n",
       "      <td>710187873492983808</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[who won't pay anymore, REAL risk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>$XLI</td>\n",
       "      <td>13915103</td>\n",
       "      <td>0.025</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[No edge offered]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>$PCLN</td>\n",
       "      <td>10448993</td>\n",
       "      <td>0.486</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[runs into the 50sma on the acquisition news]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>$AA</td>\n",
       "      <td>24886266</td>\n",
       "      <td>0.308</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[t can't go down]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>$AAPL</td>\n",
       "      <td>12793642</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[now seems like its helping the downtrend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>$AAPL</td>\n",
       "      <td>9408369</td>\n",
       "      <td>0.461</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[mastered their supply chain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>$GOLD</td>\n",
       "      <td>719909604654624768</td>\n",
       "      <td>0.408</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Most bullish stocks on Twitter during this dip]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>$AMD</td>\n",
       "      <td>9674584</td>\n",
       "      <td>-0.699</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[big dumping, would not touch it for a while]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>$SPY</td>\n",
       "      <td>10041008</td>\n",
       "      <td>0.495</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[trade continuing very nicely from yesterday, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cashtag                  id  sentiment score      source  \\\n",
       "0      $FB  719659409228451840            0.366     twitter   \n",
       "1     $LUV  719904304207962112            0.638     twitter   \n",
       "2    $NFLX             5329774           -0.494  stocktwits   \n",
       "3     $DIA  719891468173844480            0.460     twitter   \n",
       "4    $PLUG            20091246            0.403  stocktwits   \n",
       "5    $GMCR             5819749            0.000  stocktwits   \n",
       "6     $IBM  709741154393133056           -0.296     twitter   \n",
       "7    $JOSB            17892972           -0.546  stocktwits   \n",
       "8    $CSTM  709834259687710720           -0.438     twitter   \n",
       "9    $PYPL  708481442079068160            0.408     twitter   \n",
       "10  $GOOGL            31971935           -0.398  stocktwits   \n",
       "11   $ENDP  710187873492983808           -0.349     twitter   \n",
       "12    $XLI            13915103            0.025  stocktwits   \n",
       "13   $PCLN            10448993            0.486  stocktwits   \n",
       "14     $AA            24886266            0.308  stocktwits   \n",
       "15   $AAPL            12793642           -0.372  stocktwits   \n",
       "16   $AAPL             9408369            0.461  stocktwits   \n",
       "17   $GOLD  719909604654624768            0.408     twitter   \n",
       "18    $AMD             9674584           -0.699  stocktwits   \n",
       "19    $SPY            10041008            0.495  stocktwits   \n",
       "\n",
       "                                                spans  \n",
       "0                      [watching for bounce tomorrow]  \n",
       "1        [record number of passengers served in 2015]  \n",
       "2                                    [out $NFLX -.35]  \n",
       "3   [Looking for a strong bounce, Lunchtime rally ...  \n",
       "4   [Very intrigued with the technology and growth...  \n",
       "5                             [short worked, puts up]  \n",
       "6                                        [overbought]  \n",
       "7   [absolute garbage still up, stores TOTALLY EMP...  \n",
       "8                             [Biggest Market Losers]  \n",
       "9                      [Love this company long time.]  \n",
       "10                          [$GOOG $GOOGL would suck]  \n",
       "11                 [who won't pay anymore, REAL risk]  \n",
       "12                                  [No edge offered]  \n",
       "13      [runs into the 50sma on the acquisition news]  \n",
       "14                                  [t can't go down]  \n",
       "15         [now seems like its helping the downtrend]  \n",
       "16                      [mastered their supply chain]  \n",
       "17   [Most bullish stocks on Twitter during this dip]  \n",
       "18      [big dumping, would not touch it for a while]  \n",
       "19  [trade continuing very nicely from yesterday, ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TwitterData_Initialize()\n",
    "data.initialize(\"Microblog_Trainingdata.json\")\n",
    "\n",
    "data.processed_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.8729028701782227 seconds ---\n"
     ]
    }
   ],
   "source": [
    "data.do_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cashtag</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment score</th>\n",
       "      <th>source</th>\n",
       "      <th>spans</th>\n",
       "      <th>token_spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$FB</td>\n",
       "      <td>719659409228451840</td>\n",
       "      <td>0.366</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[watching for bounce tomorrow]</td>\n",
       "      <td>[watching, for, bounce, tomorrow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$LUV</td>\n",
       "      <td>719904304207962112</td>\n",
       "      <td>0.638</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[record number of passengers served in 2015]</td>\n",
       "      <td>[record, number, passengers, served]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$NFLX</td>\n",
       "      <td>5329774</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[out $NFLX -.35]</td>\n",
       "      <td>[nflx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$DIA</td>\n",
       "      <td>719891468173844480</td>\n",
       "      <td>0.460</td>\n",
       "      <td>twitter</td>\n",
       "      <td>[Looking for a strong bounce, Lunchtime rally ...</td>\n",
       "      <td>[looking, for, strong, bounce, lunchtime, rall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$PLUG</td>\n",
       "      <td>20091246</td>\n",
       "      <td>0.403</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Very intrigued with the technology and growth...</td>\n",
       "      <td>[intrigued, technology, growth, potential]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cashtag                  id  sentiment score      source  \\\n",
       "0     $FB  719659409228451840            0.366     twitter   \n",
       "1    $LUV  719904304207962112            0.638     twitter   \n",
       "2   $NFLX             5329774           -0.494  stocktwits   \n",
       "3    $DIA  719891468173844480            0.460     twitter   \n",
       "4   $PLUG            20091246            0.403  stocktwits   \n",
       "\n",
       "                                               spans  \\\n",
       "0                     [watching for bounce tomorrow]   \n",
       "1       [record number of passengers served in 2015]   \n",
       "2                                   [out $NFLX -.35]   \n",
       "3  [Looking for a strong bounce, Lunchtime rally ...   \n",
       "4  [Very intrigued with the technology and growth...   \n",
       "\n",
       "                                         token_spans  \n",
       "0                  [watching, for, bounce, tomorrow]  \n",
       "1               [record, number, passengers, served]  \n",
       "2                                             [nflx]  \n",
       "3  [looking, for, strong, bounce, lunchtime, rall...  \n",
       "4         [intrigued, technology, growth, potential]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cashtag</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment score</th>\n",
       "      <th>source</th>\n",
       "      <th>spans</th>\n",
       "      <th>token_spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$F</td>\n",
       "      <td>5540055</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Putting on a little $F short]</td>\n",
       "      <td>[putting, on, little, f, short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$AAPL</td>\n",
       "      <td>10752226</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[short some]</td>\n",
       "      <td>[short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$BAC</td>\n",
       "      <td>10920221</td>\n",
       "      <td>0.445</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[buying opportunity]</td>\n",
       "      <td>[buying, opportunity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$SHOR</td>\n",
       "      <td>12971398</td>\n",
       "      <td>0.661</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Scaling Up on Long Position]</td>\n",
       "      <td>[scaling, up, on, long, position]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$JPM</td>\n",
       "      <td>16142438</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[its time to sell banks]</td>\n",
       "      <td>[time, to, sell, banks]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cashtag        id  sentiment score      source  \\\n",
       "0      $F   5540055           -0.454  stocktwits   \n",
       "1   $AAPL  10752226           -0.464  stocktwits   \n",
       "2    $BAC  10920221            0.445  stocktwits   \n",
       "3   $SHOR  12971398            0.661  stocktwits   \n",
       "4    $JPM  16142438           -0.763  stocktwits   \n",
       "\n",
       "                            spans                        token_spans  \n",
       "0  [Putting on a little $F short]    [putting, on, little, f, short]  \n",
       "1                    [short some]                            [short]  \n",
       "2            [buying opportunity]              [buying, opportunity]  \n",
       "3   [Scaling Up on Long Position]  [scaling, up, on, long, position]  \n",
       "4        [its time to sell banks]            [time, to, sell, banks]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = TwitterData_Initialize_test()\n",
    "data_test.initialize(\"Microblog_Trialdata.json\")\n",
    "\n",
    "data_test.processed_data.head()\n",
    "#test_data=data_test.processed_data.copy()\n",
    "data_test.do_process()\n",
    "data_test.processed_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the built-in logging module\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['watching', 'for', 'bounce', 'tomorrow'],\n",
       " ['record', 'number', 'passengers', 'served'],\n",
       " ['nflx'],\n",
       " ['looking', 'for', 'strong', 'bounce', 'lunchtime', 'rally', 'coming'],\n",
       " ['intrigued', 'technology', 'growth', 'potential'],\n",
       " ['short', 'worked', 'puts', 'up'],\n",
       " ['overbought'],\n",
       " ['absolute',\n",
       "  'garbage',\n",
       "  'still',\n",
       "  'up',\n",
       "  'stores',\n",
       "  'totally',\n",
       "  'empty',\n",
       "  'stock',\n",
       "  'mispriced'],\n",
       " ['biggest', 'market', 'losers'],\n",
       " ['love', 'company', 'long', 'time'],\n",
       " ['goog', 'googl', 'would', 'suck'],\n",
       " ['wo', \"n't\", 'pay', 'anymore', 'real', 'risk'],\n",
       " ['edge', 'offered'],\n",
       " ['runs', 'sma', 'on', 'acquisition', 'news'],\n",
       " ['ca', \"n't\", 'go'],\n",
       " ['seems', 'like', 'helping', 'downtrend'],\n",
       " ['mastered', 'supply', 'chain'],\n",
       " ['bullish', 'stocks', 'on', 'twitter', 'dip'],\n",
       " ['big', 'dumping', 'would', 'not', 'touch', 'for'],\n",
       " ['trade', 'continuing', 'nicely', 'yesterday', 'looking', 'strong'],\n",
       " [],\n",
       " ['stochastic', 'overbought'],\n",
       " ['unusual', 'call', 'buying'],\n",
       " ['reserves', 'decline'],\n",
       " ['on', 'longerterm', 'technical', 'swing', 'long', 'basis'],\n",
       " ['insiders', 'selling'],\n",
       " ['goes', 'up'],\n",
       " ['breaks', 'see'],\n",
       " ['let', \"'s\", 'see', 'big', 'bounce'],\n",
       " [\"n't\", 'think', 'move', 'fb', 'short', 'term'],\n",
       " ['could', 'get', 'going'],\n",
       " ['hold'],\n",
       " ['may', 'feed', 'tsla', 'momentum', 'run', 'lately'],\n",
       " ['possible', 'double', 'bottom', 'set', 'up'],\n",
       " ['trading', 'alltime', 'high', 'strong', 'earnings', 'report'],\n",
       " ['positive',\n",
       "  'outcome',\n",
       "  'w/',\n",
       "  'lung',\n",
       "  'study/',\n",
       "  'may',\n",
       "  'see',\n",
       "  'filing',\n",
       "  'soros'],\n",
       " ['put', 'chum', 'key', 'support', 'next', 'level', 'careful'],\n",
       " ['tesla', 'great', 'company', 'bad', 'stock', 'tsla'],\n",
       " ['good', 'idea', 'buy', 'half', 'half', 'bac'],\n",
       " ['alibaba', 'ipo', 'hoopla', 'canâ€™t', 'hide', 'risk', 'chinese', 'stocks'],\n",
       " ['on', 'longerterm', 'technical', 'swing', 'long', 'basis'],\n",
       " ['on', 'fence', 'one'],\n",
       " ['stay', 'long', 'apple'],\n",
       " ['looks', 'like', 'drought', 'conditions', 'soil', 'already'],\n",
       " ['unusual', 'call', 'activity'],\n",
       " ['mdxg', 'lower'],\n",
       " ['biggest', 'market', 'losers'],\n",
       " ['hip', 'sinking'],\n",
       " ['ca',\n",
       "  \"n't\",\n",
       "  'imagine',\n",
       "  'shorts',\n",
       "  'wanting',\n",
       "  'to',\n",
       "  'go',\n",
       "  'weekend',\n",
       "  'without',\n",
       "  'taking',\n",
       "  'care',\n",
       "  'position'],\n",
       " ['nice', 'volume', 'watch', 'resistance'],\n",
       " ['simo', 'basing', 'nice', 'close', 'bullish'],\n",
       " ['big', 'money', 'pouring', 'facebook', 'directions'],\n",
       " ['placed', 'order', 'to', 'sell', 'shares'],\n",
       " ['go', 'fb', 'go'],\n",
       " ['bidu', 'for'],\n",
       " ['short', 'setups', 'looking', 'nicereally', 'nice'],\n",
       " ['defying', 'downturn'],\n",
       " ['man', 'one', 'to', 'careful'],\n",
       " ['downgrade'],\n",
       " ['short', 'tsla', 'calls'],\n",
       " ['looking',\n",
       "  'for',\n",
       "  'long',\n",
       "  'entry',\n",
       "  'today',\n",
       "  \"'s\",\n",
       "  'price',\n",
       "  'action',\n",
       "  \"n't\",\n",
       "  'appealing'],\n",
       " ['follow', 'trend', 'follow', 'money', 'flow'],\n",
       " ['tapping', 'on'],\n",
       " ['reenter', 'short', 'on', 'bounce'],\n",
       " ['found', 'good', 'bull', 'setups', 'week'],\n",
       " ['going'],\n",
       " ['volatile'],\n",
       " ['sold', 'calls'],\n",
       " [\"'m\", 'watching', 'buy', 'targets'],\n",
       " ['beats',\n",
       "  'estimize',\n",
       "  'eps',\n",
       "  'consensus',\n",
       "  'c',\n",
       "  'estimize',\n",
       "  'revenue',\n",
       "  'consensus'],\n",
       " ['short', 'percent', 'float'],\n",
       " [],\n",
       " ['add', 'to', 'fxp', 'skf', 'positions'],\n",
       " ['long'],\n",
       " ['bottom', 'losses'],\n",
       " ['ure', 'wish', 'bad', 'news', 'came', 'days', 'earlier'],\n",
       " [],\n",
       " ['wmt'],\n",
       " ['added', 'increase'],\n",
       " ['mkt', 'fell', 'on', 'debt', 'downgrade', 'due', 'to', 'slow', 'growth'],\n",
       " ['fcx'],\n",
       " ['frustrating',\n",
       "  'green',\n",
       "  'bar',\n",
       "  'gets',\n",
       "  'followed',\n",
       "  'immediately',\n",
       "  'weeks',\n",
       "  'consolidation'],\n",
       " ['thanks', 'for', 'short'],\n",
       " ['need', 'to', 'break'],\n",
       " ['fed', 'cuts', 'rates', 'forecast', 'calls', 'go'],\n",
       " ['stochastic', 'overbought'],\n",
       " ['tight', 'price'],\n",
       " ['oversold'],\n",
       " ['great', 'step', 'for', 'china', 'to', 'let', 'fb'],\n",
       " ['new', 'squeeze', 'plays'],\n",
       " ['crm', 'seems', 'little', 'to', 'high', 'also'],\n",
       " ['pie', 'sky'],\n",
       " ['moved', 'upper', 'bollinger', 'band'],\n",
       " ['highest', 'call', 'to', 'put', 'ratio'],\n",
       " ['offers', 'take', 'place', 'next', 'week'],\n",
       " ['currently', 'shorts', 'rejoicing'],\n",
       " ['breaking', 'market', 'pulls', 'back'],\n",
       " ['airlines', 'battle', 'for', 'cuba', 'routes', 'aal', 'luv', 'save', 'jblu'],\n",
       " ['buy', 'dip'],\n",
       " ['mdxg', 'lower'],\n",
       " ['blackberry', 'messenger', 'second', 'to', 'facebook', 'user', 'loyalty'],\n",
       " ['headed', 'to', 'time', 'highs'],\n",
       " ['shit', 'broke'],\n",
       " ['buy'],\n",
       " ['weak', 'open', 'goes', 'r/g', 'within', 'first', 'mins'],\n",
       " ['premarket'],\n",
       " ['guess', 'sold', 'million', 'mdlz'],\n",
       " ['buying', 'on', 'weakness'],\n",
       " ['shareholders', 'welcome', 'marriottstarwood', 'deal'],\n",
       " ['peachy', 'prospects'],\n",
       " ['another', 'sell', 'rating', 'sell', 'rating'],\n",
       " ['nice', 'day', 'rally'],\n",
       " ['nice', 'day', 'rally'],\n",
       " ['quality', 'stocks', 'high', 'cash', 'returns'],\n",
       " ['led', 'light', 'bulb', 'prices', 'rise', 'japan'],\n",
       " ['closed', 'buy'],\n",
       " ['highest', 'volume', 'last', 'days'],\n",
       " ['ibb', 'back', 'support'],\n",
       " ['long', 'earnings', 'looks', 'good'],\n",
       " ['considering', 'yahoo', 'bid', 'up'],\n",
       " ['weeks', 'steady', 'gains', 'advances', 'mkt', 'breadth', 'slowe'],\n",
       " ['buy', 'aggressively', 'pulls', 'back'],\n",
       " ['nice', 'day', 'rally'],\n",
       " ['gets', 'patents', 'goes'],\n",
       " ['buying', 'on', 'weakness'],\n",
       " ['led', 'light', 'bulb', 'prices', 'rise', 'japan'],\n",
       " ['later', 'riser', 'positive', 'catalyst'],\n",
       " ['could', 'strategy', 'to', 'exit', 'shorts', 'big', 'pop'],\n",
       " ['piper',\n",
       "  'upgrades',\n",
       "  'symantec',\n",
       "  'on',\n",
       "  'improving',\n",
       "  'renewal',\n",
       "  'rates',\n",
       "  'enterprise',\n",
       "  'growth'],\n",
       " ['look', 'for', 'strong', 'solar', 'rebound', 'today'],\n",
       " ['think',\n",
       "  'dnf',\n",
       "  'crew',\n",
       "  'get',\n",
       "  'nflx',\n",
       "  'short',\n",
       "  'next',\n",
       "  'days',\n",
       "  'heading',\n",
       "  'earnings'],\n",
       " ['red', 'aapl', 'dragging', 'qqq'],\n",
       " ['cuts', 'outlook'],\n",
       " ['weakness', 'continues'],\n",
       " ['watchlist', 'top', 'stocks'],\n",
       " ['long'],\n",
       " ['joint', 'bid', 'for', 'yahoo', \"'s\", 'internet', 'assets'],\n",
       " ['patience', 'pays'],\n",
       " ['bad', 'governance', 'not', 'confident', 'core', 'biz'],\n",
       " ['bottom', 'losses'],\n",
       " ['sales',\n",
       "  'numbers',\n",
       "  'still',\n",
       "  'holding',\n",
       "  'up',\n",
       "  'well',\n",
       "  'igh',\n",
       "  'end',\n",
       "  'might',\n",
       "  'not',\n",
       "  'concern'],\n",
       " ['feel', 'people', 'buying', 'ones', 'finger', 'on', 'sell', 'button'],\n",
       " ['gap', 'filled'],\n",
       " ['debt', 'crisis', 'entered', 'dangerous', 'new', 'phase'],\n",
       " ['to',\n",
       "  'break',\n",
       "  'to',\n",
       "  'new',\n",
       "  'highs',\n",
       "  'lots',\n",
       "  'technicals',\n",
       "  'looking',\n",
       "  'great',\n",
       "  'right'],\n",
       " ['next', 'resist', \"'s\"],\n",
       " [],\n",
       " ['looks', 'really', 'toppy', 'right'],\n",
       " ['pop', 'holiday'],\n",
       " ['breakup', 'cost', 'billions'],\n",
       " ['news', 'breaks', 'first', 'fastest', 'on', 'twitter', 'twtr'],\n",
       " ['overbought'],\n",
       " ['continues', 'to', 'consolidate', 'previous', 'break', 'area'],\n",
       " ['good', 'to', 'load', 'up', 'confident'],\n",
       " ['long', 'look', 'like', 'run', 'awaits'],\n",
       " ['buy', 'call'],\n",
       " ['companies', 'shld', 'worried', 'icloud'],\n",
       " ['spy'],\n",
       " ['decent', 'supt', 'hereexpect', 'upside'],\n",
       " ['monday', 'sold'],\n",
       " ['sector',\n",
       "  'taking',\n",
       "  'beating',\n",
       "  'recently',\n",
       "  'could',\n",
       "  'positive',\n",
       "  'catch',\n",
       "  'bid',\n",
       "  'today'],\n",
       " ['x', 'earnings', 'aapl', 'steal'],\n",
       " ['multi',\n",
       "  'top',\n",
       "  'on',\n",
       "  'mcd',\n",
       "  'chart',\n",
       "  'finally',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'fall',\n",
       "  'price',\n",
       "  'stability',\n",
       "  'questioned',\n",
       "  'stock',\n",
       "  'coming',\n",
       "  'weeks',\n",
       "  'tell'],\n",
       " ['us',\n",
       "  'adds',\n",
       "  'k',\n",
       "  'jobs',\n",
       "  'november',\n",
       "  'unemployment',\n",
       "  'rate',\n",
       "  'remains',\n",
       "  'gold',\n",
       "  'futures'],\n",
       " ['fb', 'falling'],\n",
       " ['calls',\n",
       "  'for',\n",
       "  'nice',\n",
       "  'gains',\n",
       "  'still',\n",
       "  'holding',\n",
       "  'week',\n",
       "  'made',\n",
       "  'morning'],\n",
       " ['someone', 'bought', 'lots', 'calls', 'mon'],\n",
       " ['moving', 'up'],\n",
       " ['ea', 'points', 'to', 'two', 'facebook', 'games'],\n",
       " ['ready', 'to', 'exit', 'bankruptcy'],\n",
       " ['starting', 'to', 'creep', 'up'],\n",
       " ['looks', 'like', 'bo', 'coming'],\n",
       " ['year', 'would', 'amazing'],\n",
       " ['moved', 'upper', 'bollinger', 'band'],\n",
       " ['gogo', 'short'],\n",
       " ['eu', 'getting', 'closer', 'to', 'charging', 'google', 'android'],\n",
       " ['supermarket',\n",
       "  'stocks',\n",
       "  'rally',\n",
       "  'tesco',\n",
       "  'plans',\n",
       "  'to',\n",
       "  'axe',\n",
       "  'noncore',\n",
       "  'uk',\n",
       "  'assets'],\n",
       " ['china', 'winners'],\n",
       " ['looks', 'like', 'ascending', 'channel'],\n",
       " ['patience', 'on', 'buy', 'precedes', 'patience', 'on', 'sell'],\n",
       " ['oil', 'to', 'break', 'adding', 'chevron'],\n",
       " ['brand',\n",
       "  'name',\n",
       "  'to',\n",
       "  'big',\n",
       "  'for',\n",
       "  'to',\n",
       "  'fail',\n",
       "  'bet',\n",
       "  'recover',\n",
       "  'get',\n",
       "  'bought',\n",
       "  'year'],\n",
       " ['top', 'netpayoutyields'],\n",
       " ['long', 'amzn', 'oct', 'calls'],\n",
       " ['pressure', 'along', 'market'],\n",
       " ['patience', 'pays'],\n",
       " ['stock', 'splits', 'lipstick', 'on', 'pig'],\n",
       " ['making', 'new', 'highs', 'for', 'year'],\n",
       " ['held',\n",
       "  'up',\n",
       "  'well',\n",
       "  'big',\n",
       "  'gains',\n",
       "  'still',\n",
       "  'undervalued',\n",
       "  'major',\n",
       "  'upside'],\n",
       " ['wait', 'see', 'taking', 'action'],\n",
       " ['markets', 'still', 'acting', 'weak'],\n",
       " ['breaking', 'below', 'support'],\n",
       " ['sold', 'concentrated', 'stake'],\n",
       " ['want', 'to', 'go', 'morning', \"'s\", 'time', 'looking', 'chart'],\n",
       " ['cracking', 'lower', 'early', 'short', 'correction'],\n",
       " ['fb', 'ibb'],\n",
       " ['higher', 'afternoon', 'trade', 'buy', 'point'],\n",
       " ['oil', 'to', 'break', 'adding', 'chevron'],\n",
       " ['added', 'sso'],\n",
       " ['fb', 'calls', 'entry'],\n",
       " ['tiffany', \"'s\", 'overvalued'],\n",
       " ['intc', 'aapl', 'strong', 'tech', 'leads', 'dow', 'higher'],\n",
       " ['crunching', \"'s\", 'diamond', 'rough'],\n",
       " ['biggest', 'gainers', 'today', 'large', 'caps'],\n",
       " ['aapl', 'new', 'long', 'broke'],\n",
       " ['added', 'to', 'gild', 'position', 'started', 'new', 'one', 'bwld'],\n",
       " ['largest', 'online', 'gaming', 'market'],\n",
       " [],\n",
       " ['bottom', 'losses'],\n",
       " ['stopped', 'even', 'yesterdays', 'entry'],\n",
       " ['micron', 'shares', 'pounded', 'on', 'fears', 'loss', 'business', 'apple'],\n",
       " ['closed', 'buy'],\n",
       " ['million', 'new', 'internet', 'users', 'added', 'globally', 'every', 'year'],\n",
       " ['uvxy', 'broke', 'amazing', 'not', 'st', 'time', 'wo', \"n't\", 'last'],\n",
       " ['long', 'leaps'],\n",
       " ['looks',\n",
       "  'like',\n",
       "  'support',\n",
       "  'line',\n",
       "  'around',\n",
       "  'held',\n",
       "  'close',\n",
       "  'green',\n",
       "  'could',\n",
       "  'start',\n",
       "  'seeing',\n",
       "  'pstv',\n",
       "  'momentum'],\n",
       " ['retreats', 'like', 'clockwork'],\n",
       " [],\n",
       " ['time', 'to', 'sell', 'banks'],\n",
       " ['upgrades', 'to', 'outperform', 'ifts', 'price', 'target'],\n",
       " ['unusual', 'call', 'buying'],\n",
       " ['holding', 'strong'],\n",
       " ['three', 'hot', 'stocks', 'today'],\n",
       " ['bulls'],\n",
       " ['patents', 'system'],\n",
       " ['markets', 'back', 'black', 'for'],\n",
       " ['losers', 'buying', 'tsla', 'levels'],\n",
       " ['adding', 'expe', 'pcln', 'to', 'mix', 'soon', 'already', 'ctrp', 'trip'],\n",
       " ['today', \"'s\", 'losers'],\n",
       " ['not', 'feel', 'terribly', 'good'],\n",
       " ['spy', 'up', 'still', 'holding'],\n",
       " ['record', 'number', 'passengers', 'served'],\n",
       " ['think', 'tnh', 'winner', 'ringing', 'register'],\n",
       " ['reiterated', \"'outperform\", 'rating'],\n",
       " ['airplanes', 'still', 'flying'],\n",
       " ['mtd'],\n",
       " ['bond', 'buying', 'signaling', 'bad', 'moves', 'for', 'market'],\n",
       " ['see',\n",
       "  'downside',\n",
       "  'next',\n",
       "  'two',\n",
       "  'weeks',\n",
       "  'careful',\n",
       "  'dollars',\n",
       "  'drop',\n",
       "  'potential'],\n",
       " ['run', 'course', 'needs', 'to', 'find', 'way', 'to', 'turn', 'around'],\n",
       " ['biggest', 'market', 'losers'],\n",
       " ['loaded',\n",
       "  'up',\n",
       "  'on',\n",
       "  'bsx',\n",
       "  'yesterday',\n",
       "  'looking',\n",
       "  'good',\n",
       "  'still',\n",
       "  'think',\n",
       "  'way',\n",
       "  'upside',\n",
       "  'downside'],\n",
       " ['notable', 'gainers', 'among', 'liquid', 'option', 'names', 'morning'],\n",
       " ['gevoâ€™s',\n",
       "  'alcohol',\n",
       "  'to',\n",
       "  'jet',\n",
       "  'fuel',\n",
       "  'eligible',\n",
       "  'to',\n",
       "  'used',\n",
       "  'for',\n",
       "  'commercial',\n",
       "  'flight'],\n",
       " ['star',\n",
       "  'analyst',\n",
       "  'brianwieser',\n",
       "  'pivotal',\n",
       "  'research',\n",
       "  'upgraded',\n",
       "  'rating',\n",
       "  'on',\n",
       "  'googl',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'brian',\n",
       "  'success',\n",
       "  'rate'],\n",
       " ['santa', 'rally', 'blow', 'top'],\n",
       " ['iphone', 'still', 'better', 'galaxy'],\n",
       " [\"n't\", 'factor', 'anything', 'google', 'repeated', 'good', 'earnings'],\n",
       " ['facebook', 'succeeding', 'google', 'dominated'],\n",
       " ['uco'],\n",
       " ['up', 'on', 'day', 'continue', 'surge', 'next', 'week'],\n",
       " ['facebook', 'stock'],\n",
       " ['ripe', 'for', 'squeeze'],\n",
       " ['biggest', 'market', 'losers'],\n",
       " ['personal',\n",
       "  'story',\n",
       "  'sharing',\n",
       "  'declining',\n",
       "  'fb',\n",
       "  'feeds',\n",
       "  'start',\n",
       "  'to',\n",
       "  'look',\n",
       "  'like',\n",
       "  'twtr'],\n",
       " ['upgrades', 'stock', 'recuperates'],\n",
       " ['saying',\n",
       "  'peak',\n",
       "  'fear',\n",
       "  'mongering',\n",
       "  'competition',\n",
       "  \"'s\",\n",
       "  'dying',\n",
       "  'smartphone',\n",
       "  'usage',\n",
       "  'increasing'],\n",
       " ['trending'],\n",
       " ['wo', \"n't\", 'pay', 'anymore', 'real', 'risk'],\n",
       " ['still', 'saying', 'bullish', 'lol'],\n",
       " ['today', \"'s\", 'bull', 'flag'],\n",
       " ['growth',\n",
       "  'rate',\n",
       "  'approximately',\n",
       "  'to',\n",
       "  'total',\n",
       "  'net',\n",
       "  'revenues',\n",
       "  'to',\n",
       "  'mln'],\n",
       " ['lots', 'nice', 'setups', 'energy', 'liking', 'whiting', 'day', 'crzo'],\n",
       " ['bad', 'governance', 'not', 'confident', 'core', 'biz'],\n",
       " ['airplane', 'hospitality', 'industries', 'set', 'sights', 'on', 'cuba'],\n",
       " ['landed', 'ea'],\n",
       " ['bought', 'skf', 'hedge'],\n",
       " ['transports', 'always', 'lead', 'way', 'bull', 'flag'],\n",
       " ['case'],\n",
       " ['joe', 'getting', 'attention', 'on', 'nyse', 'top', 'buying', 'list'],\n",
       " ['short', 'setups', 'looking', 'nicereally', 'nice'],\n",
       " ['highest', 'close', 'since'],\n",
       " ['bring', 'spx', 'close'],\n",
       " [],\n",
       " ['money',\n",
       "  'flow',\n",
       "  'stochastic',\n",
       "  'dropping',\n",
       "  'itting',\n",
       "  'resistance',\n",
       "  'day',\n",
       "  'downtrend',\n",
       "  'retest',\n",
       "  'day'],\n",
       " ['run', 'for', 'watch', 'list', 'winner'],\n",
       " ['wks', 'fund', 'inflows', 'for', 'first', 'time'],\n",
       " ['goog', 'googl', 'would', 'suck'],\n",
       " ['ses', 'warrants', 'to', 'buy', 'b', 'amerisourcebergen', 'pbr', 'shares'],\n",
       " ['not', 'every', 'idea', 'amzn', 'bad'],\n",
       " ['looks', 'primed', 'poised', 'to', 'run'],\n",
       " ['yahoo', 'extends', 'bidding', 'deadline', 'interest', 'grows'],\n",
       " ['good', 'news', 'for', 'domestic', 'automakers'],\n",
       " ['mrkt', 'needs', 'to', 'washout'],\n",
       " ['valuation',\n",
       "  'high',\n",
       "  'net',\n",
       "  'cash',\n",
       "  'fwd',\n",
       "  'growth',\n",
       "  'high',\n",
       "  'peg',\n",
       "  'historical',\n",
       "  'high',\n",
       "  'pe',\n",
       "  'fwd',\n",
       "  'pe'],\n",
       " ['wfm', 'dropping', 'below', 'not', 'enthusing', 'investors'],\n",
       " ['htz', 'lower'],\n",
       " ['recall', 'adds', 'to', 'reliability', 'issues'],\n",
       " [\"'m\"],\n",
       " ['think', 'may', 'start', 'to', 'avoid', 'bios'],\n",
       " ['lvmh',\n",
       "  'affordable',\n",
       "  'luxe',\n",
       "  'fine',\n",
       "  'helped',\n",
       "  'dutyfree',\n",
       "  'confident',\n",
       "  'mainstream',\n",
       "  'shoppers'],\n",
       " ['crying', 'get'],\n",
       " ['trying',\n",
       "  'to',\n",
       "  'break',\n",
       "  'daily',\n",
       "  'trend',\n",
       "  'line',\n",
       "  'big',\n",
       "  'move',\n",
       "  'could',\n",
       "  'happen'],\n",
       " ['went', 'long', 'on'],\n",
       " ['bulls',\n",
       "  'lucky',\n",
       "  'enuff',\n",
       "  'to',\n",
       "  'get',\n",
       "  'upside',\n",
       "  'gap',\n",
       "  'fill',\n",
       "  'better',\n",
       "  'take'],\n",
       " ['would', \"n't\", 'call', 'banks', 'hs', 'quite', 'yet'],\n",
       " ['banks', 'to', 'implode', 'stress', 'tests', 'failing', 'selloff'],\n",
       " ['new', 'recommendation', 'carl', 'kirst', 'bmo', 'capital', 'markets'],\n",
       " ['near', 'buy', 'point', 'last', 'week'],\n",
       " ['pc', 'shipments', 'drop', 'to', 'lowest', 'level', 'since'],\n",
       " ['momentum', 'building', 'for', 'breakout', 'trigger', 'long', 'setup'],\n",
       " ['consistent', 'gains', 'small', 'one', 'favorite', 'trade'],\n",
       " ['aapl', 'cult', 'on', 'stocktwits', 'actually', 'disgusting'],\n",
       " ['higher', 'afternoon', 'trade', 'buy', 'point'],\n",
       " ['sector', 'stocks', 'leading', 'today'],\n",
       " ['adbe', 'flying'],\n",
       " ['tesla', 'to', 'recall', 'model', 'x', 'suvs', 'seat', 'issue'],\n",
       " ['back'],\n",
       " ['us',\n",
       "  'adds',\n",
       "  'k',\n",
       "  'jobs',\n",
       "  'november',\n",
       "  'unemployment',\n",
       "  'rate',\n",
       "  'remains',\n",
       "  'gold',\n",
       "  'futures'],\n",
       " ['pressure', 'along', 'market'],\n",
       " ['cash', 'cheap', 'financing', 'fueling', 'wave', 'acquisitions'],\n",
       " ['worst', 'sentiment', 'for', 'sp', 'stocks', 'market', 'close'],\n",
       " ['gold', 'going', 'parabolic', 'keep', 'chasing', 'tops', 'boys'],\n",
       " ['would', 'take', 'profits'],\n",
       " ['never', 'widen', 'stop', 'to', 'stay', 'trade'],\n",
       " ['slips', 'alongside', 'shares', 'on', 'nsa', 'leak', 'news'],\n",
       " ['best', 'outperformers', 'ranked'],\n",
       " ['googl', 'setting', 'up', 'day', 'moving', 'average'],\n",
       " ['weakest', 'sector', 'year', 'possible', 'false', 'breakout'],\n",
       " ['tesla', 'recalling', 'model', 'x', 'cars'],\n",
       " ['unusual', 'call', 'activity'],\n",
       " ['wish', 'puts', 'bac'],\n",
       " ['see', 'maintain', 'yield', 'announcing', 'monthly', 'divy'],\n",
       " ['look', 'shorts', 'running', 'for', 'cover'],\n",
       " ['x',\n",
       "  'etfs',\n",
       "  'subject',\n",
       "  'to',\n",
       "  'decay',\n",
       "  'due',\n",
       "  'to',\n",
       "  'daily',\n",
       "  'rebalancin',\n",
       "  'careful',\n",
       "  'holding'],\n",
       " ['signs', 'life', 'emerging'],\n",
       " ['markets', 'back', 'black', 'for'],\n",
       " ['rather', 'neutral', 'to', 'bullish', 'rather', 'bearish'],\n",
       " ['diversifies', 'adds', 'international', 'exposure'],\n",
       " ['aapl'],\n",
       " ['capped', 'range', 'leads', 'to', 'meltdown'],\n",
       " ['long', 'on'],\n",
       " ['googl',\n",
       "  'patents',\n",
       "  'turn',\n",
       "  'signal',\n",
       "  'detector',\n",
       "  'for',\n",
       "  'autonomous',\n",
       "  'cars'],\n",
       " ['moves', 'up', 'little', 'today', 'cup', 'handle'],\n",
       " ['makes', 'less', 'profit', 'sales', 'aapl', 'watch'],\n",
       " ['comparable', 'store', 'sales'],\n",
       " ['making',\n",
       "  'higher',\n",
       "  'highs',\n",
       "  'higher',\n",
       "  'lows',\n",
       "  'consolidates',\n",
       "  'past',\n",
       "  'several',\n",
       "  'weeks'],\n",
       " ['looking',\n",
       "  'to',\n",
       "  'add',\n",
       "  'gold',\n",
       "  'miner',\n",
       "  'possibly',\n",
       "  'lower',\n",
       "  'pe',\n",
       "  'tech',\n",
       "  'name',\n",
       "  'close'],\n",
       " ['sold', 'flat'],\n",
       " ['suddenly', 'realizing'],\n",
       " ['long'],\n",
       " ['fit', 'sune', 'not', 'changed'],\n",
       " ['nugt', 'fucking', 'beast', 'mode', 'kicking', 'shirts', 'nugt', 'pouch'],\n",
       " ['hospital', 'reits', 'slaughtered'],\n",
       " ['want', 'to', 'cry'],\n",
       " ['top', 'japan', 'etfs', 'to', 'surge', 'higher', 'h'],\n",
       " ['new', 'bullish', 'conversation', 'activity'],\n",
       " ['bottom', 'losses'],\n",
       " ['follow', 'trend', 'follow', 'money', 'flow'],\n",
       " ['short',\n",
       "  'squeeze',\n",
       "  'ready',\n",
       "  'to',\n",
       "  'upside',\n",
       "  'w',\n",
       "  'crossing',\n",
       "  'important',\n",
       "  'technical',\n",
       "  'level'],\n",
       " [\"'ll\", 'take', 'side', 'trade'],\n",
       " ['love', 'stock/co'],\n",
       " ['choice', 'to', 'positve'],\n",
       " ['word', 'on', 'street', 'allergen', 'looking', 'endo', 'international'],\n",
       " ['buy', 'wynn'],\n",
       " ['tsla', 'hype', 'news', 'sell', 'on', 'news'],\n",
       " ['three',\n",
       "  'black',\n",
       "  'crows',\n",
       "  'followed',\n",
       "  'potential',\n",
       "  'bear',\n",
       "  'flag',\n",
       "  'not',\n",
       "  'looking',\n",
       "  'promising',\n",
       "  'short',\n",
       "  'term'],\n",
       " ['looking', 'for', 'strong', 'bounce', 'lunchtime', 'rally', 'coming'],\n",
       " ['trails', 'msft', 'orcl', 'goog', 'crm', 'adbe'],\n",
       " ['stay', 'best', 'breed', 'room', 'to', 'run'],\n",
       " ['nice', 'day', 'rally'],\n",
       " ['orgetting', 'potential', 'relative', 'value', 'users'],\n",
       " ['looking', 'goo', 'for', 'break', 'must', 'hold'],\n",
       " ['usio', 'ops', 'profitable'],\n",
       " ['bot', 'gmcr', 'nov', 'call'],\n",
       " ['reasons', 'for', 'caution', 'chinese', 'stocks'],\n",
       " ['outperforms'],\n",
       " ['earish', 'trader', 'bets', 'k', 'stock', 'sell'],\n",
       " ['congrats', 'shorts'],\n",
       " ['downbeaten', 'stocks', 'may', 'ripe', 'for', 'buys'],\n",
       " ['picked', 'up', 'like', 'going'],\n",
       " ['worst', 'performers', 'today', 'mgm', 'io'],\n",
       " ['nt', 'done', 'good', 'name', 'pass'],\n",
       " ['nothing'],\n",
       " ['bullish', 'crossovers'],\n",
       " ['player', 'onto', 'puts'],\n",
       " ['someone', 'wants'],\n",
       " ['pcln', 'back', \"'up\", 'trendline'],\n",
       " ['found', 'good', 'bull', 'setups', 'week'],\n",
       " ['humming', 'easing', 'overbought'],\n",
       " ['follow', 'trend', 'follow', 'money', 'flow'],\n",
       " ['up'],\n",
       " ['sector', 'stocks', 'leading', 'today'],\n",
       " ['ron',\n",
       "  'johnson',\n",
       "  'tried',\n",
       "  'failed',\n",
       "  'to',\n",
       "  'inject',\n",
       "  'bit',\n",
       "  'apple',\n",
       "  'culture',\n",
       "  'jc',\n",
       "  'penney'],\n",
       " ['not', 'prettiest', 'candlesticks', 'signs', 'gap', 'fill', 'yet'],\n",
       " ['agree', 'risky', 'watching', 'closely'],\n",
       " ['breakout', 'consolidation', 'zone', 'bot'],\n",
       " ['took', 'small', 'posistion', 'on', 'tsla'],\n",
       " ['flop', 'would', 'get', 'everyone', 'running', 'to', 'fences'],\n",
       " ['unusual', 'call', 'activity'],\n",
       " ['worst', 'sentiment', 'for', 'sp', 'stocks', 'market', 'close'],\n",
       " ['new', 'squeeze', 'plays'],\n",
       " ['people', 'calling', 'bearish', 'heading', 'for', 'exits', 'already'],\n",
       " ['long', 'sq', 'long', 'sq'],\n",
       " ['fader', 'play'],\n",
       " ['sectors', 'improved', 'bullish', 'breadth'],\n",
       " ['toprated'],\n",
       " ['stochastic', 'overbought'],\n",
       " ['china', 'february', 'retail', 'sales', 'ecommerce', 'remains', 'resilient'],\n",
       " ['china', 'february', 'retail', 'sales', 'ecommerce', 'remains', 'resilient'],\n",
       " ['large',\n",
       "  'cap',\n",
       "  'tech',\n",
       "  'finally',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'catch',\n",
       "  'up',\n",
       "  'rest',\n",
       "  'market'],\n",
       " ['stock', 'dropping', 'hard'],\n",
       " ['recall', 'not', 'impact', 'financial', 'results'],\n",
       " [],\n",
       " ['weak', 'res'],\n",
       " ['gap', 'up', 'today', 'say', 'heat', 'coming'],\n",
       " ['toprated'],\n",
       " ['coming',\n",
       "  'far',\n",
       "  'could',\n",
       "  'go',\n",
       "  'far',\n",
       "  'stock',\n",
       "  'price',\n",
       "  'implies',\n",
       "  'pay',\n",
       "  'nothing',\n",
       "  'for',\n",
       "  'business'],\n",
       " ['lnkd', 'great', 'doesnt', 'potential', 'side', 'fb'],\n",
       " ['long', 'endp', 'on', 'agn', 'b/o', 'rumor'],\n",
       " ['oil', 'back'],\n",
       " ['short', 'setups', 'looking', 'nicereally', 'nice'],\n",
       " ['gist', 'downgrades', 'apple', 'failed', 'to', 'make', 'phone', 'th'],\n",
       " ['another',\n",
       "  'gain',\n",
       "  'rigl',\n",
       "  'following',\n",
       "  'last',\n",
       "  'week',\n",
       "  \"'s\",\n",
       "  'huge',\n",
       "  'call',\n",
       "  'buying',\n",
       "  'apr'],\n",
       " ['stx', 'higher'],\n",
       " ['grpn', 'much', 'better', 'day', 'fb'],\n",
       " ['stocks', 'insiders', 'bullish', 'on'],\n",
       " ['hipments', 'on', 'track', 'to', 'exceed', 'forecasts'],\n",
       " ['lvmh',\n",
       "  'affordable',\n",
       "  'luxe',\n",
       "  'fine',\n",
       "  'helped',\n",
       "  'dutyfree',\n",
       "  'confident',\n",
       "  'mainstream',\n",
       "  'shoppers'],\n",
       " ['cover'],\n",
       " ['ss',\n",
       "  'interest',\n",
       "  'rose',\n",
       "  'on',\n",
       "  'on',\n",
       "  'day',\n",
       "  'hit',\n",
       "  'lows',\n",
       "  'http',\n",
       "  '//stksco/cqkr'],\n",
       " ['bullish', 'stocks', 'on', 'twitter', 'dip'],\n",
       " ['fcx', 'march', 'puts'],\n",
       " ['first', 'quarter', 'amazing'],\n",
       " ['sap', 'q', 'disappoints', 'software', 'licenses', 'real', 'problem'],\n",
       " ['today', \"'s\", 'losers'],\n",
       " ['looking', 'for', 'sharp', 'move', 'up', 'equities'],\n",
       " ['gap', 'fill', 'coming', 'up'],\n",
       " ['report',\n",
       "  'apple',\n",
       "  'signs',\n",
       "  'up',\n",
       "  'for',\n",
       "  'google',\n",
       "  \"'s\",\n",
       "  'cloud',\n",
       "  'uses',\n",
       "  'much',\n",
       "  'less',\n",
       "  'amazon'],\n",
       " ['fb', 'to', 'tomorrow', 'show'],\n",
       " ['million', 'new', 'internet', 'users', 'added', 'globally', 'every', 'year'],\n",
       " ['covered', 'call'],\n",
       " ['long', 'buying', 'point'],\n",
       " [\"'ve\", 'picking', 'up', 'railroad', 'stocks', 'for', 'retirement', 'acct'],\n",
       " ['turmoil', 'mena', 'region', 'shippers', 'perform'],\n",
       " ['going', 'back', 'slowly'],\n",
       " ['since', 'alerted', 'short', 'sell', 'on'],\n",
       " ['bet', 'farm', 'on'],\n",
       " ['interest', 'heats', 'up', 'for', 'yahoo', 'yhoo'],\n",
       " ['parties', 'volatility', 'back'],\n",
       " ['stocks', 'higher', 'afternoon', 'trade'],\n",
       " ['highest', 'call', 'to', 'put', 'ratio'],\n",
       " ['apparently',\n",
       "  'intel',\n",
       "  'thinks',\n",
       "  'women',\n",
       "  'get',\n",
       "  'paid',\n",
       "  'men',\n",
       "  'intc',\n",
       "  'gender',\n",
       "  'pay',\n",
       "  'parity'],\n",
       " ['gs',\n",
       "  'looking',\n",
       "  'weak',\n",
       "  'market',\n",
       "  'moving',\n",
       "  'higher',\n",
       "  'not',\n",
       "  'good',\n",
       "  'sign'],\n",
       " ['mil', 'buy', 'order'],\n",
       " ['top', 'stocks'],\n",
       " ['top', 'stocks', 'ready', 'to', 'lead'],\n",
       " ['globally',\n",
       "  'week',\n",
       "  'on',\n",
       "  'avengers',\n",
       "  'really',\n",
       "  'sick',\n",
       "  'stan',\n",
       "  'lee',\n",
       "  'beast'],\n",
       " ['plus', 'irish', 'based', 'getting', 'rid', 'generic', 'biz'],\n",
       " [],\n",
       " ['f', 'shows', 'new', 'stakes'],\n",
       " ['gap', 'up', 'today', 'say', 'heat', 'coming'],\n",
       " ['breakout', 'watch'],\n",
       " ['short', 'setups', 'looking', 'nicereally', 'nice'],\n",
       " ['getting', 'lot', 'hype'],\n",
       " ['court', 'tells', 'states', 'to', 'leave', 'goog', 'alone'],\n",
       " ['got', 'nice', 'push', 'today'],\n",
       " ['unloaded', 'worth', 'ensign', 'group', 'inc', 'nasdaq', 'ensg', 'shares'],\n",
       " ['end', 'weekdid', 'snatch', 'ur'],\n",
       " ['continues', 'rally'],\n",
       " ['lawsuit', 'russian', 'search', 'engine'],\n",
       " ['oversold'],\n",
       " ['wks', 'fund', 'inflows', 'for', 'first', 'time'],\n",
       " ['mu', 'today'],\n",
       " ['unusual', 'call', 'buying'],\n",
       " ['ko', 'us', 'cocacola', 'co', 'oct', 'positive'],\n",
       " ['sales', 'weak', 'margins', 'debt', 'still', 'way', 'up'],\n",
       " ['broke',\n",
       "  'resistance',\n",
       "  'redtogreen',\n",
       "  'breakout',\n",
       "  'right',\n",
       "  'gate',\n",
       "  'tomorrow',\n",
       "  'morning'],\n",
       " ['ffiv', 'up'],\n",
       " ['bot', 'chrw'],\n",
       " ['breakout', 'thru', 'dma', 'short', 'squeeze', 'progress'],\n",
       " ['up', 'still', 'holding'],\n",
       " ['bid', 'for', 'reargument', 'denied', 'judge'],\n",
       " ['upcoming', 'first', 'support', 'days', 'weeks'],\n",
       " ['cafn',\n",
       "  'cachet',\n",
       "  'financial',\n",
       "  'solutions',\n",
       "  'surging',\n",
       "  'forward',\n",
       "  'today',\n",
       "  'post',\n",
       "  'earnings',\n",
       "  'up'],\n",
       " ['lots', 'green', 'on', 'min'],\n",
       " ['looking', 'to', 'buy'],\n",
       " [\"n't\", 'think', 'right', 'fit'],\n",
       " ['stochastics', 'finally', 'starting', 'to', 'turn', 'up', 'buying'],\n",
       " ['another', 'sell', 'rating'],\n",
       " ['nice', 'breakout', 'on', 'nice', 'stock'],\n",
       " ['launching', 'shopping', 'bot', 'catalyst', 'catalyst'],\n",
       " ['buy', 'stocks', \"'s\", 'blood', 'streets'],\n",
       " ['goldman', 'sachs', 'reiterates', 'conviction', 'buy', 'on'],\n",
       " ['losers', 'profit', 'sad'],\n",
       " ['long', 'term', 'uptrend', 'intract', 'far'],\n",
       " ['trending'],\n",
       " [],\n",
       " ['adding', 'on', 'dips'],\n",
       " ['added', 'long', 'friday', 'close'],\n",
       " ['losing', 'aapl', \"'s\", 'business'],\n",
       " ['oversold'],\n",
       " ['picking', 'up', 'couple', 'shares', 'goog', 'today'],\n",
       " ['broker', 'shorts'],\n",
       " ['sales',\n",
       "  'numbers',\n",
       "  'still',\n",
       "  'holding',\n",
       "  'up',\n",
       "  'well',\n",
       "  'igh',\n",
       "  'end',\n",
       "  'might',\n",
       "  'not',\n",
       "  'concern'],\n",
       " ['trying', 'to', 'drag', 'bidu'],\n",
       " ['million', 'new', 'internet', 'users', 'added', 'globally', 'every', 'year'],\n",
       " ['downgraded',\n",
       "  'to',\n",
       "  'neutral',\n",
       "  'deutsche',\n",
       "  'bank',\n",
       "  'price',\n",
       "  'target',\n",
       "  'reduced'],\n",
       " ['five',\n",
       "  'stocks',\n",
       "  'helped',\n",
       "  'starboard',\n",
       "  'valueâ€™s',\n",
       "  'equity',\n",
       "  'portfolio',\n",
       "  'return',\n",
       "  'q'],\n",
       " ['buy', 'zone', 'today', 'take', 'swing', 'trade', 'profits'],\n",
       " ['big', 'picture', 'brilliant', 'boywonder', 'visionary', 'zuck'],\n",
       " ['bounce', 'right', 'vol', 'vol', 'slid'],\n",
       " ['another', 'story', 'stock', 'unhappy', 'ending'],\n",
       " ['love', 'bullish'],\n",
       " ['bullish', 'stocks', 'on', 'twitter', 'dip'],\n",
       " ['mark', 'zuckerberg', 'amazing', 'job'],\n",
       " ['today', \"'s\", 'top', 'gainers'],\n",
       " ['history', 'lack', 'pr', 'shame', 'for', 'investors'],\n",
       " ['closed', 'friday', 'rs', 'line', 'new', 'highs'],\n",
       " ['look', 'belooooooowwww'],\n",
       " ['whole', 'semiconductor', 'space', 'looks', 'interesting'],\n",
       " ['to', 'combine', 'billion', 'deal'],\n",
       " ['peaks', 'hod'],\n",
       " ['problem',\n",
       "  'for',\n",
       "  'shorts',\n",
       "  'every',\n",
       "  'fund',\n",
       "  'want',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'thing',\n",
       "  'on',\n",
       "  'pullback'],\n",
       " ['awesomely', 'bullish', 'stocks'],\n",
       " ['good', 'base', 'building'],\n",
       " ['biggest', 'market', 'losers'],\n",
       " ['highest', 'call', 'to', 'put', 'ratio'],\n",
       " ['sold', 'to', 'close', 'qqq', 'puts', 'for'],\n",
       " ['ooks', 'pretty', 'bullish', 'for'],\n",
       " ['looks',\n",
       "  'really',\n",
       "  'interesting',\n",
       "  'on',\n",
       "  'drop',\n",
       "  'grabbed',\n",
       "  'options',\n",
       "  'stock',\n",
       "  'enough',\n",
       "  'tme',\n",
       "  'earnings',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'stock',\n",
       "  'growth',\n",
       "  'sectors'],\n",
       " ['covered', 'shorts'],\n",
       " ['add', 'to'],\n",
       " ['triple', 'top', 'forming'],\n",
       " ['end', 'up', 'selling', 'for', 'pennies', 'on', 'dollar'],\n",
       " ['looking', 'sexy', 'morning', 'break', 'on', 'volume'],\n",
       " ['whole', 'foods', 'shareholders', 'vote', 'activist', 'initiatives'],\n",
       " ['imagine', 'aapl', 'tv', 'impact'],\n",
       " ['southwest', 'lowest', 'multiple', 'ever'],\n",
       " ['still', 'early', 'for', 'entry'],\n",
       " ['moved', 'upper', 'bollinger', 'band'],\n",
       " ['today', 'bought'],\n",
       " ['wo', \"n't\", 'anyone', 'buying', 'products'],\n",
       " ['short', 'setups', 'looking', 'nicereally', 'nice'],\n",
       " ['still', 'long', 'term', 'fan'],\n",
       " ['nice', 'reversal'],\n",
       " ['tripadvisor', 'jumps', 'on', 'rumors'],\n",
       " ['tsla', 'recalls', 'model', 'x', 'vehicle', 'shares', 'volatile'],\n",
       " ['long', 'tech', 'calls'],\n",
       " ['breakout', 'confirmed', 'upturn'],\n",
       " ['best', 'performers'],\n",
       " ['tight', 'on', 'avail', 'stock', 'for', 'shorting'],\n",
       " ['get', 'wfm', 'mjn'],\n",
       " ['stochastic', 'overbought'],\n",
       " ['bounced', 'target', 'buy', 'area'],\n",
       " ['oversold'],\n",
       " ['double', 'top', 'reject'],\n",
       " ['added', 'bounce', 'for', 'ride', 'to'],\n",
       " ['working', 'on', 'cuba', 'deals'],\n",
       " ['dividend', 'hike', 'green', 'light'],\n",
       " ['excited', 'plays'],\n",
       " ['commodity', 'weakness'],\n",
       " ['fb', 'small', 'flong', 'via', 'calls'],\n",
       " ['nice', 'breakout', 'recent', 'consolidation'],\n",
       " ['sells', 'flati'],\n",
       " ['airplane', 'hospitality', 'industries', 'set', 'sights', 'on', 'cuba'],\n",
       " ['reserves', 'decline'],\n",
       " ['pull', 'back'],\n",
       " ['pie', 'sky'],\n",
       " ['first', 'quarter', 'amazing'],\n",
       " ['tfm', 'way', 'to', 'go', 'price', 'wise', 'to', 'compete', 'kroger', 'kr'],\n",
       " ['sector', 'stocks', 'leading', 'today'],\n",
       " ['biggest', 'st', 'gainers'],\n",
       " ['bears', 'take', 'clear', 'near', 'term', 'advantage'],\n",
       " ['onetime', 'zombie', 'stock', 'rise'],\n",
       " ['today', \"'s\", 'bull', 'flag'],\n",
       " ['iphone', 'se', 'could', 'better', 'expected'],\n",
       " ['up', 'to', 'stocks', 'making', 'new', 'week', 'highs'],\n",
       " ['would', 'short', 'amzn', 'on', 'rally'],\n",
       " ['losing', 'billion', 'on', 'vrx'],\n",
       " ['cat'],\n",
       " ['top', 'brands', 'for', 'millennials', 'aapl', 'fb', 'way', 'list'],\n",
       " ['looking', 'tasty'],\n",
       " ['sell', 'short', 'position', 'on'],\n",
       " ['nice', 'day', 'rally'],\n",
       " ['damn', 'low', 'priced', 'stocks'],\n",
       " ['spy', 'bubble', 'stock', 'buy', 'backs'],\n",
       " ['sell', 'signal', 'ndx', 'internals', 'technical', 'sell'],\n",
       " ['bullshit'],\n",
       " ['x'],\n",
       " ['get'],\n",
       " ['another', 'one', 'to', 'add', 'already', 'happily', 'holding'],\n",
       " ['rsi'],\n",
       " ['baba', 'going', 'to', 'interesting', 'one'],\n",
       " [],\n",
       " ['buy', 'dip'],\n",
       " [\"'s\", 'reason', 'googl', 'ca', \"n't\", 'get', 'back', 'to'],\n",
       " ['short'],\n",
       " ['equity',\n",
       "  'indexes',\n",
       "  'working',\n",
       "  'on',\n",
       "  'positive',\n",
       "  'engulfing',\n",
       "  'for',\n",
       "  'march'],\n",
       " ['highest', 'call', 'to', 'put', 'ratio'],\n",
       " ['oil',\n",
       "  'slid',\n",
       "  'to',\n",
       "  'fouryear',\n",
       "  'low',\n",
       "  'opec',\n",
       "  'kept',\n",
       "  'oil',\n",
       "  'production',\n",
       "  'unchange'],\n",
       " ['sideways'],\n",
       " ['unusual', 'call', 'activity'],\n",
       " ['green', 'lol', 'makeup', 'to', 'cover', 'ugliness'],\n",
       " ['slight', 'green', 'may', 'runner', 'later'],\n",
       " ['pivotal', 'sees', 'upside', 'for', 'alphabet'],\n",
       " ['refuse', 'worst', 'decisions', 'ever'],\n",
       " ['profitable', 'hard', 'software', 'product', 'innovator'],\n",
       " ['msft', 'opening', 'up', 'xboxlive', 'online', 'service'],\n",
       " ['gooo'],\n",
       " ['sold', 'calls'],\n",
       " ['resistance', 'right', 'sold', 'shares'],\n",
       " ['holding'],\n",
       " ['gevoâ€™s',\n",
       "  'alcohol',\n",
       "  'to',\n",
       "  'jet',\n",
       "  'fuel',\n",
       "  'eligible',\n",
       "  'to',\n",
       "  'used',\n",
       "  'for',\n",
       "  'commercial',\n",
       "  'flight'],\n",
       " ['stocks', 'support', 'w/', 'high', 'trade', 'quality'],\n",
       " ['finally', 'broke', 'free', 'big', 'brother', \"'s\", 'shadow'],\n",
       " ['like',\n",
       "  'ascending',\n",
       "  'triangle',\n",
       "  'breakout',\n",
       "  'coming',\n",
       "  'monday',\n",
       "  'looks',\n",
       "  'promising'],\n",
       " [\"'d\", 'short', 'fast'],\n",
       " ['play', 'longs'],\n",
       " ['trending'],\n",
       " ['supermarket',\n",
       "  'stocks',\n",
       "  'rally',\n",
       "  'tesco',\n",
       "  'plans',\n",
       "  'to',\n",
       "  'axe',\n",
       "  'noncore',\n",
       "  'uk',\n",
       "  'assets'],\n",
       " ['kre'],\n",
       " ['time',\n",
       "  'to',\n",
       "  'accumulate',\n",
       "  'for',\n",
       "  'long',\n",
       "  'position',\n",
       "  'far',\n",
       "  'upside',\n",
       "  'downside'],\n",
       " ['edge', 'offered'],\n",
       " ['oil', 'to', 'break', 'adding', 'chevron'],\n",
       " ['found', 'good', 'bull', 'setups', 'week'],\n",
       " ['sets', 'up', 'for', 'breakout'],\n",
       " ['something', 'big', 'gon', 'na', 'happen'],\n",
       " ['winning', 'pick', 'week'],\n",
       " ['calls', 'popping', 'stock'],\n",
       " ['double', 'bottom'],\n",
       " ['lets', 'see', 'one', 'dip'],\n",
       " ['consistent', 'gains', 'small', 'one', 'favorite', 'trade'],\n",
       " ['on',\n",
       "  'cusp',\n",
       "  'major',\n",
       "  'bollinger',\n",
       "  'breakout',\n",
       "  'on',\n",
       "  'daily',\n",
       "  'sitting',\n",
       "  'right',\n",
       "  'on',\n",
       "  'day',\n",
       "  'ema',\n",
       "  'force',\n",
       "  'strong',\n",
       "  'squeeze',\n",
       "  'shorts'],\n",
       " ['hanging',\n",
       "  'tough',\n",
       "  'market',\n",
       "  'due',\n",
       "  'to',\n",
       "  'analyst',\n",
       "  'upgrades',\n",
       "  'up',\n",
       "  'almost'],\n",
       " ['coal', 'stocks', 'poking', 'head', 'up', 'nice', 'weekly', 'candle'],\n",
       " ['still', 'holding'],\n",
       " ['exceptionally', 'bullish', 'for', 'romney', 'mkt', 'economy'],\n",
       " ['midsingle', 'digits', 'ebitda', 'growth'],\n",
       " ['posts',\n",
       "  'percent',\n",
       "  'jump',\n",
       "  'q',\n",
       "  'profit',\n",
       "  'steep',\n",
       "  'global',\n",
       "  'sales',\n",
       "  'increase',\n",
       "  'tops',\n",
       "  'wall',\n",
       "  'st',\n",
       "  'view'],\n",
       " ['loving', 'btu', 'coal', 'stocks'],\n",
       " ['watching', 'paint', 'dry', 'low', 'volatility'],\n",
       " ['fundamentally', 'nothing', 'changed'],\n",
       " ['stares', 'abyss'],\n",
       " ['smartphone', 'wars', 'wound', 'samsung'],\n",
       " ['growth', 'not', 'high', 'pe', 'stock'],\n",
       " ['long', 'morning'],\n",
       " ['took',\n",
       "  'proprietary',\n",
       "  'profit',\n",
       "  'exit',\n",
       "  \"n't\",\n",
       "  'like',\n",
       "  'option',\n",
       "  'liquidity',\n",
       "  'ousy',\n",
       "  'spreads'],\n",
       " ['yhoo',\n",
       "  'refuse',\n",
       "  'msft',\n",
       "  'offer',\n",
       "  'b',\n",
       "  'going',\n",
       "  'to',\n",
       "  'go',\n",
       "  'one',\n",
       "  'worst',\n",
       "  'decisions',\n",
       "  'ever'],\n",
       " ['gained', 'average', 'week', 'for', 'last', 'nine', 'years'],\n",
       " ['eyeing', 'ra', 'w', 'takeover', 'interest'],\n",
       " ['added', 'to', 'gild', 'position', 'started', 'new', 'one', 'bwld'],\n",
       " ['investor', 'longterm', 'stock', 'recommendation'],\n",
       " ['eps', 'growth', 'around', 'far'],\n",
       " ['easonably',\n",
       "  'priced',\n",
       "  'high',\n",
       "  'growth',\n",
       "  'institutional',\n",
       "  'fave',\n",
       "  'glamour',\n",
       "  'name',\n",
       "  'going',\n",
       "  'least',\n",
       "  'higher'],\n",
       " ['bull', 'day'],\n",
       " ['let', \"'s\", 'go', 'up', 'gilead'],\n",
       " ['european', 'debt', 'keeps', 'stocks'],\n",
       " ['nice',\n",
       "  'little',\n",
       "  'cupandhandle',\n",
       "  'shaping',\n",
       "  'up',\n",
       "  'favours',\n",
       "  'good',\n",
       "  'day',\n",
       "  'for',\n",
       "  'index'],\n",
       " ['bail'],\n",
       " ['dumped', 'pypl', 'prlb'],\n",
       " ['top', 'netpayoutyields'],\n",
       " ['cfo', 'sees', 'profitability', 'cash', 'flow', 'positive'],\n",
       " ['price', 'target', 'raised'],\n",
       " ['sad', 'to', 'see', 'loved', 'company', 'eating', 'dirt'],\n",
       " ['up'],\n",
       " ['cash', 'to', 'burn'],\n",
       " ['downbeaten', 'stocks', 'may', 'ripe', 'for', 'buys'],\n",
       " ['strictly', 'day', 'trading', 'one', 'long', 'short', 'minute'],\n",
       " ['aggressive', 'buy'],\n",
       " ['long',\n",
       "  'favorite',\n",
       "  'covered',\n",
       "  'call',\n",
       "  'double',\n",
       "  'dip',\n",
       "  'dividend',\n",
       "  'play',\n",
       "  'touting'],\n",
       " ['close', 'ready', 'to', 'rock', 'roll'],\n",
       " ['cold', 'put', 'dent', 'massive', 'horizontal', 'rig', 'production'],\n",
       " ['long', 'look', 'like', 'run', 'awaits'],\n",
       " ['tl', 'go', 'to', 'below', 'go', 'to'],\n",
       " ['accumulating', 'bsmx', 'on', 'pullback'],\n",
       " ['record', 'number', 'passengers', 'served'],\n",
       " ['trail', 'up'],\n",
       " ['bullshit', 'applestores', 'empty', 'china'],\n",
       " ['downgrade'],\n",
       " ['another', 'strong', 'rail', 'today', 'breaking', 'intraday', 'resistance'],\n",
       " ['heard',\n",
       "  'netflix',\n",
       "  'raising',\n",
       "  'prices',\n",
       "  \"'s\",\n",
       "  'good',\n",
       "  \"'s\",\n",
       "  'worth',\n",
       "  'though'],\n",
       " ['yet', 'not', 'much', 'price', 'changed'],\n",
       " ['stocks', 'insiders', 'bullish', 'on'],\n",
       " ['markets', 'still', 'acting', 'weak'],\n",
       " ['top', 'netpayoutyields'],\n",
       " ['gap', 'keeping', 'eye', 'on'],\n",
       " ['shorts', 'likely', 'to', 'take', 'profits', 'close'],\n",
       " ['see', 'reason', 'to', 'sell', 'yet'],\n",
       " ['ripping', 'early'],\n",
       " ['keeping', 'stops', 'bit', 'on', 'tight', 'side'],\n",
       " ['receives', 'year', 'contract'],\n",
       " ['splat', 'poor', 'q', 'orders'],\n",
       " ['oil', 'prices', 'oil', 'stocks', 'looking', 'less', 'cheap'],\n",
       " ['finding', 'support'],\n",
       " [],\n",
       " [],\n",
       " ['googl',\n",
       "  'patents',\n",
       "  'turn',\n",
       "  'signal',\n",
       "  'detector',\n",
       "  'for',\n",
       "  'autonomous',\n",
       "  'cars'],\n",
       " ['wants', 'lower', 'up', 'waves', 'getting', 'smaller'],\n",
       " ['add'],\n",
       " ['see', 'percent', 'upside', 'fb', 'shares'],\n",
       " ['great',\n",
       "  'growth',\n",
       "  'stk',\n",
       "  'also',\n",
       "  'raised',\n",
       "  'dividend',\n",
       "  'clearly',\n",
       "  'great',\n",
       "  'investment'],\n",
       " ['endp', 'sued', 'ft', 'nobody', 'buy', 'hanging', 'heads'],\n",
       " ['breaking', 'week', 'highs', 'timing', 'looks', 'great'],\n",
       " ['largecap', 'growth', 'fundholders', 'get', 'lift'],\n",
       " ['progress', 'witnessed', 'truly', 'stunning'],\n",
       " ['trying', 'to', 'drag', 'bidu'],\n",
       " ['short', 'interest', 'not'],\n",
       " ['momo', 'leaders', 'taken', 'one', 'one'],\n",
       " ['stochastic', 'overbought'],\n",
       " ['new', 'squeeze', 'plays'],\n",
       " ['active', 'puts'],\n",
       " ['mulls', 'sale', 'billion', 'venture', 'capital', 'portfolio'],\n",
       " ['strong', 'buy', 'within', 'month'],\n",
       " ['buy', 'stocks', \"'s\", 'blood', 'streets'],\n",
       " [\"'m\", 'watching', 'buy', 'targets'],\n",
       " ['yhoo', 'lost', 'since', 'nov'],\n",
       " ['would', \"n't\", 'surprised', 'to', 'see', 'green', 'close'],\n",
       " ['failed',\n",
       "  'breakouts',\n",
       "  'failed',\n",
       "  'setups',\n",
       "  'limping',\n",
       "  'on',\n",
       "  'crutches',\n",
       "  'next',\n",
       "  'week'],\n",
       " ['highflyers', 'falling'],\n",
       " ['decision',\n",
       "  'to',\n",
       "  'sell',\n",
       "  'robot',\n",
       "  'business',\n",
       "  'exposes',\n",
       "  'growing',\n",
       "  'pains'],\n",
       " ['stocks', 'insiders', 'bullish', 'on'],\n",
       " ['drop', 'expected'],\n",
       " ['upgraded', 'to', 'buy', 'alpha', 'street', 'research'],\n",
       " ['worth', 'chance'],\n",
       " ['rally', 'friday', 'newweekhighs', 'p'],\n",
       " ['expects', 'to', 'break', 'even'],\n",
       " ['higher'],\n",
       " ['adobe', 'receives', 'new', 'rating', 'top', 'analyst'],\n",
       " ['alot', 'to', 'worry'],\n",
       " ['see', 'reasons', 'to', 'cautious'],\n",
       " ['huge', 'buy', 'names'],\n",
       " ['msft', 'higher', 'expected'],\n",
       " ['verizon', 'still', 'bidder', 'to', 'beat'],\n",
       " ['could',\n",
       "  'pride',\n",
       "  'social',\n",
       "  'media',\n",
       "  'gettin',\n",
       "  'ready',\n",
       "  'to',\n",
       "  'fall',\n",
       "  'chart',\n",
       "  'rolling'],\n",
       " ['gold', 'going', 'parabolic', 'keep', 'chasing', 'tops', 'boys'],\n",
       " ['hold', 'media', 'bs', 'profitable', 'patience', 'key'],\n",
       " ['biggest', 'market', 'losers'],\n",
       " ['sectorbreadth', 'strongest', 'sector', 'industrials', 'bullishness'],\n",
       " ['uch', 'bloated', 'valuation'],\n",
       " ['love', 'blood', 'like', 'vampirekeep', 'bleeding', 'for'],\n",
       " ['fb', 'ibb', 'still', 'weak'],\n",
       " ['bull', 'candle'],\n",
       " ['ief', 'bullish'],\n",
       " ['best',\n",
       "  'scenario',\n",
       "  'going',\n",
       "  'forward',\n",
       "  'stock',\n",
       "  'slowly',\n",
       "  'falling',\n",
       "  'everyday'],\n",
       " ['plus', 'irish', 'based', 'getting', 'rid', 'generic', 'biz'],\n",
       " ['today', \"'s\", 'losers'],\n",
       " [\"'s\", 'want', 'buy'],\n",
       " ['sold', 'apr', 'calls'],\n",
       " ['stochastic', 'overbought'],\n",
       " ['long', 'position', 'on'],\n",
       " ['new', 'hod'],\n",
       " ['longs'],\n",
       " ['beat', 'up', 'ah'],\n",
       " ['since', 'tue', 'morning'],\n",
       " ['dividend',\n",
       "  'increase',\n",
       "  'rewards',\n",
       "  'patient',\n",
       "  'investors',\n",
       "  'future',\n",
       "  'looks',\n",
       "  'bright'],\n",
       " ['go', 'long', 'exp', 'imo'],\n",
       " ['remember', 'zuck', 'told', 'us', 'going', 'to', 'fix', 'email'],\n",
       " ['bought', 'little', 'yesterda', 'hoping', 'for', 'earnings', 'pop'],\n",
       " ['long',\n",
       "  'term',\n",
       "  'uptrend',\n",
       "  'broke',\n",
       "  'year',\n",
       "  'resistance',\n",
       "  'looks',\n",
       "  'primed',\n",
       "  'for',\n",
       "  'upside'],\n",
       " ['sets', 'up', 'for', 'breakout'],\n",
       " ['picked', 'up', 'calm'],\n",
       " ['advance', 'announce', 'licensing', 'agreement'],\n",
       " ['gets', 'patent', 'goes', 'up', 'today'],\n",
       " [\"n't\", 'like', 'neither', 'wall', 'street', 'fell'],\n",
       " ['gale', 'stacks', 'up', 'poorly', 'insider', 'ownership'],\n",
       " ['nice', 'day', 'rally'],\n",
       " ['oversold'],\n",
       " ['took', 'small', 'position'],\n",
       " ['continues', 'to', 'base', 'on', 'weekly', 'chart'],\n",
       " ['amazon', 'signed', 'deal', 'to', 'lease', 'boeing', 'cargo', 'planes'],\n",
       " ['today', \"'s\", 'losers'],\n",
       " ['up'],\n",
       " ['eps', 'growth', 'around', 'far'],\n",
       " ['may',\n",
       "  'not',\n",
       "  'bad',\n",
       "  'great',\n",
       "  'stocks',\n",
       "  'to',\n",
       "  'trade',\n",
       "  'making',\n",
       "  'new',\n",
       "  'highs'],\n",
       " ['top', 'netpayoutyields'],\n",
       " ['next', 'major', 'platform'],\n",
       " ['dailymail', 'content', 'perfect', 'for', 'yhoo', 'demographics'],\n",
       " ['investors', 'nervous', 'outlook'],\n",
       " ['money', 'flow', 'positive'],\n",
       " ['electronic', 'arts', 'attracts', 'investors'],\n",
       " ['biggest', 'market', 'losers'],\n",
       " [],\n",
       " ['multiple', 'expansion', 'intact', 'well'],\n",
       " ['added', 'regn'],\n",
       " ['plunging', 'back', 'to'],\n",
       " ['running'],\n",
       " ['add', 'to', 'fxp', 'skf', 'positions'],\n",
       " ['get', 'ready', 'for', 'flush'],\n",
       " ['needs', 'new', 'tablet', 'strategy'],\n",
       " ['taking', 'profits'],\n",
       " ['day', 'for', 'biotechs', 'good', 'to', 'load', 'up'],\n",
       " ['still', 'loving', 'today'],\n",
       " ['breaking', 'week', 'highs', 'timing', 'looks', 'great'],\n",
       " ['timberrrr'],\n",
       " ['best', 'stocks', 'for'],\n",
       " ['double', 'bottom', 'could'],\n",
       " ['star',\n",
       "  'analyst',\n",
       "  'joe',\n",
       "  'wittine',\n",
       "  'longbow',\n",
       "  'research',\n",
       "  'reiterated',\n",
       "  'hold',\n",
       "  'rating'],\n",
       " ['still', 'trouble', 'resistance', 'line'],\n",
       " ['accumulation',\n",
       "  'chart',\n",
       "  'continues',\n",
       "  'to',\n",
       "  'make',\n",
       "  'new',\n",
       "  'highs',\n",
       "  'showing',\n",
       "  'accumulation',\n",
       "  'continuing',\n",
       "  'to',\n",
       "  'take',\n",
       "  'place'],\n",
       " ['apple',\n",
       "  'hires',\n",
       "  'former',\n",
       "  'amazon',\n",
       "  'executive',\n",
       "  'george',\n",
       "  'stathakopoulos',\n",
       "  'head',\n",
       "  'corporate',\n",
       "  'data',\n",
       "  'security'],\n",
       " ['slipping'],\n",
       " ['bullish', 'reversal', 'setup', 'breakout'],\n",
       " ['near', 'hod'],\n",
       " ['moody', \"'s\", 'downgrade'],\n",
       " ['markets', 'back', 'black', 'for'],\n",
       " ['one', 'looking', 'beat', 'up', 'interesting'],\n",
       " ['amd',\n",
       "  'two',\n",
       "  'dollar',\n",
       "  'spec',\n",
       "  'play',\n",
       "  'ur',\n",
       "  'penny',\n",
       "  'scalps',\n",
       "  'cost',\n",
       "  'u',\n",
       "  'w/irs'],\n",
       " ['sell', 'signal', 'ndx', 'internals', 'technical', 'sell'],\n",
       " ['starting', 'to', 'creep', 'up'],\n",
       " ['invest', 'elon'],\n",
       " ['still', 'position'],\n",
       " ['minuscule', 'gain', 'ziv', 'lost', 'handsome', 'gains', 'on', 'friday'],\n",
       " ['airlines', 'battle', 'for', 'cuba', 'routes', 'aal', 'luv', 'save', 'jblu'],\n",
       " ['receivable', 'going', 'to', 'zero'],\n",
       " ['cisco', 'also', 'lower'],\n",
       " ['bullish', 'crossovers'],\n",
       " ['sell', 'rht'],\n",
       " ['play', 'longs'],\n",
       " ['next', 'charts', 'illustrate', 'bullish', 'weekly', 'outcome'],\n",
       " ['would', 'buy', 'wtsl', 'prices'],\n",
       " ['positive', 'comments', 'ms'],\n",
       " ['volume', 'footprint', 'looks', 'great'],\n",
       " ['drugs', 'biotech', 'getting', 'perky'],\n",
       " ['wants', 'to', 'ta', 'ceo', 'says', 'taxes', 'may', 'make', 'co', 'leave'],\n",
       " ['companies', 'shld', 'worried', 'icloud'],\n",
       " ['negative', 'p', 'l', 'on', 'hardware'],\n",
       " ['eyes', 'disposals', 'bid', 'to', 'appease', 'city', 'backers'],\n",
       " ['gap', 'fill', 'still', 'waiting'],\n",
       " ['long'],\n",
       " ['pie', 'sky'],\n",
       " ['afternoon',\n",
       "  'selloff',\n",
       "  'usual',\n",
       "  'brutal',\n",
       "  'get',\n",
       "  'ready',\n",
       "  'to',\n",
       "  'lose',\n",
       "  'ton',\n",
       "  'money'],\n",
       " ['short', 'markets', 'tank'],\n",
       " ['great', 'cash', 'balance', 'impressive', 'growth', 'rate'],\n",
       " ['calls',\n",
       "  'for',\n",
       "  'nice',\n",
       "  'gains',\n",
       "  'still',\n",
       "  'holding',\n",
       "  'week',\n",
       "  'made',\n",
       "  'morning'],\n",
       " ['top', 'holdings'],\n",
       " ['getting'],\n",
       " ['strong', 'min', 'bollies'],\n",
       " ['near', 'buy', 'point', 'last', 'week'],\n",
       " ['google', 'soon', 'start', 'selling', 'chromebooks', 'walmart', 'staples'],\n",
       " ['broke', 'bull', 'flag', 'channel', 'make', 'new', 'highs'],\n",
       " ['start', 'strong', 'finish', 'weak'],\n",
       " ['services', 'like', 'nflx', 'hulu', 'growing', 'much', 'faster', 'cable'],\n",
       " ['top', 'stocks'],\n",
       " ['goldman', 'sachs', 'reiterates', 'conviction', 'buy', 'on'],\n",
       " ['aapl', 'max', 'pain'],\n",
       " ['oil', 'prices', 'oil', 'stocks', 'looking', 'less', 'cheap'],\n",
       " ['got'],\n",
       " ['favorite', 'stocks'],\n",
       " ['buy'],\n",
       " ['run', 'run', 'amzn', 'up'],\n",
       " ['consumers', 'keep', 'cautious', 'stance'],\n",
       " ['on', 'longerterm', 'technical', 'swing', 'long', 'basis'],\n",
       " ['fb', 'taking', 'shine', 'aapl', 'goog'],\n",
       " ['broken', 'major', 'horizontal', 'resistance'],\n",
       " ['pie', 'sky'],\n",
       " ['balancing', 'roic', 'growth', 'to', 'create', 'value'],\n",
       " ['locked', 'fb', 'puts', 'for', 'nice', 'gain'],\n",
       " ['close', 'around', \"'s\", 'good', 'sign', 'tom', 'continue', 'upwards'],\n",
       " ['nflx', 'positive', 'comments', 'ms'],\n",
       " ['stochastic', 'overbought'],\n",
       " ['not', 'time', 'low', 'lower'],\n",
       " ['one', 'to', 'go', 'long', 'money', 'rotating', 'large', 'cap', 'tech'],\n",
       " ['looks', 'great', 'bullish'],\n",
       " ['starting', 'to', 'show', 'relative', 'strength'],\n",
       " ['time', 'to', 'stomp', 'on', 'dreams'],\n",
       " ['positive',\n",
       "  'outcome',\n",
       "  'w/',\n",
       "  'lung',\n",
       "  'study/',\n",
       "  'may',\n",
       "  'see',\n",
       "  'filing',\n",
       "  'soros'],\n",
       " ['test', 'coming', 'up'],\n",
       " ['rsi', 'lowest', 'level', 'since', 'october'],\n",
       " ['long', 'setup'],\n",
       " ['baird', 'upgrades', 'tesla', 'motors', 'tsla', 'to', 'outperform'],\n",
       " ['year',\n",
       "  'old',\n",
       "  'year',\n",
       "  'old',\n",
       "  'never',\n",
       "  'on',\n",
       "  'fb',\n",
       "  'mom',\n",
       "  'grandmas',\n",
       "  'though'],\n",
       " ['sector', 'stocks', 'leading', 'today'],\n",
       " ['yoku'],\n",
       " ['may', 'not', 'secure'],\n",
       " ['best', 'stocks', 'for'],\n",
       " ['long',\n",
       "  '/great',\n",
       "  'find',\n",
       "  'hope',\n",
       "  'wold',\n",
       "  'another',\n",
       "  'anly',\n",
       "  'pzzi',\n",
       "  'still',\n",
       "  'holding',\n",
       "  'second'],\n",
       " ['today', \"'s\", 'momentum', 'movers'],\n",
       " ['google', 'soon', 'start', 'selling', 'chromebooks', 'walmart', 'staples'],\n",
       " ['found', 'good', 'bull', 'setups', 'week'],\n",
       " ['holding', 'up', 'relatively', 'well', 'compared', 'to', 'broad', 'market'],\n",
       " ['less', 'stellar', 'day', 'held', 'day', 'moving', 'average'],\n",
       " ['beautifully', 'orchestrated', 'marke'],\n",
       " ['up'],\n",
       " ['cures', 'hardtotreat'],\n",
       " ['long', 'buying', 'point'],\n",
       " [],\n",
       " ['let', 'run'],\n",
       " ['yahoo', 'extends', 'bidding', 'deadline', 'interest', 'grows'],\n",
       " [],\n",
       " ['today', 'bought'],\n",
       " ['enjoy', 'bull', 'run', 'started'],\n",
       " ['issues', 'statement', 'on', 'debt', 'ceiling'],\n",
       " [\"'s\", 'good', 'short', 'spot'],\n",
       " ['worst', 'performers', 'today', 'mgm', 'io'],\n",
       " ['insiders', 'selling'],\n",
       " ['good', 'news', 'for', 'domestic', 'automakers'],\n",
       " ['one', 'cheerleaders', 'show', 'actual', 'valuation', 'work'],\n",
       " ['up', 'to', 'market'],\n",
       " ['buying', 'on', 'weakness'],\n",
       " ['three', 'hot', 'stocks', 'today'],\n",
       " ['ready', 'for', 'take'],\n",
       " ['report', 'apple', 'signs', 'up', 'for', 'google', \"'s\", 'cloud'],\n",
       " ['short', 'setups', 'looking', 'nicereally', 'nice'],\n",
       " ['short', 'mbly'],\n",
       " ['push', 'nly', 'investment', 'to', 'another', 'time'],\n",
       " ['notable', 'gainers', 'among', 'liquid', 'option', 'names', 'morning'],\n",
       " ['looking',\n",
       "  'to',\n",
       "  'add',\n",
       "  'gold',\n",
       "  'miner',\n",
       "  'possibly',\n",
       "  'lower',\n",
       "  'pe',\n",
       "  'tech',\n",
       "  'name',\n",
       "  'close'],\n",
       " ['point', 'possible', 'move', 'up'],\n",
       " ['let', 'stock', 'fall', 'big', 'time', 'earnings'],\n",
       " ['not', 'selling'],\n",
       " ['tremendous', 'opportunity', 'awaits'],\n",
       " ['up', 'premarket', 'ready', 'for', 'lift'],\n",
       " ['overall', 'market', 'improve'],\n",
       " ['gots', 'aezs', 'morning'],\n",
       " ['erinn', 'murphy', 'piper', 'jaffray', 'thinks', 'finl', 'buy'],\n",
       " ['longer', 'term', 'top', 'building', 'quickie', 'short'],\n",
       " ['debt', 'crisis', 'entered', 'dangerous', 'new', 'phase'],\n",
       " ['mu', 'may', 'go', 'bear', 'pattern', 'confirmed'],\n",
       " ['looking', 'good', 'note', 'broke', 'area', 'on', 'lighter', 'volume'],\n",
       " ['cracking'],\n",
       " ['bullish', 'crossovers'],\n",
       " ['still', 'interesting', 'finance', 'play', 'one', 'since', \"'s\", 'hold'],\n",
       " ['broke',\n",
       "  'downtrend',\n",
       "  'line',\n",
       "  'ready',\n",
       "  'to',\n",
       "  'launch',\n",
       "  'day',\n",
       "  'moving',\n",
       "  'average'],\n",
       " ['stocks', 'came', 'up', 'on', 'screens', 'for', 'longs'],\n",
       " ['defying', 'downturn'],\n",
       " ['soars', 'premarket'],\n",
       " ['stock', 'buy'],\n",
       " ['pain'],\n",
       " ['hi', 'beta', 'hi', 'performers'],\n",
       " ['trouble', 'earnings', 'gap', 'still', 'unfilled'],\n",
       " ['calls',\n",
       "  'for',\n",
       "  'nice',\n",
       "  'gains',\n",
       "  'still',\n",
       "  'holding',\n",
       "  'week',\n",
       "  'made',\n",
       "  'morning'],\n",
       " ['long', 'look', 'like', 'run', 'awaits'],\n",
       " ['bull', 'move', 'ended', 'waiting', 'for', 'next', 'setup'],\n",
       " ['trying', 'to', 'lead', 'higher'],\n",
       " ['bought', 'back', 'shares', 'today'],\n",
       " ['getting',\n",
       "  'close',\n",
       "  'to',\n",
       "  'hasnâ€™t',\n",
       "  'closed',\n",
       "  'since',\n",
       "  'july',\n",
       "  'significant'],\n",
       " ['addding', 'tsla', 'ss', 'added', 'small', 'vrx', 'long', 'tsla', 'vrx'],\n",
       " ['sold', 'xoma'],\n",
       " ['nice', 'blurb', 'for', 'bbry'],\n",
       " ['nice', 'reversal'],\n",
       " [\"'m\", 'watching', 'buy', 'targets'],\n",
       " [\"n't\", 'catch', 'falling', 'knives'],\n",
       " ['barclays', 'signs', 'on', 'to', 'apple', 'pay'],\n",
       " ['looking', 'weak'],\n",
       " ['markets', 'still', 'acting', 'weak'],\n",
       " ['short/put',\n",
       "  'positions',\n",
       "  'looking',\n",
       "  'good',\n",
       "  'wait',\n",
       "  'for',\n",
       "  'market',\n",
       "  'downturn',\n",
       "  'to',\n",
       "  'confirm'],\n",
       " ['bullish', 'nflx', 'day', 'trade', 'setup'],\n",
       " ['unusual', 'call', 'activity'],\n",
       " ['institutions', 'seem', 'to', 'like', 'class', 'stocks'],\n",
       " ['loading', 'spy', 'aapl', 'puts', 'think', 'toppy'],\n",
       " ['watch', 'tsla'],\n",
       " ['still', 'bear', 'market'],\n",
       " ['china', 'winners'],\n",
       " ['stock', 'options', 'trade', 'would', 'doubled', 'money'],\n",
       " ['master',\n",
       "  'class',\n",
       "  'on',\n",
       "  'to',\n",
       "  'conquer',\n",
       "  'mobile',\n",
       "  'astonishing',\n",
       "  'turned',\n",
       "  'fortunes',\n",
       "  'around'],\n",
       " ['got', 'hit', 'hard', 'lower'],\n",
       " ['biggies', 'must', 'loading', 'up', 'lows'],\n",
       " ['hard', 'to', 'diminish', 'lead'],\n",
       " ['inverse', 'head', 'shoulders', 'forming'],\n",
       " ['weak', 'outlook'],\n",
       " ['indices',\n",
       "  'rallying',\n",
       "  'today',\n",
       "  'lot',\n",
       "  \"'highly\",\n",
       "  'covered',\n",
       "  'companies',\n",
       "  'underperforming'],\n",
       " ['gpro', 'up'],\n",
       " ['embarrassing', 'china', 'numbers'],\n",
       " ['possible', 'target'],\n",
       " ['rally', 'friday', 'newweekhighs', 'p'],\n",
       " ['long', 'setup', 'closed'],\n",
       " ['closed', 'green', 'bullish'],\n",
       " [],\n",
       " ['bumping', 'head', 'on', 'declining', 'daily', 'overhead', 'resistance'],\n",
       " ['least', \"n't\", 'stop'],\n",
       " ['finds', 'support'],\n",
       " ['longterm', 'potential', 'robust'],\n",
       " ['hopefully', 'peeps', 'shorting', 'camt', 'for', 'scalps'],\n",
       " ['time', 'to', 'short', 'tsla'],\n",
       " ['keep', 'stock', 'on', 'watch', 'list'],\n",
       " ['gap', 'up', 'tomorrow'],\n",
       " ['demand', 'ahead', 'strongest', 'growth'],\n",
       " ['updated', 'core', 'portfolio'],\n",
       " ['new', 'hod', 'conviction', 'keeping', 'on', 'watch', 'for', 'resistance'],\n",
       " ['long', 'market'],\n",
       " ['acting', 'tough', 'on', 'big', 'volume', 'tape'],\n",
       " ['best', 'outperformers', 'ranked'],\n",
       " ['infection', 'worries', 'prompt', 'regulatory', 'reviews'],\n",
       " ['back',\n",
       "  'to',\n",
       "  'back',\n",
       "  'intraday',\n",
       "  'reversals',\n",
       "  'look',\n",
       "  'below',\n",
       "  'shorts',\n",
       "  'moving'],\n",
       " ['weekly', 'calls'],\n",
       " ['bull', 'gld', 'bear'],\n",
       " ['watchlist', 'top', 'stocks'],\n",
       " ['would',\n",
       "  'consider',\n",
       "  'opportunity',\n",
       "  'to',\n",
       "  'add',\n",
       "  'position',\n",
       "  'company',\n",
       "  'on',\n",
       "  'right',\n",
       "  'track',\n",
       "  'still',\n",
       "  'improving',\n",
       "  'sales'],\n",
       " ['markets', 'still', 'acting', 'weak'],\n",
       " ['bear', 'flag'],\n",
       " ['took', 'endp', 'long'],\n",
       " ['yes', 'buy', 'everything', 'up'],\n",
       " ['brent', 'back', 'below'],\n",
       " ['premier', 'retail', 'dividend', 'play'],\n",
       " ['beat', 'up', 'ah'],\n",
       " ['shipments',\n",
       "  'slid',\n",
       "  'to',\n",
       "  'lowest',\n",
       "  'quarterly',\n",
       "  'total',\n",
       "  'since',\n",
       "  'dethrones'],\n",
       " ['long'],\n",
       " ['bullish', 'crossovers'],\n",
       " ['trending'],\n",
       " ['unusual', 'call', 'activity'],\n",
       " ['nice', 'day', 'rally'],\n",
       " ['added', 'long', 'friday', 'close'],\n",
       " ['looks', 'like', 'might', 'break', \"'m\"],\n",
       " ['long',\n",
       "  '/great',\n",
       "  'find',\n",
       "  'hope',\n",
       "  'wold',\n",
       "  'another',\n",
       "  'anly',\n",
       "  'pzzi',\n",
       "  'still',\n",
       "  'holding',\n",
       "  'second'],\n",
       " ['pushing', 'channel', 'development'],\n",
       " ['bot', 'ezpw'],\n",
       " ['like', 'trade', 'to', 'sma'],\n",
       " ['short'],\n",
       " ['chunk', 'dec', 'puts', 'bought'],\n",
       " ['not', 'time', 'to', 'buy'],\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list_tweet=get_tweets(data)\n",
    "list_tweet=list(data.processed_data[\"token_spans\"])\n",
    "#sentences=review_sentences(list_tweet, remove_stopwords=True)\n",
    "sentences=list_tweet\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-22 09:31:59,337 : INFO : collecting all words and their counts\n",
      "2018-05-22 09:31:59,339 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-05-22 09:31:59,344 : INFO : collected 2218 word types from a corpus of 7608 raw words and 1700 sentences\n",
      "2018-05-22 09:31:59,346 : INFO : Loading a fresh vocabulary\n",
      "2018-05-22 09:31:59,351 : INFO : min_count=2 retains 1013 unique words (45% of original 2218, drops 1205)\n",
      "2018-05-22 09:31:59,352 : INFO : min_count=2 leaves 6403 word corpus (84% of original 7608, drops 1205)\n",
      "2018-05-22 09:31:59,357 : INFO : deleting the raw counts dictionary of 2218 items\n",
      "2018-05-22 09:31:59,359 : INFO : sample=0.001 downsamples 66 most-common words\n",
      "2018-05-22 09:31:59,360 : INFO : downsampling leaves estimated 5337 word corpus (83.4% of prior 6403)\n",
      "2018-05-22 09:31:59,365 : INFO : estimated required memory for 1013 words and 100 dimensions: 1316900 bytes\n",
      "2018-05-22 09:31:59,366 : INFO : resetting layer weights\n",
      "2018-05-22 09:31:59,394 : INFO : training model with 4 workers on 1013 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-05-22 09:31:59,407 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-22 09:31:59,409 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-22 09:31:59,411 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-22 09:31:59,418 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-22 09:31:59,419 : INFO : EPOCH - 1 : training on 7608 raw words (5324 effective words) took 0.0s, 340879 effective words/s\n",
      "2018-05-22 09:31:59,435 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-22 09:31:59,436 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-22 09:31:59,439 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-22 09:31:59,446 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-22 09:31:59,447 : INFO : EPOCH - 2 : training on 7608 raw words (5347 effective words) took 0.0s, 326788 effective words/s\n",
      "2018-05-22 09:31:59,461 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-22 09:31:59,464 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-22 09:31:59,465 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-22 09:31:59,474 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-22 09:31:59,475 : INFO : EPOCH - 3 : training on 7608 raw words (5288 effective words) took 0.0s, 326383 effective words/s\n",
      "2018-05-22 09:31:59,488 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-22 09:31:59,490 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-22 09:31:59,494 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-22 09:31:59,503 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-22 09:31:59,504 : INFO : EPOCH - 4 : training on 7608 raw words (5363 effective words) took 0.0s, 274081 effective words/s\n",
      "2018-05-22 09:31:59,516 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-22 09:31:59,521 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-22 09:31:59,526 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-22 09:31:59,532 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-22 09:31:59,533 : INFO : EPOCH - 5 : training on 7608 raw words (5369 effective words) took 0.0s, 284734 effective words/s\n",
      "2018-05-22 09:31:59,534 : INFO : training on a 38040 raw words (26691 effective words) took 0.1s, 190777 effective words/s\n",
      "2018-05-22 09:31:59,535 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2018-05-22 09:31:59,537 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-22 09:31:59,548 : INFO : saving Word2Vec object under microblogs_word_vector, separately None\n",
      "2018-05-22 09:31:59,550 : INFO : not storing attribute vectors_norm\n",
      "2018-05-22 09:31:59,551 : INFO : not storing attribute cum_table\n",
      "2018-05-22 09:31:59,568 : INFO : saved microblogs_word_vector\n"
     ]
    }
   ],
   "source": [
    "# Creating the model and setting values for the various parameters\n",
    "num_features = 100  # Word vector dimensionality\n",
    "min_word_count = 2 # Minimum word count\n",
    "num_workers = 4     # Number of parallel threads\n",
    "context = 10        # Context window size\n",
    "downsampling = 1e-3 # (0.001) Downsample setting for frequent words\n",
    "\n",
    "# Initializing the train model\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model....\")\n",
    "model = word2vec.Word2Vec(sentences,\\\n",
    "                          workers=num_workers,\\\n",
    "                          size=num_features,\\\n",
    "                          min_count=min_word_count,\\\n",
    "                          window=context,\n",
    "                          sample=downsampling)\n",
    "\n",
    "# To make the model memory efficient\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# Saving the model for later use. Can be loaded using Word2Vec.load()\n",
    "model_name = \"microblogs_word_vector\"\n",
    "model.save(model_name)\n",
    "#model = gensim.models.Word2Vec.load(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-22 09:31:59,985 : WARNING : vectors for words {'the', 'Thanks'} are not present in the model, ignoring these words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1013"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Few tests: This will print the odd word among them \n",
    "model.wv.doesnt_match(\"Thanks for the short upper\".split())\n",
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('call', 0.4241793751716614),\n",
       " ('for', 0.3864457607269287),\n",
       " ('last', 0.36644792556762695),\n",
       " ('end', 0.35728055238723755),\n",
       " ('long', 0.35341405868530273),\n",
       " ('to', 0.35009369254112244),\n",
       " ('quarterly', 0.34859561920166016),\n",
       " ('keep', 0.3455084562301636),\n",
       " ('on', 0.33903056383132935),\n",
       " ('cuba', 0.33614590764045715)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"big\")\n",
    "#len(model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Function to average all word vectors in a paragraph\n",
    "def featureVecMethod(words, model, num_features):\n",
    "    # Pre-initialising empty numpy array for speed\n",
    "    featureVec = np.zeros(num_features,dtype=\"float32\")\n",
    "    nwords = 0\n",
    "    \n",
    "    #Converting Index2Word which is a list to a set for better speed in the execution.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    for word in  words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    \n",
    "    # Dividing the result by number of words to get average\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the average feature vector\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        # Printing a status message every 1000th review\n",
    "        if counter%1000 == 0:\n",
    "            print(\"Review %d of %d\"%(counter,len(reviews)))\n",
    "            \n",
    "        reviewFeatureVecs[counter] = featureVecMethod(review, model, num_features)\n",
    "        counter = counter+1\n",
    "        \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 1700\n",
      "Review 1000 of 1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Globalnet\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Globalnet\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#transformer les donner de train en moyenne de vecteurs word2vec \n",
    "trainDataVecs = getAvgFeatureVecs(list_tweet, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=trainDataVecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.366,  0.638, -0.494, ...,  0.405,  0.296, -0.296])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=data.processed_data[\"sentiment score\"].values\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y,train_size=0.7)                                                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=0.7, gamma=0.3, learning_rate=0.1,\n",
      "       max_delta_step=0, max_depth=4, min_child_weight=4, missing=None,\n",
      "       n_estimators=100, n_jobs=1, nthread=None, objective='reg:linear',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=0.8)\n"
     ]
    }
   ],
   "source": [
    "#appliquer le mdele xgboost \n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection, preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#Fitting XGB regressor \n",
    "model_xgb = xgb.XGBRegressor(max_depth=4, min_child_weight= 4,gamma=0.3,subsample=0.8,colsample_bytree=0.7)\n",
    "model_xgb.fit(X,Y)\n",
    "print (model_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cashtag</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment score</th>\n",
       "      <th>source</th>\n",
       "      <th>spans</th>\n",
       "      <th>token_spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$F</td>\n",
       "      <td>5540055</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Putting on a little $F short]</td>\n",
       "      <td>[putting, on, little, f, short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$AAPL</td>\n",
       "      <td>10752226</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[short some]</td>\n",
       "      <td>[short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$BAC</td>\n",
       "      <td>10920221</td>\n",
       "      <td>0.445</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[buying opportunity]</td>\n",
       "      <td>[buying, opportunity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$SHOR</td>\n",
       "      <td>12971398</td>\n",
       "      <td>0.661</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[Scaling Up on Long Position]</td>\n",
       "      <td>[scaling, up, on, long, position]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$JPM</td>\n",
       "      <td>16142438</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>stocktwits</td>\n",
       "      <td>[its time to sell banks]</td>\n",
       "      <td>[time, to, sell, banks]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cashtag        id  sentiment score      source  \\\n",
       "0      $F   5540055           -0.454  stocktwits   \n",
       "1   $AAPL  10752226           -0.464  stocktwits   \n",
       "2    $BAC  10920221            0.445  stocktwits   \n",
       "3   $SHOR  12971398            0.661  stocktwits   \n",
       "4    $JPM  16142438           -0.763  stocktwits   \n",
       "\n",
       "                            spans                        token_spans  \n",
       "0  [Putting on a little $F short]    [putting, on, little, f, short]  \n",
       "1                    [short some]                            [short]  \n",
       "2            [buying opportunity]              [buying, opportunity]  \n",
       "3   [Scaling Up on Long Position]  [scaling, up, on, long, position]  \n",
       "4        [its time to sell banks]            [time, to, sell, banks]  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.do_process()\n",
    "data_test.processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet=list(data_test.processed_data[\"token_spans\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Globalnet\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "testDataVecs = getAvgFeatureVecs(test_tweet, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=testDataVecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isoler les tweets du test et leur vrai valeur de sentiment \n",
    "labels=[\"real pred\",\"spans\"]\n",
    "pred=list(data_test.processed_data[\"sentiment score\"])\n",
    "twt=list(data_test.processed_data[\"spans\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real prediction</th>\n",
       "      <th>spans</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.454</td>\n",
       "      <td>[Putting on a little $F short]</td>\n",
       "      <td>0.016784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.464</td>\n",
       "      <td>[short some]</td>\n",
       "      <td>-0.492857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.445</td>\n",
       "      <td>[buying opportunity]</td>\n",
       "      <td>0.087142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.661</td>\n",
       "      <td>[Scaling Up on Long Position]</td>\n",
       "      <td>0.275433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.763</td>\n",
       "      <td>[its time to sell banks]</td>\n",
       "      <td>-0.437254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.627</td>\n",
       "      <td>[Entering long]</td>\n",
       "      <td>0.284053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.653</td>\n",
       "      <td>[picked some up]</td>\n",
       "      <td>0.190707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.668</td>\n",
       "      <td>[time to accumulate for a long position, far m...</td>\n",
       "      <td>0.287769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.460</td>\n",
       "      <td>[Looking for a strong bounce, Lunchtime rally ...</td>\n",
       "      <td>0.342317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.403</td>\n",
       "      <td>[Very intrigued with the technology and growth...</td>\n",
       "      <td>0.233602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000</td>\n",
       "      <td>[short2 48 + - ***worked, puts up]</td>\n",
       "      <td>-0.118719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.438</td>\n",
       "      <td>[Biggest Market Losers]</td>\n",
       "      <td>-0.405218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.398</td>\n",
       "      <td>[$GOOG $GOOGL would suck]</td>\n",
       "      <td>-0.280648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.483</td>\n",
       "      <td>[Buying $SBUX on dip]</td>\n",
       "      <td>0.227486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.480</td>\n",
       "      <td>[is a short below 740, and is overbought]</td>\n",
       "      <td>-0.306876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.454</td>\n",
       "      <td>[don't Putting on a down little $F short]</td>\n",
       "      <td>0.061738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    real prediction                                              spans  \\\n",
       "0            -0.454                     [Putting on a little $F short]   \n",
       "1            -0.464                                       [short some]   \n",
       "2             0.445                               [buying opportunity]   \n",
       "3             0.661                      [Scaling Up on Long Position]   \n",
       "4            -0.763                           [its time to sell banks]   \n",
       "5             0.627                                    [Entering long]   \n",
       "6             0.653                                   [picked some up]   \n",
       "7             0.668  [time to accumulate for a long position, far m...   \n",
       "8             0.460  [Looking for a strong bounce, Lunchtime rally ...   \n",
       "9             0.403  [Very intrigued with the technology and growth...   \n",
       "10            0.000                 [short2 48 + - ***worked, puts up]   \n",
       "11           -0.438                            [Biggest Market Losers]   \n",
       "12           -0.398                          [$GOOG $GOOGL would suck]   \n",
       "13            0.483                              [Buying $SBUX on dip]   \n",
       "14           -0.480          [is a short below 740, and is overbought]   \n",
       "15           -0.454          [don't Putting on a down little $F short]   \n",
       "\n",
       "    Prediction  \n",
       "0     0.016784  \n",
       "1    -0.492857  \n",
       "2     0.087142  \n",
       "3     0.275433  \n",
       "4    -0.437254  \n",
       "5     0.284053  \n",
       "6     0.190707  \n",
       "7     0.287769  \n",
       "8     0.342317  \n",
       "9     0.233602  \n",
       "10   -0.118719  \n",
       "11   -0.405218  \n",
       "12   -0.280648  \n",
       "13    0.227486  \n",
       "14   -0.306876  \n",
       "15    0.061738  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict \n",
    "output_2 = model_xgb.predict(x_test)\n",
    "test_df = pd.DataFrame(pred,columns={\"real prediction\"})\n",
    "#final_df[\"ID\"] = id_vals\n",
    "#final_df[\"cashtag\"]=row2\n",
    "\n",
    "test_df[\"spans\"]=twt\n",
    "test_df[\"Prediction\"] = output_2\n",
    "#final_df.to_csv(\"Output_1.csv\",sep=\",\")\n",
    "test_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error: 0.09462120484743503\n",
      "R2 score: -0.16800682237999953\n"
     ]
    }
   ],
   "source": [
    "#tester la performance de prediction avec R2 score et MSE\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"mean squared error:\" ,mean_squared_error(output_2, pred))\n",
    "print(\"R2 score:\" ,r2_score(output_2,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
